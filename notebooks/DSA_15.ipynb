{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFjcgYU6xqWL"
   },
   "source": [
    "## **Exploratory Data Analysis (EDA):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1728325527342,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "7F52gdvuxRNN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score,precision_score,recall_score,f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 722,
     "status": "ok",
     "timestamp": 1728325528498,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "Yl0W1GeV0H7U"
   },
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"data/Titanic_train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1728325528498,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "QMfFQdAO0vni",
    "outputId": "4d51d533-9b72-4034-d609-77a0c1a28892"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1728325528498,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "5FGqq9pY08d5",
    "outputId": "2bd13696-f300-4f8a-ca1c-e2b5038a2939"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1728325528499,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "fswGUTDl1C2v",
    "outputId": "7dbfefec-75c8-40fc-f392-1312648ef602"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>681</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>347082</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name   Sex  Ticket    Cabin Embarked\n",
       "count                       891   891     891      204      889\n",
       "unique                      891     2     681      147        3\n",
       "top     Braund, Mr. Owen Harris  male  347082  B96 B98        S\n",
       "freq                          1   577       7        4      644"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe(include=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1728325528499,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "XJewez7M1InO",
    "outputId": "9f4f71bf-ff7f-494c-caa2-dc9d37bf05ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1728325528499,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "qKpYDJVO1OCM",
    "outputId": "c53ba1d0-7897-48c8-c8a9-1db960b9ab31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "executionInfo": {
     "elapsed": 2245,
     "status": "ok",
     "timestamp": 1728325530738,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "2lcGgq_U5N8x",
    "outputId": "3f78602f-aca7-4aa2-aa9e-30c5ca152af7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train.hist(bins=10,color='teal',edgecolor='black',figsize=(14,8))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1728325530738,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "p-WNqU4h6Gqh",
    "outputId": "f48ff84f-214b-41d2-c585-a358fda47927"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data=df_train)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 1265,
     "status": "ok",
     "timestamp": 1728325532001,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "V-FGifuK7D0d",
    "outputId": "4ae342c7-2176-43f2-e2f0-fe0bfda093ab"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=\"Sex\",y=\"Survived\",data=df_train,color='red')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1728325532001,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "IW6rz0LV8RwI",
    "outputId": "9dd4b024-2169-4c57-e19f-47d78f9fecec"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAA2MxJREFUeJzs3XeYZGWZ+P3vSZVTV3XunggDw5CTMKAsIDAiKgiIYSS4LO6y4KoYcVF30VdY3FXXnyDuGsBVzICighIEFAZEJEeBGSZ0TpXTCe8f3V3T1VXV0z3Tseb+XFdfMOepOuep6uqqu55w34rjOA5CCCGEEGLJUxe6A0IIIYQQYnZIYCeEEEIIUScksBNCCCGEqBMS2AkhhBBC1AkJ7IQQQggh6oQEdkIIIYQQdUICOyGEEEKIOiGBnRBCCCFEndAXugOLgW3bdHV1EQwGURRlobsjhBBCCFHiOA7JZJL29nZUdeoxOQnsgK6uLpYtW7bQ3RBCCCGEqGnbtm10dnZOeRsJ7IBgMAiMPmGhUGiBeyOEEEIIsVMikWDZsmWleGUqEthBafo1FApJYCeEEEKIRWk6y8Vk84QQQgghRJ2QwE4IIYQQok5IYCeEEEIIUSdkjZ0QQggh5pVlWRSLxYXuxqJhGAaaps3KuSSwE0IIIcS8cByHnp4eRkZGFrori04kEqG1tXWP8+lKYCeEEEKIeTEe1DU3N+Pz+aQoAKPBbiaToa+vD4C2trY9Op8EdkIIIYSYc5ZllYK6WCy20N1ZVLxeLwB9fX00Nzfv0bSsbJ4QQgghxJwbX1Pn8/kWuCeL0/jzsqdrDyWwE0IIIcS8kenX6mbreZHATgghhBCiTkhgJ4QQQoi91v3334+iKHO+U/eiiy7irLPOmtNrgAR2Qog6YVo58oUB0tnXyeS2ky8OYds2juNQNBNk891kctspFIexbcmfJcRi09/fz6WXXsry5ctxu920trayYcMGHnrooTm97nHHHUd3dzfhcHhOrzNfZFesEGLJK5oJhhNPMBD/I45jAaBrQTqbz0VVXWztuQXTSgKgKBpNkRNpCB2BrskibiEWi3POOYdCocDNN9/M6tWr6e3t5d5772VwcHC3zuc4DpZloetThzoul4vW1tbdusZiJCN2QoglL53dQv/I/aWgDsC0krze8wNMK1kK6gAcx6Jv+F4yudcXoqtCiCpGRkb44x//yH/8x39w0kknsWLFCt7whjdw5ZVX8o53vIMtW7agKApPPvlk2X0UReH+++8Hdk6p3nnnnRx55JG43W6++93voigKL774Ytn1vvrVr7LPPvuU3W9kZIREIoHX6+XOO+8su/1tt91GMBgkk8kAsG3bNs477zwikQjRaJQzzzyTLVu2lG5vWRZXXHEFkUiEWCzGJz/5SRzHmf0nrgoJ7IQQS1qhOMLAyB+rtjlOkWxuB153e0Vb39B9FM30XHdPCDENgUCAQCDA7bffTj6f36NzffrTn+baa6/lhRde4Nxzz+Woo47ihz/8YdltfvjDH/K+972v4r6hUIi3ve1t3HLLLRW3P+uss/D5fBSLRTZs2EAwGOSPf/wjDz30EIFAgLe85S0UCgUA/uu//oubbrqJ7373u/zpT39iaGiI2267bY8e13RJYCeEWNIcbPLF2lM1BXMIXQtVHM8XhwBzDnsmhJguXde56aabuPnmm4lEIhx//PF85jOf4emnn57xua6++mpOPfVU9tlnH6LRKBs3buRHP/pRqf3ll1/m8ccfZ+PGjVXvv3HjRm6//fbS6FwikeA3v/lN6fY/+clPsG2bb3/72xx88MEccMABfO9732Pr1q2l0cOvfe1rXHnllZx99tkccMAB3HjjjfO2hk8COyHEkqag4TYaa7a7jBhFM15x3G3EUGSZsRCLxjnnnENXVxe/+tWveMtb3sL999/PEUccwU033TSj8xx11FFl/37Pe97Dli1beOSRR4DR0bcjjjiCtWvXVr3/W9/6VgzD4Fe/+hUAv/jFLwiFQpxyyikAPPXUU7zyyisEg8HSSGM0GiWXy/Hqq68Sj8fp7u7mmGOOKZ1T1/WKfs0VCeyEEEuaywjT1PB3VdtUxcDrbidX6K5oa46+GV33z3X3hBAz4PF4OPXUU/nsZz/Lww8/zEUXXcTnP/95VHU0XJm4Tq1WhQa/v/zvurW1lZNPPrk0vXrLLbfUHK2D0c0U5557btnt3/3ud5c2YaRSKY488kiefPLJsp+XX3656vTufJPATgix5HndnbRET0FRdo7AGXqYFa3nY6ghDH3nFIiiGLTGNuDzLFuIrgohZmDdunWk02mampoA6O7e+SVt4kaKXdm4cSM/+clP2LRpE6+99hrvec97dnn7u+66i+eee4777ruvLBA84ogj+Nvf/kZzczP77rtv2U84HCYcDtPW1sajjz5auo9pmjz++OPT7u+ekHkIIcSS5zLCNASPIuhbi2mlURQNXfPhMhoAWNV+MaaVBsdC0/zoWgBVlbc/IRaLwcFB3vWud/H3f//3HHLIIQSDQf7yl79w3XXXceaZZ+L1ejn22GO59tprWbVqFX19fVx11VXTPv/ZZ5/NpZdeyqWXXspJJ51Ee3vlhqqJTjjhBFpbW9m4cSOrVq0qm1bduHEjX/7ylznzzDO5+uqr6ezs5PXXX+fWW2/lk5/8JJ2dnXz4wx/m2muvZc2aNaxdu5avfOUrc54AedyCjtj927/9G4qilP1MnPPO5XJcdtllxGIxAoEA55xzDr29vWXn2Lp1K2eccQY+n4/m5mY+8YlPYJqyIFqIvY2muXG7Yvi9y/F5OkpBHYChB/G6W/F6OnAZEQnqhFhkAoEAxxxzDF/96lc54YQTOOigg/jsZz/LJZdcwje+8Q0Avvvd72KaJkceeSQf+chH+OIXvzjt8weDQd7+9rfz1FNPTTkNO05RFN773vdWvb3P5+PBBx9k+fLlpc0RF198MblcjlBodKPWxz72Mc4//3wuvPBC1q9fTzAY5J3vfOcMnpHdpzjzlVilin/7t3/j5z//Offcc0/pmK7rNDaOLoS+9NJL+c1vfsNNN91EOBzm8ssvR1XVUhZqy7I47LDDaG1t5ctf/jLd3d1ccMEFXHLJJXzpS1+adj8SiQThcJh4PF76pQghhBBi9uRyOTZv3syqVavweDwL3Z1FZ6rnZyZxyoJ/bdV1vWrG53g8zne+8x1uueUWTj75ZAC+973vccABB/DII49w7LHH8vvf/57nn3+ee+65h5aWFg477DC+8IUv8KlPfYp/+7d/w+VyzffDEUIIIYRYMAu+eeJvf/sb7e3trF69mo0bN7J161YAHn/8cYrFYml7McDatWtZvnw5mzZtAmDTpk0cfPDBtLS0lG6zYcMGEokEzz33XM1r5vN5EolE2Y8QQgghxFK3oIHdMcccw0033cRdd93FN7/5TTZv3syb3vQmkskkPT09uFwuIpFI2X1aWlro6ekBoKenpyyoG28fb6vlmmuuKe1cCYfDLFsmu+OEEEIIsfQt6FTs6aefXvr/Qw45hGOOOYYVK1bw05/+FK/XO2fXvfLKK7niiitK/04kEhLcCSGEEGLJW/Cp2IkikQj77bcfr7zyCq2trRQKhYrtwb29vaU1ea2trRW7ZMf/XW3d3ji3200oFCr7EUIIIYRY6hZVYJdKpXj11Vdpa2vjyCOPxDAM7r333lL7Sy+9xNatW1m/fj0A69ev55lnnqGvr690m7vvvptQKMS6devmvf9CCCGEEAtpQadiP/7xj/P2t7+dFStW0NXVxec//3k0TeO9730v4XCYiy++mCuuuIJoNEooFOJDH/oQ69ev59hjjwXgtNNOY926dZx//vlcd9119PT0cNVVV3HZZZfhdrsX8qEJIYQQQsy7BQ3stm/fznvf+14GBwdpamrijW98I4888kipdMhXv/pVVFXlnHPOIZ/Ps2HDBm644YbS/TVN49e//jWXXnop69evx+/3c+GFF3L11Vcv1EMSQgghhFgwC5qgeLGQBMVCCCHE3JIExVObrQTFi2qNnRBCCCHEUnP99dezcuVKPB4PxxxzDH/+858XrC8S2AkhhBBC7Kaf/OQnXHHFFXz+85/nr3/9K4ceeigbNmwo29g5nySwE0IIIURdiFsWmwsFns7l2FwoELesOb/mV77yFS655BI+8IEPsG7dOm688UZ8Ph/f/e535/za1Sx4rVghhBBCiD3VY5p8tr+fh7PZ0rHjvV6ubmqiVZ+bcKdQKPD4449z5ZVXlo6pqsopp5xSKn8632TETgghhBBLWtyyKoI6gIeyWT7X3z9nI3cDAwNYllW1vOlUpU3nkgR2QgghhFjShiyrIqgb91A2y9A8TMkuFhLYCSGEEGJJS9r2HrXvrsbGRjRNq1redKrSpnNJAjshhBBCLGlBdepwZlftu8vlcnHkkUeWlT+1bZt77723VP50vsnmCSGEEEIsaVFN43ivl4eqTMce7/US1bQ5u/YVV1zBhRdeyFFHHcUb3vAGvva1r5FOp/nABz4wZ9ecigR2QgghhFjSwprG1U1NfK6/vyy4G98VG57DwO7d7343/f39fO5zn6Onp4fDDjuMu+66q2JDxXyRwE4IIYQQS16rrvPl5maGLIukbRNUVaKaNqdB3bjLL7+cyy+/fM6vMx0S2AkhhBCiLoTnKZBbzGTzhBBCCCFEnZDATgghhBCiTkhgJ4QQQghRJySwE0IIIYSoExLYCSGEEELUCQnshBBCCCHqhAR2QgghhBB1QgI7IYQQQog6IYGdEEIIIUSdkMBOCCGEEGI3Pfjgg7z97W+nvb0dRVG4/fbbF7Q/EtgJIYQQQuymdDrNoYceyvXXX7/QXQGkVqwQQggh6oRpZbGsNJadQ1M9aJofXfPO6TVPP/10Tj/99Dm9xkxIYCeEEEKIJa9oxtnR/yvS2ddKx/zefehoejuGHl7Ans0vmYoVQgghxJJmWtmKoA4gnX2VHf13YFrZBerZ/JPATgghhBBLmmWlK4K6censq1hWep57tHAksBNCCCHEkmbZuT1qrycS2AkhhBBiSdNUzx611xPZPCGEEEKIJU3T/Pi9+5DOvlrR5vfug6b55+zaqVSKV155pfTvzZs38+STTxKNRlm+fPmcXbcWGbETQgghxJKma146mt6O37tP2fHxXbFzmfLkL3/5C4cffjiHH344AFdccQWHH344n/vc5+bsmlORETshhBBCLHmGHqaz+Zx5z2N34okn4jjOnF5jJiSwE0IIIURd0DXvnAdyi51MxQohhBBC1AkJ7IQQQggh6oQEdkIIIYQQdUICOyGEEEKIOiGBnRBCCCHmzWLaQbqYzNbzIoGdEEIIIeacYRgAZDKZBe7J4jT+vIw/T7tL0p0IIYQQYs5pmkYkEqGvrw8An8+HoigL3KuF5zgOmUyGvr4+IpEImqbt0fkksBNCCCHEvGhtbQUoBXdip0gkUnp+9oQEdkIIIYSYF4qi0NbWRnNzM8VicaG7s2gYhrHHI3XjJLATQgghxLzSNG3WAhlRTjZPCCGEEELUCQnshBBCCCHqhAR2QgghhBB1QgI7IYQQQog6IYGdEEIIIUSdkMBOCCGEEKJOSGAnhBBCCFEnJLATQgghhKgTEtgJIYQQQtQJCeyEEEIIIeqEBHZCCCGEEHVCAjshhBBCiDohgZ0QQgghRJ2QwE4IIYQQok5IYCeEEEIIUScksBNCCCGEqBMS2AkhhBBC1AkJ7IQQQggh6sSiCeyuvfZaFEXhIx/5SOlYLpfjsssuIxaLEQgEOOecc+jt7S2739atWznjjDPw+Xw0NzfziU98AtM057n3QgghhBALb1EEdo899hjf+ta3OOSQQ8qOf/SjH+WOO+7gZz/7GQ888ABdXV2cffbZpXbLsjjjjDMoFAo8/PDD3Hzzzdx000187nOfm++HIIQQQgix4BY8sEulUmzcuJH//d//paGhoXQ8Ho/zne98h6985SucfPLJHHnkkXzve9/j4Ycf5pFHHgHg97//Pc8//zw/+MEPOOywwzj99NP5whe+wPXXX0+hUFiohySEEEIIsSAWPLC77LLLOOOMMzjllFPKjj/++OMUi8Wy42vXrmX58uVs2rQJgE2bNnHwwQfT0tJSus2GDRtIJBI899xz8/MAhBBCCCEWCX0hL/7jH/+Yv/71rzz22GMVbT09PbhcLiKRSNnxlpYWenp6SreZGNSNt4+31ZLP58nn86V/JxKJ3X0IQgghhBCLxoKN2G3bto0Pf/jD/PCHP8Tj8czrta+55hrC4XDpZ9myZfN6fSGEEEKIubBggd3jjz9OX18fRxxxBLquo+s6DzzwAF//+tfRdZ2WlhYKhQIjIyNl9+vt7aW1tRWA1tbWil2y4/8ev001V155JfF4vPSzbdu22X1wQgghhBALYMECuze/+c0888wzPPnkk6Wfo446io0bN5b+3zAM7r333tJ9XnrpJbZu3cr69esBWL9+Pc888wx9fX2l29x9992EQiHWrVtX89put5tQKFT2I4QQQgix1C3YGrtgMMhBBx1Udszv9xOLxUrHL774Yq644gqi0SihUIgPfehDrF+/nmOPPRaA0047jXXr1nH++edz3XXX0dPTw1VXXcVll12G2+2e98ckhBBCCLGQFnTzxK589atfRVVVzjnnHPL5PBs2bOCGG24otWuaxq9//WsuvfRS1q9fj9/v58ILL+Tqq69ewF4LIYQQQiwMxXEcZ6E7sdASiQThcJh4PC7TskIIIYRYVGYSpyx4HjshhBBCCDE7JLATQgghhKgTEtgJIYQQQtQJCeyEEEIIIeqEBHZCCCGEEHVCAjshhBBCiDohgZ0QQgghRJ2QwE4IIYQQok5IYCeEEEIIUScksBNCCCGEqBMS2AkhhBBC1AkJ7IQQQggh6oQEdkIIIYQQdUICOyGEEEKIOiGBnRBCCCFEnZDATgghhBCiTkhgJ4QQQghRJySwE0IIIYSoExLYCSGEEELUCQnshBBCCCHqhAR2QgghhBB1QgI7IYQQQog6IYGdEEIIIUSdkMBOCCGEEKJOSGAnhBBCCFEnJLATQgghhKgTEtgJIYQQQtQJCeyEEEIIIeqEBHZCCCGEEHVCAjshhBBCiDohgZ0QQgghRJ2QwE4IIYQQok5IYCeEEEIIUScksBNCCCGEqBMS2AkhhBBC1AkJ7IQQQggh6oQEdkIIIYQQdUICOyGEEEKIOiGBnRBCCCFEnZDATgghhBCiTkhgJ4QQQghRJySwE0IIIYSoExLYCSGEEELUCQnshBBCCCHqhAR2QgghhBB1QgI7IYQQQog6IYGdEEIIIUSdkMBOCCGEEKJOSGAnhBBCCFEnJLATQgghhKgTEtgJIYQQQtQJCeyEEEIIIeqEBHZCCCGEEHVCAjshhBBCiDohgZ0QQgghRJ2QwE4IIYQQok5IYCeEEEIIUScksBNCCCGEqBMS2AkhhBBC1AkJ7IQQQggh6oQEdkIIIYQQdWJBA7tvfvObHHLIIYRCIUKhEOvXr+fOO+8stedyOS677DJisRiBQIBzzjmH3t7esnNs3bqVM844A5/PR3NzM5/4xCcwTXO+H4oQQgghxIJb0MCus7OTa6+9lscff5y//OUvnHzyyZx55pk899xzAHz0ox/ljjvu4Gc/+xkPPPAAXV1dnH322aX7W5bFGWecQaFQ4OGHH+bmm2/mpptu4nOf+9xCPSQhhBBCiAWjOI7jLHQnJopGo3z5y1/m3HPPpampiVtuuYVzzz0XgBdffJEDDjiATZs2ceyxx3LnnXfytre9ja6uLlpaWgC48cYb+dSnPkV/fz8ul2ta10wkEoTDYeLxOKFQaM4emxBCCCHETM0kTlk0a+wsy+LHP/4x6XSa9evX8/jjj1MsFjnllFNKt1m7di3Lly9n06ZNAGzatImDDz64FNQBbNiwgUQiURr1E0IIIYTYW+gL3YFnnnmG9evXk8vlCAQC3Hbbbaxbt44nn3wSl8tFJBIpu31LSws9PT0A9PT0lAV14+3jbbXk83ny+Xzp34lEYpYejRBCCCHEwlnwEbv999+fJ598kkcffZRLL72UCy+8kOeff35Or3nNNdcQDodLP8uWLZvT6wkhhBBCzIcFD+xcLhf77rsvRx55JNdccw2HHnoo//3f/01rayuFQoGRkZGy2/f29tLa2gpAa2trxS7Z8X+P36aaK6+8kng8XvrZtm3b7D4oIYQQQogFsOCB3WS2bZPP5znyyCMxDIN777231PbSSy+xdetW1q9fD8D69et55pln6OvrK93m7rvvJhQKsW7duprXcLvdpRQr4z9CCCGEEEvdgq6xu/LKKzn99NNZvnw5yWSSW265hfvvv5/f/e53hMNhLr74Yq644gqi0SihUIgPfehDrF+/nmOPPRaA0047jXXr1nH++edz3XXX0dPTw1VXXcVll12G2+1eyIcmhBBCCDHvFjSw6+vr44ILLqC7u5twOMwhhxzC7373O0499VQAvvrVr6KqKueccw75fJ4NGzZwww03lO6vaRq//vWvufTSS1m/fj1+v58LL7yQq6++eqEekhBCCCHEgll0eewWguSxE0IIIcRitSTz2AkhhBBCiD0jgZ0QQgghRJ2QwE4IIYQQok5IYCeEEEIIUScksBNCCCGEqBMS2AkhhBBC1AkJ7IQQQggh6oQEdkIIIYQQdUICOyGEEEKIOiGBnRBCCCFEnZDATgghhBCiTkhgJ4QQQghRJySwE0IIIYSoExLYCSGEEELUid0O7F599VWuuuoq3vve99LX1wfAnXfeyXPPPTdrnRNCCCGEENO3W4HdAw88wMEHH8yjjz7KrbfeSiqVAuCpp57i85///Kx2UAghhBBCTI++O3f69Kc/zRe/+EWuuOIKgsFg6fjJJ5/MN77xjVnrnBALzXEcTCsFOGiqF1U1ABg0TQYsiz7LolnTaNQ0YvrUf061zlWLZecxrTTF4jCKYmDoYQx99O+taCYxrTi2XcQwGtA1P5rqno2HLIRYhAbG3nMGLIumab7niL3Tbr0qnnnmGW655ZaK483NzQwMDOxxp4RYDIpmknjqGYYSf8a2C/i9+9LccAJxJcSHevt4tlAo3Xaty8XXW1roMKoHa5PPFfCtoSnyJlxGFEWpHDg3rTQDI5sYjD8MOACoqocVLe/Hoci23p9g2bmxWyvEwutpDB+Hrvtn+2kQQiywHcUi/9Lby4sT3nMOdrv5SnMz7TXec8Tea7emYiORCN3d3RXHn3jiCTo6Ova4U0IstKKZZFvvz+gdupuiGceysyTSz/Dqjv+haA6xpVgsu/2LhQIf7+tjyLKmda546mle3fE/5IuDVa+fyrzGYPwhxoM6ANvOYTlZXu/+wYSgDsBhMP4wqewrs/HQhRCLyJBlcUVfX1lQB/BMPs+/9vczUuU9R+zddiuwe8973sOnPvUpenp6UBQF27Z56KGH+PjHP84FF1ww230UYt7lCwNk89sqjjtOkXz8Ad4V9FS0PZ3PM1zlTXaqc/UN34dl58uOF80U/SMPVNze6+4gk9uKQ/U38v7hByiaqZqPSQix9AxZFs/m81Xb/pzLVX3PEXu33QrsvvSlL7F27VqWLVtGKpVi3bp1nHDCCRx33HFcddVVs91HIeZdPP1szbZc5mXe6Kn+p5Oy7RmdK5V+Gbts9A3AplgcqbitrgUompXHxxXMEagR9AkhlqZq7ykzaRd7nxmvsXMch56eHr7+9a/zuc99jmeeeYZUKsXhhx/OmjVr5qKPQsw7TXXVbFMUg4JTvS2sVgZ8uzoXKJOO6bhdzeQK5csdCuYw4cDBNc/lcTWjKLKYWoh6Uu09ZZwKhKZoF3un3Qrs9t13X5577jnWrFnDsmXL5qJfQiyocOAQBuOPVG3zBQ7n9nTlyNibfT6imjajczWEjkBTyzc86JqPlugpvN7zf2XH84U+PK4WNNUzaY3dqOboKeiabJ4Qop5ENY2TvF7+kM1WtL3V7ydW5T1H7N1mHOqrqsqaNWsYHKy+6FuIemDoEWLh4yuOu4wYzZFj8Kk642+nGvC2QIB/bWwkVOVNdqpzxULHoKqV9/G62+hoOgtN9ZaOuY0mDC3CyvYP4DaaS8c11UN705n43J0zf6BCiEUtrGl8tqmJt/r9pQ9sDTgrEOBjsRgBCezEJIrjODUmlWq74447uO666/jmN7/JQQcdNBf9mleJRIJwOEw8HicUCi10d8QiYVpZCsUhhpOPY1lZwoGD8HmWYegh0rbNoGWRtm38qkpM0/BPMSUy1blqcRwb00piWhkURUNXfeh6YPR8ZhrTzuA4Jprqw9CDVdOmCCHqw+T3nEZNwyfTsHuNmcQpuxXYNTQ0kMlkME0Tl8uF1+stax8aGprpKReUBHZiKo7j4OCgzkLgNJvnEkIIsXeYSZyyWyutv/a1r+3O3YRYkhRFQZm0wWExnEsIIYSYbLcCuwsvvHC2+yGEmIFhy2LYsjAdh5Cm0axpqIoEjGJhOI5N0UphW1kURUPTfOiab6G7JcReaY9zI+RyOQqTMmLLdKYQc+fVQoEr+/p4buzvLqqqXNnYyJu8XoKykFrMM8vKkcz+jZ6Bu7DsDAAedzsdTWfhcTUtcO+E2Pvs1kKfdDrN5ZdfTnNzM36/n4aGhrIfIcTc6CoWuaCrqxTUAQzZNp/o66uZnV6IuZTN72BH362loA4gl+9iS9dNFKok2hZCzK3dCuw++clPct999/HNb34Tt9vNt7/9bf793/+d9vZ2vv/97892H4UQYx7N5RipkWn+v4aGpLyQmFemlaF36J6qbZadIZN7fZ57JITYranYO+64g+9///uceOKJfOADH+BNb3oT++67LytWrOCHP/whGzdunO1+CiGAx6okKR33cqFAfuab3IXYbY5dJFfordmezm0hEjx0HnskhNitEbuhoSFWr14NjK6nG09v8sY3vpEHH3xw9nonhCizr6t2ebI2fWfSZCHmhaJOmYvRbcgaOyHm224FdqtXr2bz5s0ArF27lp/+9KfA6EheJBKZtc4JIcqd4vdj1Gj7x0iEJl1qxYr5Y+hBmiInVG1TUAn6185zj4QQMwrsXnvtNWzb5gMf+ABPPfUUAJ/+9Ke5/vrr8Xg8fPSjH+UTn/jEnHRUCAGtmsY3W1vxT0htogDvC4U40S91YsX8C/r3Jxo6uuyYqrhY3roRQwsvUK+E2HvNqPKEpml0d3fT3Dxap/Ld7343X//618nlcjz++OPsu+++HHLIIXPW2bkilSfEUmI6Dv2myTbTJG3brDYMopomqU7EgrGsHKaVplAcQFXdGHpkrMydvCaFmA1zVlJMVVV6enpKgV0wGOSpp54qrbdbqiSwE0IIIcRiNZM4RQpWCiGEEELUiRkFdoqioEwqWzT530IIIYQQYmHMaAud4zhcdNFFuN1uYLSc2D/90z/hn7Ro+9Zbb529HgohhBBCiGmZUWB34YUXlv37/e9//6x2RgghhBBC7L4ZBXbf+9735qofQixall0Ax0ZV3bL0YC/iOA62nQdFRVNrJ4beU/L6EkLMJslmKkQNppkiW+hhMP4Itp0n5D+AkH8dLiOy0F0Tc6xQHCGRfoFE+nlU1UUsfCxeVzu6Pnu5Ak0zRTbfzWDiEWy7QNh/IEH/Wnl9CSH2iAR2QlRhWml6hu4mnnq6dCyb385g/BFWtX8Al9GwgL0Tc6lQHGZz1/cwrWTpWDr7GmH/wbQ2bkDX9jy4M600PYO/I55+tnQsm9/OQHwTq9ovkteXEGK3SboTIaooFEfKgrpxppVkYORP2La5AL0Sc822TQZGHioL6sbF089QKA7PynUKxaGyoG6caSUYiG+S15cQYrdJYCdEFfHUUzXbRlLPYNmZeeyNmC+Wnaka0I+LJ2u3zcRw8skpryGvLyHE7pLATogqpi7IYs9bP8T8c6j9u7dn7Xcvry8hxNyQwE6IKiLBg2u2hfwHoaneeeyNmC+a6iXsP7BmeyQ4O7WwI4FDa7bJ60sIsScksBOiCpceJejbv+K4pnppajgBVTUWoFdirqmqQVPDCVUDq4BvP9x6dFau4zZiBHxrKo5rqo+mhjfK60sIsdsUZ+o5p73CTIrrir1H0UyRyb3OYHwTtp0n6F9LQ/AIDD0i+cbqXKE4zHDyCZLpF1BVN7Hwsfg8KzD04Kxdo2imSOe2MDSWTifoP4CG4OGyI1YIUWEmcYoEdkhgJ6ZmWlnARlU9qIq20N0R88RxLCw7B6jo2txNjY6/vjTVgyKvLyFEFTOJUySPnRC7MJcf6mLxUhRtVnLW7Yq8voQQs0nW2AkhhBBC1AkZsRN1x7ILWFYaBwdNcaHrgYXu0qI2bFkMWxZFxyGsaTRpGtou1hCaZhrLyaOgoGn+Oa2lujdyHJuilcRxTBR0DD2Iosj3cCHErklgJ+pKoThM79C9JNLPAw5uo4m2xrficbdL8FHFK4UCV/b18XyhAEBUVfl0YyMneL0Etcr1XpZdJJfvonvgt+SLfYBCyL+Wluipsuh/lphmiuHkkwzGH8Kyc2iql8bI8YQDh2HMYq1aIUR9kq+Aom4UzQRbur9PIv0c4wlg88V+tnTfTL7Qt7CdW4R2FItc0NVVCuoAhmybT/b18eyEYxMVCn2jz2dx/Pl0SKRfYEv3zRTN+Dz0ur5Zdp7+kT/RN3zv2MYNsOwsvUP3MBh/CNuu/nsRQohxEtiJupHN7aBojlRt6xn8/djuQzHuz7kccbt6lYP/Ghxk2LLKjplWlp6he6hWNaFoxsnkts9FN/cqlpVmKPHnqm2D8UcxrfQ890gIsdRIYCfqRjL7t5pt2fx2HBntKPNYtnag+3KhQH5SJiTHKZDNba15n2T65Vnr297KtDLULjdmj7ULIURtEtiJumHo4ZptuuYDWXxeZl9X7TWH7bpO5Qo7FW2K9B+GUfv5F9OjKlNXnFAVWRYthJiafNKJujFVjc9YeD26JrtjJ3qz30+tMOIfIxGa9PIgQtcCxMLra54vHKhdX1dMj6b5cRmxqm1uo2le8uoJIZY2CexE3TD0EB1N7wTKU3UEvPsSDhwiZcAmadM0vtnain/C86IAG0Mh/s5fGUAoikI4cBAB336TW+hoOgtDl6ote8rQAyxreXdFAKdrATpb3iWpe4QQu7SgJcWuueYabr31Vl588UW8Xi/HHXcc//Ef/8H+++8svp7L5fjYxz7Gj3/8Y/L5PBs2bOCGG26gpaWldJutW7dy6aWX8oc//IFAIMCFF17INddcg65Pb9pCSorVD8suYlpJMrmtWFYWv3clhh6SkY4aTMehzzTZYZqkbZtVLhdRVa2a6qR0HytN0UyQzm5BUz34vCvQtYCkk5lFhWKcfLGPfKEft6sZj9EkU91C7MWWTEmxBx54gMsuu4yjjz4a0zT5zGc+w2mnncbzzz+Pf2zE4KMf/Si/+c1v+NnPfkY4HObyyy/n7LPP5qGHHgLAsizOOOMMWltbefjhh+nu7uaCCy7AMAy+9KUvLeTDEwtAUw00NYrbiC50V5YEXVFoNwzajanXdpXdR/Oja3687rY57NnezWWEcRlhgr41C90VIcQSs6AjdpP19/fT3NzMAw88wAknnEA8HqepqYlbbrmFc889F4AXX3yRAw44gE2bNnHsscdy55138ra3vY2urq7SKN6NN97Ipz71Kfr7+3FNsUB8nIzYCSGEEGKxmkmcsqjW2MXjowlOo9HR0ZbHH3+cYrHIKaecUrrN2rVrWb58OZs2bQJg06ZNHHzwwWVTsxs2bCCRSPDcc8/NY++FEEIIIRbWotk7b9s2H/nIRzj++OM56KCDAOjp6cHlchGJRMpu29LSQk9PT+k2E4O68fbxtmry+Tz5fL7070QiMVsPQwghhBBiwSyaEbvLLruMZ599lh//+Mdzfq1rrrmGcDhc+lm2bNmcX1MIIYQQYq4tisDu8ssv59e//jV/+MMf6OzsLB1vbW2lUCgwMjJSdvve3l5aW1tLt+nt7a1oH2+r5sorryQej5d+tm3bNouPRgghhBBiYSxoYOc4Dpdffjm33XYb9913H6tWrSprP/LIIzEMg3vvvbd07KWXXmLr1q2sXz+aKHX9+vU888wz9PXtLPJ+9913EwqFWLduXdXrut1uQqFQ2Y8QQgghxFK3oGvsLrvsMm655RZ++ctfEgwGS2viwuEwXq+XcDjMxRdfzBVXXEE0GiUUCvGhD32I9evXc+yxxwJw2mmnsW7dOs4//3yuu+46enp6uOqqq7jssstwu90L+fCEEEIIIebVgqY7qVUJ4Hvf+x4XXXQRsDNB8Y9+9KOyBMUTp1lff/11Lr30Uu6//378fj8XXngh1157rSQoFkIIIcSSN5M4ZVHlsVsoEtgJIYQQYrFasnnshBBCCCHE7pPATgghhBCiTkhgJ4QQQghRJySwE0IIIYSoExLYCSGEEELUCQnshBBCCCHqhAR2QgghhBB1QgI7IYQQQog6IYGdEEIIIUSdkMBOCCGEEKJOSGAnhBBCCFEnJLATQgghhKgTEtgJIYQQQtQJCeyEEEIIIeqEBHZCCCGEEHVCX+gOCCHqm+M4FM04uXw32UI3XlcbHncbhh5GUZSF7l5dsOw8ppkklX0Fy8oT8O2DS4+g64GF7poQYp5JYCeEmFP5Qh9bum/GsrOlY5rqZWXbhXjcLQvYs/pg2XniyafpHvxt6Vj/yP34PavpaD4LQw8uYO+EEPNNpmKFEHOmaCbZ1vvTsqAOwLKzbOv9CUUztUA9qx9FM14W1I1L514jnnoGx3EWoFdCiIUigZ0QYs6YVpqCOVS1rWAOY1oS2O2pkeRTNdsG44/IcyzEXkYCOyHEnHEcaxft5jz1pH6ZZrJmm2VncJAROyH2JhLYCSHmjK75UGq8zSio6Jp/nntUf4L+tTXbfJ6VaIprHnsjhFhoEtgJIeaMrvmJhY+r2hYNr5fAbhb4PJ0YekOVFoWW6Clommfe+ySEWDgS2Akh5oyquoiFj6Ut9lZ0bTT1hq4FaIu9lcbwelRVRpP2lKGHWNl2AZHAoaXRUa+7g1XtF+M2Ghe4d0KI+aY4smWKRCJBOBwmHo8TCoUWujtC1B3HcTCtJI5joSgauhZc1DnscrbNgGUxaFkYikJM02jWtCn7bFoZTCuNbedQVQ+65kfXfPPWZ9suYlppwEFV3fN67Xoy8feoqV40zY+ueRe6W2IvN5M4RfLYzTPbNrHsDACa6kNVd/4KMrZNwrZRgZimoS3iDz4xu0wrg+OYY0HPnk1PDlsWecfBrSg0aNos9XDPKIqCoS+NL03DlsXPEgluGB6mOHasSdP4WksLB7nd6FX+LovFONv7byOTe710zOdZSWfTWRhGeF76raoGLjUyL9eqV4VinB0Vv8dVdDafiaHPz+9RiD0lI3bM34hdoTjCYPxR4qmnAIdQ4GAaw+vR9Ahbi0W+OTzMA5kMXlXl3cEgZ4dCtOgSe9cz08qSze+gb+g+8sUB3EaM5uhJeN3LZjxKELcsns7n+e+hIbYUi6wwDD4cjXKo2014kQR4S8HvUimu6OurOO5RFG7v7GSZYZQdN60s23p/Sia3peI+fs9qOlvOlRGfJcC0MmO/x9cr2vzefelsPlt+j2LBzCROkTV286RQjLOl63sMJR7BsrNYdo7hxGNs7vouueII5+3YwW/SaVKOQ79l8Y2RES7r6aHPlHQQ9cq2TeKpZ9ja80NyhW4cp0iu0MPWnh8RTz2FbRd3fZIxBdvmt6kU/9TTwwuFAlnH4cVCgUt7evhVKkXetufwkdSPQdPk/w0PV23LOQ4PZjIVxy0rVTWog9EkwZaVns0uijliWumqQR1AOvuK/B7FkiGB3TxwHIdE+nmKVqKizbRSDKae5lBP5SLyFwoFXsjn56OLYgGYVoreoXuqtvUO3Tu2Xmp6+i2L/xqqngj4a0NDDFhT55MTo4rA1mLtgPrZKn+Plj313+iu2sXiYNu5Kdvl9yiWCgns5oFl50ikn6vZXsg8z5vc1X8Vd6RSUhKoTplWGsepHkQ4jjmjigFDlkW2xusk5zgMSmA3LQawatJU60SHut0VxzR16nQiu2oXi4OmTj3NKr9HsVRIYDcPFFQUpfaHhaq4yNaI3YKquqh3D4rdpyhTr3vbVftExi5eI7tqF6Nius6Ho9GqbT5F4Y2+yp2mmubH79236n0C3jVosjt1SdA0H37P6qptAe9+knNRLBkS2M0DTXMTCx9Ts90bPJpfZ6qvpTsnGJyrbokFNpoOo/rvV9cCM/ogadA0WmpskGjSNKKyeWLajvR4uDIWwzshGO7QdW5qb6etymYmXfPS0fR2gt41ZceD3v1ob3qbLLhfQpoa3oTfu0/ZsYBvDbHIsVKaTSwZsuVynnjdnQR9a0lmXiw7HvDuS9C7Eleicv3dRaEQnVNMC4mlTdcCLGt5F1u6v19WM1VRdDpb3lUz6KumWdP4SksLF3d3k5swJetWFL7S0kKzBHbTFtY0zgsGOdnnY2gsj11U02iaYoe6oYdobz4by0ph2Xk01YOu+dAkqFsyTCvN1p5biIaPIRZ6A7Zjoio66dzrbO25hX06/lGCdLEkSLoT5i/diWmmyBcHGU7+FRyHSOgI3EYjhh6gzzR5Pp/njlSKoKpybjBIp2EQkQ/kuuY4FkUzTiL9Apn8DryudsKBdeh6GHUGU7EApuPQbZrcnU7zdD7PwW43p/n9tOl61dxrQoidMrltbO76bs32Ve3/gM/TMY89EmInSVC8SOl6AF0P4PMsByhbO9es6zTrOif4fKjyIbzXUBQNlxGlMXI8juPs0XpKXVFYZhj8fSSC7TjyOhJiBmTzhKgXssZuASiKUvMDXD6M916zuUlGXkdCzIym+fF7VlVtC3r3kxJtYsmQwE4IIcReT9e8dDSfid9bvjM26F1DW9MZsl5SLBkyFSvEAuszTbabJlsLBZa7XHToupSS2w2mlcW0UuTyXaiqB4+rubQBxbSS5Aq92HYej7t9bNexfFCLcoYeprP5XCwrPbYJxo2mBdA1mYYVS4d8egixgLYWi3ywu5ttE0rHdeg6/9vWxgrZET1tppmiZ+hu4qmnS8cURWNF6/lYVobt/b/AcXYmaQ4HDqE1eiq6HpiV6zuOTdGMk0y/TCa/HZ+nk6BvPww9jGmlyeV7SKSfQ9W8RAKH4tLDdTcCZFpZbDuPoihoqh9VXZofL7rmlaBfLGlL8y9PiDowZJp8tLe3LKgD2GGafKS3l2+3thKTkbtdGi3Z90JZUDd63MZ2Cmzr+xlMykEWTz2Nz7OMhuCRe7y20XEcsvmusbQ1o5VEEuln6Ru6j9Udl7Ct7+fkC72l2w/FH6Gp4URioTfURXBn2yb5Yh89A3eRyW9DUXQiwcNpDB+PywgvdPeE2OvIGjshFsiQbfNioVC17eVCgSHbnuceLU2mlWIg/lDFcZ9nOensZiYHdeMGRv40o7Jtta+fZFvvzyrKw/m8KxhK/KUsqBvXP3w/BTO+x9deDPLFAV7b8R0y+W3AaDm84cRjbO35AUWzMj+nEGJuSWAnxALJ7iJwy0hgN00ORTNZcVRTvZhVjo8bbdvz59i00phWZQAT8h9QMYo40VRtS4VlZekd/D3Vnsd8cYBcvmf+OyXEXk4COyEWSFjTqJWCWGW0TJjYNUXR8brbKo4XigN43O017+dxt09Zw3m6HKd6cKgqOradr3k/y87u8bUXmu0USOe21GxPTKq0I4SYexLYCbFAYprG2TVqAb8jECCqyp/ndOiaj5bYaRXH88UB3EasZs3dltips5KbTNd8KErlWshMbkdF6oyJQv4D9/jaC0+ZMnGvrs3O5hQhxPTJJ4cQC8Svqlze0MA/hMOlgvMeReGicJiPRqMEZMRu2jyuFpa3vBdD37lY3+dZhcvVxMr2D+CbkHjW0MMsb3kvHlfLrFxb0wI0N5xYcXwk9SRNDSdUDfo8rrZZu/5C0rUA0dAbaraHAwfNY2+EECC1YoH5qxUrRDUF26bfssg5Dh5FoUnTcMlo3W4pmkksO4eiqGiqr5S2wrSyWFYGBxtN9WDo1UdKd5dpZcjkXqdv6A/ki4O4jRjN0ZPxuZdj2in6hu4jlXkFVXURDR1NQ+hIDL0+3muKZoJtvT8jm99edrw1djqRwCFokgNOiD02kzhFAjsksBNCzA7TTOFgoaCV5cizrDy2M7reTtf8KEp9jcYWzRSF4iDJzMtompeQby26HkRT3QvdNSHqwkziFEmSJYQQs6RWwmNNc6NRv0GOoQcw9AB+74qF7ooQez0J7MS8cRwH0xqbKkNF03y7vXh9Ns8l6l+hmMB2cjiOhaq6MbQIqkx3CyHqkAR2Yl5Ydp5MdgtdA78t5fzyujtpb3oHHlfTjM+Vzm6hexbOJepfLt9L18BvyI4l0NW1IK2xDfg8KzH06jtmhRBiqZKvrGJe5Aq9bO39cVki12x+O1u6bqJQHJnxubbN0rlEfcsXBtnS/f1SUAejlSK2TyrzJYQQ9UICOzHnTCtL7+A9VdssO0M6+9oMzpWhd/DuKc61ebf6KOpTOrsZy85Ubesbvk9KXgkh6o4EdmLOOU6RXKG7Znsq++oMzmWSK9QuUzSTc4n6l8m9XrMtm+/Gccx57I0QQsw9WWMn5pyCiqGFKJhDVdvdxvTXxY2eK0jBHK5xrsbd6uNiZNtFTCuFaaVRFA1d86NrQZSxZMZLiWllMK00tp1DVT1jj2XuN7sYRrR2mx7CYek9l2JujVgWQ5ZFwrYJqSpRTSMiycLFEiKBnZhzuh6gMfImugZ+WaVVmVF2+p3n+tUen2sxM60Mw4m/0j9yP45jAaNZ/pe1nIfX3b6k8qAVi3G2999OZkJNUZ9nJZ1NZ2EY4dp3nAXhwIEMjPwRqEzXGQuvx200zOn1xdLSXSxyZX8/j+VypWPrPR6+2NxMqy4fl2JpkKlYMS+Cvn1pCB5VdkxRdJa1vBtdn9mHe9C3hobgkbNyLhhNrprObqFn8Hf0DT1ArtCHZeV2fcc5lMm9Tt/wvaWgDsC0Umzp/j5FM76APZsZ08qwo/9XZUEdQCa3he39v8S0qq9/my26FmJZy7sqynqFA4cS9O0/4/NZVo5coY++4QfoGfwd6ewWimZqtrq7qNmOw45ikduSSb40MMCvkkl2FIvUS477EcuqCOoANuVy/Ft/PwnLqnFPIRYX+Qoi5oWuB2iJvplY+BhyhV5U1YXbaELXAqjqzF6Go+c6hVj42EnnCqKqMxvJKprJsXJIO3dN9o/cT0v0FBqCR5DCxYhtYzoOQVWleR6+tZtmir6hP1RtcxyTRPolGiPr57wfs8GyMqRz1TfHZHKbsazMnE7J6poHv2cf9un4J/LFfiw7h9fVhqb5ZlxWzLJyDCefoHfo96Vjg/FH8Lo7WdbyrropEVbLi4UCF3V1kZ4QyAVVlZva2ljrXvrJl4csqyKoG/fHbJZByyIkU7JiCZDATswbTfOgaR7crj1fBzcb53Icm5Hkk2VB3bjeoXvwePfh44M2D4+92bdqGp9pbOQYr5fAHCa3dbAoFAdrtmfzXXN27dlm2VOPfO6qfTZomgtNi+F2xfboPEUrXhbUjcvmtzOcfJKmyBtRlPqcBOk1Tf6lt7csqANI2jYf6e3l/9rbaVriU5UJ256yPbWLdiEWi/p8FxJiGkwrzVDizzXbBxJPok7YqNBjWfxLby8v5PNz2i9F0XFNEbD6PJ1zev3d5Tg2hWKcTG4rqcyr5ItDaOrUo3GaunQKxI8kn6rZNpz4M6ZVv1OyQ5ZFt1l9B/E202TAsthaLPJwJsMTuRzdxSLmEpuiDe3iy1pQKpWIJWJpf8USYg84jjnliJFip/FWeTP/z6EhbmxtpWGOpmV0zU9Lw8ls7f1xRZuqGAR9+83JdfeEbVtk89vY1vuTCc+pQix8LB3N57Cj7xcV9/F790XTlk7lB9NK12wbXZO5tAKZmSjsIkgbsizO27GD8TGtsKry3y0tHObxYCyRXdxRTWO9x8OmKtOxJ3m9RGUaViwR8hVE7L0UFb9nZc1m07u26ujc8/k8+TmelvF6ltMaewuKYpSOGXqYFW0XYuzGBpG5ZlpxXu/+waRA2WEwvgnHMWkIHl12+4B3DR1Nb0fXvPPb0T0Q8q+r2eb3rkZVlv46s1pimoZRo82tKOQdh4l/EXHb5oM9PTVH+RajiKbxxeZm3uQtf02e5PXy2aYmWV8nlgwZsRN7LQWNaPhY0tnNOJTveHMZMfrURrablaM0LZpWNkU7F3TNS0PwSIK+/bGsNIzlsZvpgv/5kki/WPEcjhsY/iMr2i4gFj4Gy86hqW40LYCuLZ1pWACvuw2X0UihOFB2XEGlJXoy2hJ7PDMR0zQuiUS4YWSkou38UIhfpyqnoQuOw/3pNBdEInPfwVnSqutc19zMoGWRsm2CY3nsJKgTS4kEdmKvZegBsrntLGs5j8H4JtK5LSiKTjhwEOHwG7m4K1n1fv8QidA0D2/0qqrjUiNgROb8WnsqN0Xd1YI5jKKMBstLmaGHWNn6fgbiDzOcfALHKeLzrKI1diquGSTZXoq8qsr7wmE6DINvDA/TbZp06DqXNTTQZ5r8Ll19mvrlYnGee7rnQhLIiSVuQadiH3zwQd7+9rfT3t6OoijcfvvtZe2O4/C5z32OtrY2vF4vp5xyCn/729/KbjM0NMTGjRsJhUJEIhEuvvhiUlW+PQpRjdfTSSr7Gl53B53N76K96R3YtknRzHB1UxPuSSNzZwYCnOL3L8nqD3PJ71lRs83jaimbUl7KDCNMS/RU1iy7jDXLP8KylnfhdbfNOM3OUtSgaZwVDHJLezt3L1vGD9vbOdHn47c1gjqAIzz1O4opxGK1oIFdOp3m0EMP5frrr6/aft111/H1r3+dG2+8kUcffRS/38+GDRvITVjcunHjRp577jnuvvtufv3rX/Pggw/ywQ9+cL4egljiDD1AU8PfEQ4eioOFprhpiZ5M2NPGcV4vd3R2ckNLC9c1NfGrzk4+FYvRuMTTOswFv3c1ao0drs3RU+alfNh8UVUdQw/j0sNLao3gbGnWddoNgyZdJ6xpXBGtXrYtrKocI4GdEPNOcRZJ2nBFUbjttts466yzgNHRuvb2dj72sY/x8Y9/HIB4PE5LSws33XQT73nPe3jhhRdYt24djz32GEcdNVrV4K677uKtb30r27dvp729fVrXTiQShMNh4vE4oVB9JxkVYi44jkO+0Mf2vlvJF/uA0VQmrbENBH1r63r92d4uYVncm8nw5cFB4mObivZzubiuqYl9XS4Z3RZiFswkTlm0Qw+bN2+mp6eHU045pXQsHA5zzDHHsGnTJt7znvewadMmIpFIKagDOOWUU1BVlUcffZR3vvOdVc+dz+fJT9jtmEgk5u6BCLEXUBQFj7uFFW0XYNlpHMdCU0erO9Rr0l4xKqRpvCMQ4FiPhxHbxqUoRFSVmIxsC7EgFu07bk9PDwAtLS1lx1taWkptPT09NDc3l7Xruk40Gi3dppprrrmGcDhc+lm2bNks916IvZOmulAVN5rqQVUNCer2Epqi0GYYHOB2s4/LNa2gznEcimaCQnGYopmsm5qzQiy0vfIr1ZVXXskVV1xR+ncikZDgTog9VCiO0D/8IPHU0zhYeN0dtMZOx+NqRlXrY/OEmB2mlSaReo7+kQcxrTS6FqSp4e8I+dai60snabUQi9Gi/Trd2toKQG9veRqF3t7eUltrayt9fX1l7aZpMjQ0VLpNNW63m1AoVPYjxEyYVpZ8YYBMbjv5wgCmlV3oLgEL16+imeD17v9jJPVEKZ9dNr+DzV3fIT8p75vYu9l2gYGRTXQP3lmq5mFaSboHfs1Q4s/Y9tJLkSLEYrJoR+xWrVpFa2sr9957L4cddhgwOrL26KOPcumllwKwfv16RkZGePzxxznyyCMBuO+++7Btm2OOOWahui7qXNFMsKP/DtLZV0rH/N7VtDe9A9cCVoVYyH5l810UzKEqLQ69g/ewrOVctBnsILXsAqaVIpPdgmXn8XtWYBhh9ClKkJlWmmIxTjr3Oprqxuddia4G0DTXjB9P1XNpATR15ueaTUOmSbdp8udcjpCqcrTXS5OmVS19N1csK4ftFFEVY7c2xZhWisH4pqptAyMPEQkehktt2NNuCrHXWtDALpVK8corOz+ENm/ezJNPPkk0GmX58uV85CMf4Ytf/CJr1qxh1apVfPazn6W9vb20c/aAAw7gLW95C5dccgk33ngjxWKRyy+/nPe85z3T3hErxEyYVrYieAJIZ1+jq++XdLacuyCpPabu16/obDlnTvuVTL9Ysy2d24LtFNCYXmBn2QWS6efZ0f8rJtZfDXjX0N709qrVN4pmkq7+O0hlJ+a5VOhoegdB/wFo6vTLfY2e61ekyp7L8XOtW7Dgrt80+Wx/P3/M7hyFVYH/r6mJN/v9+Oc4uLOsHLlCH/3D95MvDuJ2NdLccCJuo2lGAZ5pZYDqJfkcLEwrg8uQwE6I3bWggd1f/vIXTjrppNK/x9e9XXjhhdx000188pOfJJ1O88EPfpCRkRHe+MY3ctddd+GZkBvphz/8IZdffjlvfvObUVWVc845h69//evz/ljE0mCaqbGpQnW3ynNZVroieBqXzm3GsjILEthN3a/X5rxfulb7uRzN9Tb9lBdFM86O/l8R9O1PyL8WRdHJ5ncwknySeOoZYuH1ZSk0HMchnnpmUlAH4LCj/5fs4+5Ac02vMsTouZ6eFNTt3rlmk+04/CqVKgvqYDQ8+kx/P79yu1ntmruA07YtEpkX6er/ZemYmU2wOfsaHU3vJBQ4EFWZXpJmVZn6Y2dX7UKIqS3oX9CJJ5445U4oRVG4+uqrufrqq2veJhqNcsstt8xF90QdMa0M6exm+obuo2AOYegNNDecRMC3z4wCnvIi9zNvnysL3a9w8GAG4n+q2hYNHYOuBaZ9rkT6BZa3vIdk5mW6B36L7RTxe1fS0fxOhhN/JRw4CEPfuS52qqk9gHjqGTzRk6d17dFzPVK7b6ln8URPqtk+VwYsi+/H41XbHODOVIrLaiQKng2mlaRn4LdV27oHfovfuwJ1mtP9mubH0CMUzZGKNpcRQ5tiul0IsWuLdvOEELPFtouMJJ5ge9/PS+vAiuYwO/pvZSjx2IwWa2s1qitMt32uLHS/VMVNS8MpFcd9nuWE/AfOKO2J191B79A9DCcfx3YKgEM6u5ltPT+hIXRElXvYY9N71ZnmTPJUTn2uolk9uJprNjBsWTXbu8faEpbFsGlizXLqENNKYzvV/05sJ49pTr+Mo6EHWd7y7orXpKZ6WdZyHoY+/S8BQohKMuYt6p5ppekbub9q28DwH4kEDpn2Ym1N8+P37lt12tPnWTUvow2WnadoJkimX8KyMwR9+2PokZr98ntWoe3mNGzKssg6Dh5FIThFYfR8oY9csY/lre8jm9uOZefxeZZhWil6B++mo/nMaa/Dsu08+WJ/xXEHi6H4n2lvOrPsuKK48HmWk8ltqXq+gG+/aV13OueKBA8nV+gnmX4Ry84R9O2Hy4jNeTDiVRSO8Hh4LFd95PVNXi9/TKf51sgIWcfhVL+ftwcCdBizk2ZG2dVU+gzzFbpdLazu+Eey+R3kCr14XK143e24jMjud7KKopmkUBwimXkJTfUR9O+PoYdmtOZSiKVGArslynFsimacZOZlMrnteN1thPxrMfQwyjTXuuwtTCuN45hV20YXa6envVhb17x0NL1tbKPCq6Xjfs8q2pvOnPPaoZaVYyT1FD2Dd5WODcY34fOspKPpHXQN/GZSv1bT3vyOGa+vS1oWrxaLXD88zOZCgZWGwWXRKPsaRtUAL5F+nnjq6dFpT1crqqIzknoS286joGI7eTSmF9glMy/XbEtnNwPlI1e65qUlejKbu77HxM0WAIYexuNum9Z1x8/VGj2F17q+U3GuWPh4svkueod+Xzo2GH8Yr3sZy1retVtrNqcrrGl8LBrlfV1dFdsOOnSdkKryDxOSsr9YKPCjRIIftLezbBaCO133o6k+LLtyNFPXAlPuVq5GURRcRgSXESHMgXvcv2qKZoJtvT8lm99ROtY3fC9tsdMJBw+V4E7ULQnslqhcvpst3TeXpkcS6WfpG/4DK9ouwOfulPqME+wq0J2q3baLpV18qupG13wYepjO5nOwrDSWnUNTPWiab142TRStRFlQNy6T20I89SydTWdj2ZkJ/fLPONgsOg5/yGS4sn/nqFm3ZbGpq4v/r6mJMwIBjEmvr50jgg65QndZm6p6mMnmiameR1V1V5zLtotkcjvobD6H/pEHyRf6AIWgb3+ioSOxrSzMYJely9XMyrYL6R78belcIf+BhAMH8tqO/6m4fTa/jZHkkzRGjp/TShv7ulzc1NbGFwcHeblQQANO8/u5tKGBi7u7K24/YFl8Z2SET8diGIpC3nFwKwrabrw36FqQzuazeb3nFibuaFVQ6Wg6e8rNM7XYjkO/ZVFwHFyKQrOmzdr7luNYDCceLwvqxnUP3onPuxLN1VzlnrvPtk3AmVYy7tH3lRSmlUFRNHTNP6dfDMTeRQK7JahoJtnW9/OKNS+OY7K996es7rikbHH53k6fYrG2roVqjjZMrqTgcbfTFjsdt6sFXfPu1ujcaMJgG1X1THsX4UTx5DM12wbjjxAJHorb1VjluhlMK0U2twNVdeF1t6NrgaofQv2myRcHqicV/tLAAG/weGifNAoUCR7CYPzhqveJho6a0YhOJHBozc0Qo+cqn/a07Cz9w/ehaQGioaMw9AgwmuplW+9PCTecwqDWxHP5PCnb5hCPhyZNI1JjatlxiuSLA0QCh2GMbQiwrOyUz/1Q4lEiwUPn9O/Oq6oc6fXy7dZW0o6DBjRoGv81OEh/jfV3w6bJdtPk1mSSF/N5DnC7OTcYpEPXcc0gPYqiqPg8y9m381KGE38ZnT51t9EQPAJDj+wyIBt/3WuqB0XRGLIsHs9k8JHBrzikHIVnFT+HezxEpyhHNhoQpRkNoNw1vwSYVpqhxGM1zzO6CWZ6G2p2xbTS5Av9DMYfxXYKhAMHE/CuKr12Km+fYTjxOP0jD+A4o783Qw+zrPk8PO5WFEWteL6EmAkJ7JYg00pXDVJG21KYVloCuwkMPciylvPY0nUztpMvHVcVF8tbzqs62lA0E7ze838UijuT7ubyXWzu+i6rO/4Br3tmeRKLZpJU9nWGE49g2wUCvv2JhI7AM8N8XUWr9iL10Z2vlYvmi2aK3sHfEU8/WzqmoNLRfDYB3xpURZ/wYelhxLJJ11h8n3YchiyrIrAztDAt0VPoHbqn7LjH1U5D6MgZfTgZepjm6Cn01TxX9YCkaA7TO3R32TG3/2CeUvflym3bmPg16HS/n0/HYjRWCSIyudfpHvh12bGgb+2UIzGWVf25nwsxXSc24d/VFxnAQW43pwYCnLN9e+k2j+Zy/DAe51ttbRzt8aDWCMgcx8Yce62pqme0BrBq4HY10thwAo5dRFGNXY5SF80U6dwWhuKjr/uQ/wBCwcMYNBX2NV+gkHgI00rTpAVwhd5It7oGnxrBUyXoLBRH6B2+n2TqGRzsCSXrWlDVSb9Hx5lyJ/hUf0czYVppeofuYST5ZOlYOvsaLr2BFW0X4jIqg7t09jX6hu8r748ZZ0v3zazu/CDZXBdDiUdLz1ckePisrz0U9U0Cu6XIqZ7cs9RcYz3Z3szjamWfzn8inX2NbL4Lj7uNgHf12JrEyg+3bL67LKjbyaFn8G6WtbwbfZqbAQpmanTtW+al0rF8vJ+R5OOsaP8HvK7pp6nw+dYSTz1Ztc3rXYlDeS4zx3FIpl8oC+pGH4VNV/+vWN3xjyTSz43tDs4T8K1heeQEDnMbPJmvvguyWjCgaR4agkcS8K0hkXoW08oS8q/D7WqccoqpaCbJFXpJpJ9HU72EAwfj0iNEg0cSnOa5NNVHKHAwI8m/TmpRsIPH88mekYp1aXem0xzh8fDeUKjs91800/QN3cdkppUl5l9HPFV91M7nXQkszMjKmcEgP08mK46/PxTi2sHBisCvCHyyr4+fdnTQUiWwLZoJhpNPMpx4bOxLyBqaG05EU/1k89voG/7DaIJiI0Zz9GS87s6qo9emmRpL9Lwzv2D/SD9Dib+wrPW9vD58b6n8nGmlMIfvwhtKkTaOxzNpx2y+GOf17pvLvtCOlqz7Lqs6LsHnLi8hqaoufJ6VZHKbqz5nId8BVY/PVKE4XBbUlY6bwwwl/kxz9OSykXnTTNE3/Ieq57KdAsn0S8RTT5MrjJbS7B/pZyj5OKvbL5akzWLaJN3JEqRpPlSl+ujB6HoNSRcw2fhi7YbQEbQ3vY1o6EhcRkPN0Z/khCBsskzudZwJI3+7kisOlQV140anEB+cUbqVIa0Rl9GIgobPs5KAd9+x37eKHj6JEcpfF6aVYiD+UNVztcY2sL3v5/QN34dpJbGdAon0c2zt+l++1KATqBLARVWVaI0pTE3z4HE10xw9mfamMwj4Vu0iqEuwtedHdPXfjmkmR0dEd3ybwcSjANM+l6rqNEXeWPG693mW8/usUqPGAXx3ZKTKFKZJvjhYcVtd86JpflxGrKJNQSUWPoZa1RTm2gpdZ4O/cqrbr6oM29X7NGBZDFWZvi2aSbb2/Jj+4T9gWqnSa+LVHf9DwRxie98vyBV6cJwiuUIPW3tuIZ56Zmx9Wbl8caBK0miw7AzDiccIBdZVtOUSmzCcdMXxdH57jVkKm76he8dGTHfSNC+tsVOp9hHnNprwuFuqnGvmhpNP1GwbST6BZZU/FtuxanxhHJUr9KFPmm2xrDQDIw9VfY6FqEYCuyVI14I0RytzhgE0RU6UwG4WGFMsBtdULzP506k1ygOQyjxHboq8aZPdmnZQms5HabucX7o2cJN+Mn2xCwl2fJT/l1CrhBZ21RxjuhYARanY6ABjI76JB3lvsHzURAf+o7mZpinSnkyX41iMJJ5ECb2Jvuj53KSfzG2u03BaLiFhFSjUWGpQi8toYFX7xTRHT8HjasPnWUlL9FS2m7WnRwcsq8rzpeOuErzZToF0djOtsQ1EAoehjFVH8HmWs6zlPIYTTzCTDSKzKabrfCYW4xstLbzB4+FAl4srotGaAfi4arnucoXeGq+JIgMjfyIcOKSirW/ontK07UQjyadqXjuZfhG/d3XldbDAylYcT09Rsi6T20K+yrSr22hidcfF+DwrAFAUnYbQG1jRunHWlqo4UwRb4+vnJlIVDZdRe4TebcQoVsm7GE8/W3VHshDVyFTsEqSq2uiUlRGhd+g+CoUBXEaU5uhJ+DwrprUrS0wt6D+Q/pEHq7Y1hI+Z0WaAqReWK1NWX5nsbcEgv0mn+Z+RkdKxnyazrHPluDIWIzRpbZKijG6UyOS3lR33uttJZ1+veZ105m9c3LmBguLihXyetS4X7wqF6ND13dpVOZlppcm4V3HlMDxb2Dmq8e0E/Ev4YN5eiOOdNL22Ky4jQmP4OBqCh6OgoWlu3lRMcke6cgQI4GC3G++kx2LofpqjJ7Ot96dlxzPZLcRCx7Ct58cE/QfQ0fQOQCVX6GXHwB3EwusX9AtVo65zkq5ztMeDBQRVlR7TxKcoZKq8vgKKQqzKNOyUX0Kyr9De+DaGk38pO247xbGUQZHyO0z1OlEUaq1J1Kq8fzm7+KJlV/mipao6Xnc7y1rePZp2R1HQVH/lerw9EAocSDz9dNW2oG8tilK+NELXAzQ3nMz2vp9X9ldx4XG1VKy/g2nkEVxgOdsmY9v4VLXq+kgxvySwW6J0zUvQtx9edwe2Y6GiokvG9lkzogTwR88gPfSbsuNuzwry3oOxUKb9xxPwH0y8xg49v/9gbHX6u2tVKAvqxj1fKPDHbJZDPJNG2TQvLbHT2Nz1nbLjtmOh15jOB1BVA4+q8rFoeI/SZNRio/KrnM6zhcrRma/HM7yxtZmZbU8ZpShK2YL+IzwemjWNvknTjgrwsViMcJVRLa97Oc3RN9M//EBpvaquBTD0EK2x0+ke/A2J9HOl2/s9q4gEDlkUKYYCEx5Po6bxmViMq6rscP7XxkYaqzz2qXK7qYqr6igUVE8Z1BA8jJEaU5Uh/zpSmcpk2i4jhqvKlyZf4BCSieo7pd3BY7CU2ps4dM0Lc5RfUkHB615GdtIXJ031EAkeguMUYFL+Rr93Fc0Nb6Z/5P6yXbEdzefQM3Bn1euEA4eiqfNfg3pX0rbN68Ui3x4eZrNpsr/LxQfCYZYbBl4J8BaMBHZL3EwTg4rp+XEyy5DVxgWt/4ia2wxOFtyreN7y8l+9CX7SEay68Lya12w/If/B5NPloyG6FsAMHEPcUZluBqvfpmrv5vtpIsF7QqGKfnlczaxofT/dA78tlVRT0IgED6sYfRkXCR6JpvlRFQXfHAQsI46LnyRrr1P8bcbkwFn4HGtUiny7OcR1IxkeyuZxgOW6zpUNPlZrRSZ/6AJYVpJsvovO5nNwHBtFUbGsDD1D99HeeAb7ei8jlX0Fy8oR8O2LS48syi9VLlXlFL+fFYYxmmi6WGT1WKLpNYZRkYsQRitr1EoTEg4cTKLKlKihharujnXpMUL+A8uCYBhNMdQYPm4sofROmuplWXP1kmKKFsTXsIHM8O/Kjrs9qwgEDiI8zb/F2ZbM/I1Y+GgKxTXEU09jO0UC3n0I+dfRO/QHlreeV3EfXfMRDR9DOHBgWR470HAZDRVT4YYWIhY+dlZHGmdD0XF4MJPh4319pWMvFwr8JpXi/7W08Cafb1a/DIrpW1yvFCEWiWHb5tZUnttSsNa1DI+i8EqySNLOoDGzxBa3pU2O9BzPwb4DUVOP4dh58K4l617DRwZy/M/0CyNMWS80ZdtV+6WqLgK+fVjZftHYlJSKpvpwcGiMvImBkT+W3d5tNBELH71befamy1FUUjUW9gMM27OTOqRoDlDo/RGfCr4BK7QG0wGXNYwz8muSnmUEYqeXfWBaVo6eoXtIZ18lmX6h4nz5Qi9B/35VcwUuRkFN4wivl6+5XGQdB+8uSsMZephY+HgGJ224cRvNRENH8eqkBM2KotPZ8q6qa9Z03U9b7C1EgocyOJbuJOw/kOBYhZzVHZeQzXeRHysp5nG3V00PAhDRfWR9B+N3r8TKvQZOHsW9CkeP4FrAKfBI8BA2d30Hj7udcOAQFEUnm9/O6z23EAsfW7PEoKYaaGpDxU7X1tjpo3kcx9KdhAMHEfStrfm8LKR+0+Tz/ZWl/2zgqv5+ft7ZSesCBdx7O3nWhajiVL+fXySTOMALhUJZ2/FeL/4ZfBM90e/nX3p7adE8nO5/M34FNmVt/jqSYmMwQKOTZDD+CtncDryedoK+/cbSsFROZZzq93JrjVG747wephq/Hd1VWj42GAuvJ+Rby3DyCSw7QzhwMF53+5SLy/tNk5cKBe5KpwmpKu8IBGjXdUIz2FQRUBSO83p5IFs5FQtU3eW5O4aTT2HbObLxByE+umZyfJl90RyhueHvUNWdj9V28mSy1VNkwGjptKB/+rVnF4ugpk1rVFjXfDRGjifsX0ci/QK2U8TvXYXX3Yam+dm385+Ip18gl9+B191B0H8ArrGE0FXPpwcI6mtGNzA4FqrqKU1Zj5cUg8rdsZNpikKn28+A6SatR7EZTdgc07SqI4/zxWU0EAkcxkjqSXL5rp3H9Qai4TfM+MuRoQcw9P1G0+dMer4WmwHLqpnvcti2GbIsCewWiDzrQlSxv8vFWpeLFycFdQbwkWh0ylGPaufaz+Xi5UKBmxI7A5k1hsHlwSJbdny7VEUknn6a3qF7Wdl2AV53R8Wb+mo1w/4ug5cK5SlSDOBDYRduJwlMP9/VeAUNr6cdx3F2+SHSa5pc3tPD8xOel5vjcS6LRNgYDldds1ZNQNP4aCzGph07KEz6cFhjGBzgnq06nlNvXKl2TFU9NXcg7g07zhVFR9O8eNwtWHYBlxFBUfTSjs6myPHTeq1MpKmuXd9oGhp1ncU0Vqprflqip4yNSk6v8sR0zNbzNZd29dtfnOHo3kFWNwpRRbOuc31rKxeHwwQUBZXRkbqfdHSwaoZF1TsNg//X0sL5oVDpXMd5vXyvJURP38+qlIYrsq33pxTNBIXiCJncDrL5Hiwrj5L6C19pULgo5J3QLzc/bA3iGrkTZw+qH+yyLJTj8NNEoiyoG3f9yAjd5szybK00DH7S3s6bvF5UwK8ofCAc5sa2Nppn6Zt+Q/DQmm3hwMEVC9J1LUA0dHTt+wQPnpV+LVa2XSCVeYm/bfsG2/t+QffAHby6/UZ6Bn5LcULanMU6irQQdN2P37uSzuZzWN7ybhqCh+1RULdUxDStaq5LGM132TALaZHE7pEROyFqaNV1PhSNsjEcxnYcAqo6o5G6iToNg4+MnctxnNG0ANYARTNe9famlaRojvB6zw9KOzODvrVEAoewrfe7nOPbn3MajwBFh/zLFPoeQ3e3oTJ33/QHLYufJCpzbI37ZSrF2hmMtBmKwn5uN19ubiZl26iKQnSWp9ZcepSgfx3J9PNlx3UtQGPk+IoF6Yqi0hA6klT2VbL57WVtLdHTMLSl+YFtOQ4Fx8G1i93NRTPB9r5fVByPp5/D51lBQ+io3QrqhiwLy3GIqCpGne6WXKjNDTnbZnAs4bRLUWjQtFn7YjSVJl3n6qYmPtbXV/Z1UgW+2NREswR2C0YCOyGmYCjKtHe/7opHVVk24UMtY9beCAGjVSMmloez7Eyp+kE28yJkJu5QVImF18/p/IcDNdfUAIxMsbFjKkFN2+2AeVdGF/CfTiRwCIPxTaP1NwPrCPsPqll/c7y2cKE4SDLzEqrqIeRfh6EF0aZZRm6xKNg2O0yTXySTvFgosM7l4p3BIB26jqtKgDWSqp6TDWAg/tDYxofp7uEeXY/5YCbDDxIJMrbNyT4f7wuH6dR1GfWbBSOWxc8TCW4YGSE/9rfZrut8tbmZdW53zVrAs8FQFN7k8/Hzjg6+OzLCq8Uia10uLgqHWWYYc3ptMTUJ7IRYILrmQ1H0qrV9FUUvVTcYp6le4qmnaY2dRiL9AvHUMziOic+znMbwcQzGN40lzp0bAUXhjV4v92Wqrz976yxteJhtowvS98fvWYmDjaa6a5aS23mfIIYexO9dOT+dnAO24/B4Lsc/9fSU6sVuymb5fjzO/7S1cbSncmF+oThc83yj1SWmP9U/YJp8qq+PR3M7q0J8P5Hgl6kUP+roYMUMlzTYtolpJckXBrCdPB5XK7rmR5ujHHVLwSPZLF8dLv+ddZkmH+ju5rbOTjpn+BzPlE9VWet284WmJjJju64lQfHCk9+A2GsUzRTZXBfx1PNkcl0UzfLC6bZtYjvzV+9T14I0N5xctS0WPpb4pNGTfLEft6uJbT0/xrYLdDS9g87mc/F5VtA1cAe2XUCZIunwngpoGh+ORnFX+Sa+1uVi/11MwzqOg20XZ1RpYzZpmhtd8+4yqFvMLCtHvjBAIv0iqcxmCsUR7BpJg/ssi0/29TH5a0MR+ERfX0XSZoCgb03Na3vdnTN6fb1aLJYFdePits3/Dg+TmyLdzWSWXSSVfYVXtt/A1t5b2N73C17Zfj09Q/eUrf3bmwyYJl8frh6IZxyHTTV2nM8F99iaOgnqFgcZsRN7hUJxmK09PyJf3Jl3yWU0sqL1fSiopHNbiaeeQVXdRMNH4zZic578WVV1IsFDcRkN9A3dR744gNuI0dRwEqaVZGDkT5MewxCGHkTT/CTSz1Ukfl3W8u6qiWJhdFG8aaUpmklURUPTAxhaaMrpsGHLYtCyGLYsGjSNmKaxwjD4aUcH/z00xB8zGXyqyrtDId4dChFVimTz/Ywkn8C0soQDB42myVD9FM0RRpJPkit043G1EQkeiqE3YNsFLDtN0UqiKjqa6sfQI6iL+APCcRxMKw3YaKp33kr4mWaKvuEHypJKq4qLZS3njZUSLH87H7QshmoETwNjv9vJywx8nhWjibOr1H5tiZ6CZecYST5BdizdSci/FkOPoCgqOdsmYY8W94ppGr9MJivOMe536TQfikanHQiYZnyszFv5l4KR5F/xuTtpCB0+rfPUkyLwerFYs/25fJ53zV93xCIigZ2oe6aVYXvfL8qCOoBCcZBCcZjuwd9SKA6WjifSzxINHUVT5CR0fW7L+OiaD79nJcta3oVl51FVN4YWJJ2rXse1Z3A0FUrP4O9JZf8GjG4QaG08HbfRPLaLdhu5QhceVxs+z3JUxcVQ4s8MjPwRZ6zsvab6WNZyHl5PZ9VcW93FIp/s6+Ov+Z3VIQ53u/lySwv7ulxc09REynFQgKimodg5BuObypIdJ9LPEvCuJRY5mq3dt4wWeAdS2VcZjG9iVcc/kEg9z2D8obJ+dbaci9fdWbVm6EIrmkniqWcZSvwZ2y4Q9O1HY+SNuIyGOR8JTGReqlKntcDrPbew77J/xq3GJrVNPTJard1lhFnZ/gG6B+4knX1l7FiUtthbURSdV7ffUFo6kEg/T9/w/axsu4BhtZkbRkZ4MJPBr6psDIU4Oxjkd+k0uSrXmekGmXjqWWpNAw+M/JGgb82irP4xl3RGq6hsrbEb/cBZSxkklhoJ7ETdM6002fyOiuNB334kMi+UBXXjhhJ/IRw4bMrALmFZ5BwHj6LMKDnvREUzQc/A70hkdu7aDPrW0hrbQEv0NPqG75tQrzRIZ/NZuIwGOpvPxrIzOI49GgzqQXL5HjZ334xt75z+8rg7iIWOoX/kgbLrWnaG13v+j306/xmX3jA2AuWgqV4SjsJn+vvLgjqAJ/J5ruzr42stLUQ0jYkfo1kzXlHBAiAc2J8dfbeWgrpxLiNKJreNgXj5fSw7w9aeW9in44OoRmNZv6az69C2TSw7Cyjomn9aC/STllXaMTrVJo6imWRb78/K6oKOpJ4kkX6e1R2XzGk1iqKZrPr8jrJJpl/EHTm+7GhU0/ApCpkqgZVfUYjVeKxuI8qy5nMmvL5GN4y8tuNbFetBHafI9t6f0dXwPm5PpQEYsm2uHRriSLebT8RifKFKrdqzAgGiMxiVzRcrzzGuaCUrXl97g6axXfufmFDSa5xPUVjv3XvXHu7tJLATdc+2K/OuwWhg1zt0T837jSSfxOfpqDietCxeLhT4xvAwrxWLrDQMLm9oYH+Xa0YBnmVl6R64k2SmvP5mMvMiOBZtTWcS8q/FtNKlepK6FkRRFDRNK9uhWTSTbO39aVlQBxD2r6N/5MEaPVCwrAzDmVdLJYyCvv0Ih9eTsKt/UD6WyzFoWUQmPc6R1FNVb6+q7rHgrNxoTdJHq97HcUySmZcx9H76hu8r9SsWOQ6X3lA1WHMch6IZJ1foBRwUVFA0PK7mmrs4U5ZFwUqSLvRTKPTjcjVRdDXi0kIEqvwe84X+imLvMDpq1jd8P+1N75hRYlnLLlK0kqSz27CdPD7PMtx6uMZ0ukPRrJ1qJl+oLO3UrGl8Ohbjc1UCq39tbCSmFEjnB8jktqGpHnyeztGdv6oBigIopf9aVrrq9CxA0UrQqVX+jT2ez3NBOExUVcumhDt0nfeHw7tMe2LbRUBFVTUCvn0qlh6M87jaUJTFn9B3Lhzn9fLhhga+OTJSSvTdpml8raWFNqn6sNeS37yoe6O75hQmT+Uoilp1R+o426n8sCo6DvdmMvzrhBqJA5bFRd3d/HtjI2cGAtPO02VamYqgblwy+zda7CxuV2NFPcnq50pTNCsXUut6kGJxqOp9WqOn0Tt0D5kJ077DyceJp57lP1su4rxes+poT7rKuq3JAeW48Y0SHlcrBI8DLQhWErfhmXIHZi7fQya3vTSaOt6v0ZGxWMXtC8VhcoVu+ocfGJtyVwj61hALHweoGHr5esmibVMsDtLf+wNMa3QtWA7IaEGaW99PUW2qmC6Mp56p2d9k5iVsOzftwM62C8TTL9LdfzsTX5cB3wG0xk7HbZQHo4qi4XG1VhSIH+f3rqo4Zqgqp/n9LDcMbhgeZnOxyGrD4LKGBtbpRbr67yCdfWnCPVTam96J39NJz+DvSGZeAhzcRhOtsbcQ9K2t+XpVamw6+lM2y7fb2rh+eJiUbXNGIMBxXi9tU+zWLJhx0pnXiKefQ1M9RENvwO9Ziab6qlYEaYmegr6X7oyNaBoXhMO8NRBgyLIwxkZi5yOPnVi85Lcv6p6u+QkHDiE+aVQpndtKwLeGxKTkteMigUMqjvWbJl+qMgIC8B+Dgxzn9dI+zcDOsnMoikEsfAw+9zJsx0RVdDL57QzFH8GqESzB6AidaaVxHGtsk0f1axaLI7hcTeQLvWXHNdWHqrrLgrpxtpPHSf6JswPH84Nk5c66YJXHF/IfyEjyyYrjqubHF30bTyidfDOep8s0adfDXBYOcHjjO0kNVCbDBXC7mkikX6jo1+jI2NvLAijLLlAwh8YS644HSQ7JzMvkCr0sb30fxqQqujkzxWD/z0pB3TjTSjLY93O01vdjGOX1ctUpgjZVmdlbabYYp7v/torjqcwLxD0raAq/oWxkUtf8tMRO4fXu/6u4j6b6RmuxVhHUNI72evlvl6u0bCCoqvTFn5gU1AHYdPX/guWt7y8FdTC6G/v1nh+wrOXdZHJbK4IrRTFIKR6gcmTWp6rsP5aE2hr791QKxRG2dN9M0RwpHUuknyMSOpqWtosYGvgVubHE0YYWwt2wgYQWm7JGcr3zqCqdqjrnqU1mKm/bDCxA4mQh6U7EXkBT3bRE30xD8GgURqfYFFRUdJoaTkRVKhcZe93LcLuaK44PTVH4OuM4DM4gSa+mulnWfA65fDdbe3/E9r6fsbX3R2TzO+hsPhdVreyX49hkc11s7voOr+34Fpu7vs0r268nnf0bTZETK24/knyCWPiYiuM+Tyfp7Gs1+5bLvMiJ3sq3h7/zequuzfK4WvC42iuOp5QId9kr+Oxgmq6xRd5dpsm/Do7wG7MVj7+y5JequMZGp3oq2pKZFytGBy0rM7b+rPL3UjTjZHPbK447Tqbmuq18sR+qjAxFArXLk0WCR6DNYBd1PF179G8k/jA5s3JHqdfVTmfzOWXX8bo7WNl+Uc1ky+NCYx+qIU0jZyYZiW+qedt09lV8nuWTjjoMxh+hIVi5+zQcOZnvJquPfL8tMLoS062quwzqbNtkIP5wWVA3biTxGCNmjoe9b4OWD0LzP7Ct4X18LBHiS0PJqqPIYuGMWBb/F4/z9u3beU9XF2fv2MH7u7p4Pp/f5aYeseckfJ5nA6ZJj2nSZZq06Tqtuk7TEvwWU3Qc+k2T14tF0o7DvoZBVNOmXGOWHEux8EqxiE9RWGkYNOn6bpWQmum5DD1IoOHN+EPHYDoFDNWFo/pxa25Wd36QwZGHR6sMKC6ioTcQCqyrujZrV9nUpyrXVHEu1cVQ4jFS2VfLjo8GXA7tjWdV3KdoxtnSfVNZfVnHMekduoeOprNwGY0UJgQsBXMYTfXQFjuD3qG7S9PLmupDmWLXqYJOSNVKE9gKcLLPx782Nlb9HRt6kOWt72Y4+QTDib9g23kCvn1JKx7+J159Kvh/RhK8tf0k1MwLpX659ChtTW+jd/D31ftVZQcv2GSqBG/j0rktNISOKDvm2LXTRIy2VwYqhhEhGjqmYm2gy4gRC72h6u7iWswppqEdII7Bq7kcO0yTDl2nRddp0j2E/Afi8yzHsrIoioam+WqmuKnFxqm67rHUNyuNplZW2Mjmt9Ea20Ay+wqF4iBuI0Zz9GRso4OXk5UbkD4QDtM+g/c2y84QrzLqW5J5jj+ah3LtyPgo8ujmns3FIknbxr+IU+TsbTZVSZy8wzS5qKuL2zo76Vhko4v1ZulFFEvYjmKRf+7p4ZUJuYdWGAY3trayfAm90Au2zV9yOT7c21u2ButdwSAfamggVuXNfNA0+dbICLckEqVxFa+i8F/NzRzr9eKewZvyoGly48gIP6pyrmO83qq5sbYXi/xzTx+vlp77LKuMDN9sbWWZEaU19haaGk4A1Cl3U8Y0jUZNY6DKyFxUVYnOYPOEbRcqgrpx6exmnCpr/JKZv5UFdRMNjPyJ9qZ3sKP35xStBIYWoqnhxNGUJ6qHgG9fLDuDwmhAYJpJhhOPVT1XOHgYT5o632hpIe84uBWFp3M54lVyn40z9BBNkTfREDwCcFBVD0/lrdKi7smKwJDj4sCOD07olxfLLlQdrQOIBA5HU8tHxhR0dM1fMa26s1+RymOaj2rrLsfPaFQJlnTNR1PDCYQDBzIU/wu2kyMcOBifZ9mMi74b3jWQfrbiuKb6MJov4JKeAV6b8D6xj2FwQ2srnYaBoYcw9FDFfafLRsfj7iRXZSMIjI4CDsUfqTiuq350zc/KtvNxbAtF1Uq5Hr/X5uKvuRy/TacJjeU2XGEYFZtsdsWZIkG4QhG9yt9lQFVl6mkR6TdNvj5U/ctc2nF4JJvlnCX0ebcUSWA3T0Ysi0/19ZUFdTCaYPIjvb38b2tr1YBoMeqxLP65p4fJ4cXPkkkOcLs5LxisCIweymb54aQC8lnH4UO9vfyqs5OVrunvavtTNsstMzjXsGXx8b6JQd2ozcUiH+3t5Vtjz72q7vrDsknT+M/mZi7p7i57/AZwXXPzjApfW3Z+F+2Va+yqpW0Zly8O4tJDrOr4BxzHQlG0slHH0em6SOnfiqIRDR3N0KTgztAbyPiP4sruoYqqBb9Np/l+e3vNtTKKopZd06NO/Rjdqjq2GWLnhgjTytTsVyxyDKpa/hzrepBY+Fh6h+6ueo1w4KCKYy4tQCR4FCPJysA2EjwKV41pVX1shMzr7sBxnIq+TFfAs5yEFsK0yl/HrsjJfGowWxbUwWgVh4/39fHN1lYa9rCurl/3EW54M7memyraDD2MrvkpVNmIE4sch64FRv+2J3Wh1TB4q2Fwqt+PqigzGrkep6oegv61NXe/Wp51PDVY+TexMRSqmbpFzD8TaubWA3g2n+ec+evOXkm+6MyTIcviiXz1D7mXCoWaGeIXo/vS6Yqgbtz/Dg/TP2k0a2BshK0aC7gzXXtaaLKBsZG/mZxryLJ4psZz/8IMn3tVUTjU7eb2zk4uCYc5zuvl4nCY2zs7OdLjmVHha23CGjqXHsXvWYXLiFZtH+d1V6ZfKZ3DiAGjwZzLiOyyWPvoCNSJrGr/ACH/gQS8+9DRdCatrRdwcV+6IqgD2GaaDM9gHWGjptFZIwhs13Waqnwgj/br71hZ1q+zWNV+Ia4qo2+KohAOHEygohyWQnvTWVXvo2tumhpOoDFyYmkto6q6aYycRFPDm9C1qZO7Koq620EdgKaHaG49H693P0ZHDsFtNFLwrOX5QvX0PM/k8wzN4LmvRVUUdFcL0eaNY68ZAAWvb3/aWt4/NoZZ/joO+vYn5D9wl3kBDVXdraAOQFNdNDeciFoldYnPsxpLb2Bk0t/qYW43ZwaDu31NMfsMRhMn17JOEifPuaUxRFQHMrsIHlI12i07j2kmSWZexrQyBH1rcBkxjAXMsr55ijI2PZZVsTjWdBx6pvgG90qND7JqTJjyXK9WOdeunvtdtU/mUlVWulz8SzRKwXEwdnOEQtP8hANHEPKvoWiOkC8MEvTvh6FHSKReRtMqf8dB3xp6h+7BqTId29xwEsOOm7+kUjyXz7PO7eZwt5s2Xa/5gTw6ArUcj7sDHBtVNXgml2PAqj6VAlStJFBLs67ztZYWLurqIjXhfgFF4b9bWmqO/I3m7POPBrJj/ZqKoQfpaDqTopkkk92CqnnweZaja8Ga93XpAZob3khD8DBsp4iqGBh6oMY6vtnlU1UUI0q48UwCVgYbG0P1sNWe+tqztUkgontQvKtwuc6naOfRxqbBdc2Dzwix77LLyeS2Yts5fJ6VGHpoxmv5dofLiLG68x8ZjG8imX4ZTXUTDR9D0LcfWcXH7Z0B7kqlSFgWpwQCrB5bWysWj0Zd5/KGBj45ISXUOEmcPD/kL2KehDQNFaj1ttysqvSYJnHLQlcUGlSVsGoRTz1D98BvSrcbjD+E193BspbzMPQQjuPgOCaKou1RSaPs2Nb09Ngi5Jim1dzFdrTHw89r1IHc3+XCNel+HlXlAJeLJ2uMms3kD92jKBzgcqEA54VCeMaCqteLRX4Qj3NslXOFNA0X8A+RCGf5VNyKTd5RuSPrcOPw8IzXAY1TFQXPHowU6JqXWPgoXu/+ftm0q6q6Wdl6QdXcXIYeZmXbhWzr/UlpTZmiaDRFTqToWsaZO3aQmPDhH1RVbmprY+0uviWrigZjAU2DpmFA1VFZA2Y87bW/y8WtnZ38JZfj+bGA8yiPZ1oJVCf2a1d2BoOtZccztk2/ZfHnbJaUbXO0x0O7rhPVdRRFw2XMbH3cVBzHLk2Dj/89Wo5Dn2WRGMszFtE0opqGV1Xxqj4wdgZMqWKx5so/FQjP4gaBsKaBVu2xu3AcL373ClAcFMWYl6AORkdf3UaU1ugGmiInoKCij+UgNBj9W14TjU59kgVStG1smNF64Xp1nM/HvzQ0cKMkTl4QiuPI3uNEIkE4HCYejxMK7f6i5KlkbJsvDQxwW6oye/tnYlGims6XBgZK04L7u1xc0xRD7b+JQqGyZExb7O34vcsZST5FttCFx9VCQ/CIsQLqM/vD6TdNrh8e5rZkEpPR5TNvCwT4SDRadUSlq1jkPV1dVVN7fLu1lfW+yg+Bx7NZLuiuTK4aVlV+1tExo11SL+RyPJnPc8PwcOn5Wuty8dFolH0Ng9ZJ50rbNvFiCvJbSI3cT9EcxtAj+MMnoHn2wa/7pywlNVeKZpItXd+rup7J0COsav/7qtOpo0Xoy/PYZRQf7+3qrbq2pUPX+cEU6+Imy9o2/zsyUnXK+5JwmH9saMC7RD680rbN79NpPtffX/al6k1eL19oapq10R7bNimaIwwnnyBX6MHjaqMheBimFuIPmTzXDg4yPPZaPcDl4trmZvYxjIqR1KRl8YWBAX5TZUnBmYEAn4nFqlbF2B0Z22bQsugxTdyKQvPY1LhpDtHV/2syuS3A6GuxrfEMfJ7lM6qssbcYtixeLRT4USJByrZ5WyDA0V4vrXt5AJOblMcuKnns9shM4hQJ7JinwM6yGDaz/K2Qo101UZ08tuJmwNExVB8X9VTuAgyqKj9sMsj1frvsuNvVTFPk76rU4FRZ0fo+/N5V0x69S1kW/9/gIL+qEnCe6vfzhcZGvE4Oy8mhoKJpPjTVzeZCgav6+0ujcLGx8kVv8nqrBkkp2+aRbJYvDgyU1uAd5Hbz/zU1Vf2Am8qjmQx/X+X5CqkqP68SJGbMPIOJR0mM/KHiPsHwCcTC6/HrlekdpmI5Dn2mSZ7RUcQmTZvxdGwu38urO26s2b664x8rRp9qeSmf5+wdtTdW/KKjY5ejdhMNmSb3ZDLcMLZmsknTuLShgVN9PqK78eacGHuDT9o2wbER4fkIpl8tFHjH9uqpUD4RjXJBODyjdZHVOI5DOreFrd0/wJkQPiqotLVu5JIhgxcK5eOfU32h6TdNvjk8zK3JJEVGR6rODQb5x4aGWQtEhy2L78fjfGdkpPQO0qCq/KY9TE/3d6qmQ1nV/vf4PMtm5fr1Ytiy+O+hIX42aQZjhWHwndbWKStsCDETM4lTJHyeJ5adImT2sjr917Gs7qM6vPtSiGyoWqw7adtsKmisd7WVlRKKhY+lZ/CuKoWvbbb3/YJ9Ov9x2ukXhiyLX1cJ6gBwijiF7WwZvHOscoFC0Lc/rbHTWOVq4PrWVoYtC5PRILRZ02p+SAZUlTf7fBzc0UHCttEZLYcz0x1+I5ZVkR9pXMK2eSib5bxJb6a2nSY5qdj8uFT8IaLBQ4HpB3aDpsmvUin+d2SEuG0TVlX+PhzmrGCQxhl88NpTlDMDpix3NlmtlCLTbZ8squuc4/dygseggIMLhSZNR9Nm/pbRa5p8cWCAP2QypSnG8Zx4cz2q8Ztar23g5nictwYCezyKYFoJtvf+vCyoA3Cw6eu/lQ9Hz+ef+ssDu7ht8+dcjndW+eBv0nU+GYvx95FIaWlEo6ZVTeMz0bBlMWxZWIx+yWnWtJpfmB7KZPifSSOyMU1jMLO5FNQpioaCVsox2Dt4N8ta37ukyneNj25bdraU5mc2p5W3FYsVQR2MZjv4USLBh6LR3crTKcSekMBunmh2kYHk4yQzL5cdT2VfwePYXBY+lS+PVGa7f7ygcIIRLQvsNNVTM2eXZWcxzfS0A7v42LqQySKqykeDDtu6b6a8TNOLZPNdrGr/e7L4GLFtsraN2zDIOA6BKd7EFEWhRddpmVbPqss5Di9Psdniz9ks5036NmNZmZpBkoOFZaWB6a3bydo2343HuSkeLx2L2zZfHR6mz7L4SDRadW2iOZbQuceyyNo2nYZBs+ZDQasSoI+O9ugzqGSwq3VxM8mvB6PTxP3Df2Qk+QSqqpOyTezgoTQ1/N0ud9tOlLAs/r2/nwey5aXJ7stkMPv7uba5eXSt1xzpmmKjz7Bl1VzzOhOmlalaw3S0LU27Wv31+lg2yzuD1Z/L8TJR0/VqocC/9veXdn83ahpXxWKs9/kITDrPwNjSi30Mg/eEQjSOBYBp20bP/Bm3uxM1fDL9+Mg7Du2ag5J+gmzyr2M5FJdGYGdZOVLZV+gZvKsUrHrdHXQ0nYXb1Tgr17i1xlrj8baN4TBRTSNv27hVda8K8sYT2D+YyRDRNE7y+WjWdUkkPQ8ksJsnClZFUDcul3uNN0YcvlylbR/dwcqXT4vsavZ88sjBzvvZFM0kRTOO7RRwGQ20qt6qi7U3Bt1YiXuqtIyOUMRzr3NFIsbTYx8kKvD+UIhLIpHdmqqbLh1o03W21PjAXlMlH96u6njOpM7ngGXxgwlB3UQ/TiQ4PxyuCOyKjsMTuRwf6e0lPrbOSgX+o7GBIyNvZGDkgYpzxSLHzyiwa9Q0LolEuKHKuri/j0RmtOHBsvL0Dz9IztWB1XIk3ZZDs6aSM7voG7qf1tipaNr0RjgHLasiqBv3YDbLkGXtVmBXNJNVc/VNdrLfzx010ukc7vHgm4UP2qmS6o6q3r7vDHI3TqWrWOSCrq6yVCADlsVH+vq4qa2NoydtKDIZXQZxgs/HDcPDbDVNFEYrRaz37sNWtYOPD6RJ2qPPmwpcGDqcc2PLUFg6gUk23zVWP3jisR1s7r6J1e2XzMqmmdwUu5QLjkPWtrk3m8VWRosZrnW5aNP1ig1m9abXNPloby9PTdgw919DQ3y+sZG3BgIVXzbE7JLAbp7YVaoITKTauYpdszpwRjBCzHMssfCxOI6FqugYRhRVdePxrMYOHE0eF26KqOnHyWZeRtcCFMx4qeyQrvpQNQ/Z3A76Mq9jelZhOh5c2R6C1gjfatqfD/aXJ0o9xKWSS2yt2d9s5mU+F3sbKApFx0EFfppIcH8mw9lTzP/3myZJ20ZXFCKqOmUJsmoadZ1LIxE+VWUrvQ5s8FcGQ4rmw9AjVWtQGloIRZ3+1MzI2NRzNRajo0DLJk2vdZsmH5yU0NgGPjEwzB3th9GuR+gb/gOmlUDXgjQ1nEjIt/+URecn86gq7wuHadN1rh8epseyaNE0Lmto4CSfb0abHUwrTc5/BJ8cMnmhsDMo2t/VyH9GWzCtTM3AznHssdGR0coTu0rPkZxh+g7TSpNMv0zf8P2YpeoaJxH071d1iu0Qt5sOXWfHpE0lKvCxaLTm62/0cSQxJ/wNje/OHDBN4raN6Tj4VZVmzY+qGFUrgqiKi7jjAcqDSwN4c5XX6u7YlM1W5Hcb95WhIb7Z2lq289utKLwlEODDvb0TxuLh+/E4Z3Xsz+U7Kl+r30tk2b+xk5UzGK1dSKaVrpmw2rLSZHKv4zIO2ePrvCMYrPnF4c1+P/2WxQ8TCbaaJqvGRkhTts0Bbvcer+1crIqOw08SibKgbty/DwxwlMdDYJa+1IjqJLCbJ7o69fSFX/MCO6dzfIrCfzY300iWvuH7SyWWNNVDe+M7ibT9Iz9N5flBf5aMk8erKLw7eBzvbzuJfHGIHX2/KE0PuY1mOlveRbfj5suF1TwUz+MAHXqQTzU0cZCa4gy/n+cKBdp1nV7TxHJG00cUzTia6sXjbsWxTTL5HYCNoYf5XTrNt+PxsXPpfCwaxR6bcpy8yDtj2zyZy/GFgYHSzs31Hg9XNTbOqOoEwHFeLxeFw3w/Hi8Fwn5F4Ss1ttKPOB5amt9FV/f3sZ2dbzaq4qKl5TxG8DLdrIAeRcEAzgt6eYdPwXCKmIrBrzMOP0pmq6Y/uX+KhM7/3Jfgx+0Hsdq3T2kEqpTdf4YaNI0zA16O8xgUcTBQaNQ0dE0vBSqWlYUJgYpl5ymaCZKZl7Cs7Gi+MC3G54YzFQv+XyoUuGrYxX83uTBNk8SE1DxRXadoJhhJPsVQ4rGxWrFrWBn5Ow51GzyVr/4M+FVIZ18nmfkbmurB59ufEbzEGa09PHHdpm0XGYo/Rv+EEc6ilaBr4Jc0mX9HY+T4ipx1rYbB99ra+OrQEHenR5Mur3W5+NfGxtKI2YBpljYpNOo6lpUjmXmJnsHfYdmjo41uVwvLms5luxLi2oEBso6DW1VJWhafiTWwPPYWugfuqHh8LbG3cI/pQiFdCqICijKa9mGWpqAfqTEiCvBCPl+Rd1ABvjsyUjEWf4jbzW/TmZqv1W/FUxznC85KhRzHcSiacTK5reQK3Xjc7fjco6XZZvratx2HbtPkr7kcLxQKHOh2c6LLrFmWDkbrB0eCtQO7ftPEZOdropY1LhdHuN38dVIQE1JVNoZCXNDdTX7s+R+wLB7L5fh0LDa6A7lOd4gOWRY/mlQZaKK7Uin+eZGmrJmp8Vkwyx77Aqj5ZjTTMlfq85W1CGmaH793H9JVaoN63Z1stgz+p7WVQcvCo6ooQIeSZ0fXt0sfLjBaZmog+wo/yjZwS3JnIJh1HG5KZBmxVS5WXytb86OqOn22wgf7c/ROSFGywzT5l/4U32kO8dkGN/fmfTyfz/MWv5/9PB5c4TcSx02f1swDWZugCidFVFyZJ8l7D+QXfUne4vfjVhSezee5oq+Pb7W2ojoOjuOUkveqisIrhQIf7Okp+zDZlMtxYXc3P2pvp30Gu8dCSpGLPCnO8vrZajp4FYVWtUiLlsalVI4kDds2Vw06/Ef7JZDfSiHfhcvViuJZyccGsnwoZtM5zWs3aBrfbwkRTP+JTO8zmNiAwnn+g3lry5uqrmV7aYo1gTtMk6xjohf7yBf7cRtN4LJnXHsURqcne4fuI556Gsb6ZQYOprnhJDK5rfQM3lUWqHQ2nUU230vXwO2lcwzGH0ZvvZwn8tX7/FS+QLetc2nX9tIo0f4uF99tDjLY/zNyE0qeJdLPkcy8zH+2/j1n9ZikJwUYb/B4MHJ/Y8vArTsPDt+Lr+FU7jBXclemyFdbWjjA5cKtqphWioGRP1Xt18DIn4gED8WlNlS0dRgGVzc18dFoFIvRjTxRTWPYsrgnmeT/DQ+z3TTp1HU+1NDAG1wm/f23l50jX+hlh5nlF1l4fyTCY9ksGdvmiECAF4sWMddqOpvPZSjxGIXiIC4jRjR0FKrq4XRXgGP8AbYUi/gUhQ5dp1nXq9Y93R37uFxQY9SoTdcxHQfbcUoBcs5xSksoJmrUdV4v1t6ws71YrBn05cdSWwyP5epr2EVqi1yhhy1dN5d/0VI9rGq7EM80d4KPe7FQ4AOTEmB/vdHPMi1E0aoeYLiM6mvshi2LP2YyfGN4mB2myTJd51+iUdZ7vVU3ejXpOv/V0sLd6TS3JBJkbZuT/X7eGwrx6d7eUlA30TeGhjje66VpRo9y6XCYeiS+Wp3tpci0siTTL9I79PtSHlKPq42O5nficS3sb1cCu3limsnSdOp4figYDer06JkkLTc9xSJP5nK4gBP9fgylSN6u/DZu+w7jp73VF+3+MpXmotaDIPFQ6Zjb1cpTBacsqJvoq/E8X4x5+MrQIM2axu/Saf7Dtrm982D+ra+fxyes8bs+Dh9tOIoj8PCvjQ73ptMMWRbvDAZp13U2ZTK0hULcMjzMs/k8B7hcvCMY5HepVNWkqwOWxZ9zOc6aQWCXze+gr/eHAHSoHmzHIusU2aq42Kfzn3AZ5R/uIVXlL/k8J+/Is7/RyGpXO5sTBV4cHF0rd9UMpikbFJNs6gESZQXcHTLppwk7BRo8ZzL5z+pIr5fba+zOXONykU2/yNDQL0vHdC3AirYLpnxzsO3ihClPNwoqPYO/m1Bnc3RiP5N7nWy+ix39t5XdP1/oZXP3zXQ0nVVx7pQ99W7cHtMsm/obsiyG871lQd04xylixh/gioaT+cLQztfsUR4PV8f8pLpurrhPZvhuLmq7hHN8Bmr6EQZTOcL+tWiqH0VR+f/bO+8wucqy/39Om153Zne2pAdI6D0QeokCooCAgoKGF0GlCFhBLLy+vgi/FxU7Si/SO4g0gaAgXVpAQkkgyWb77vR2yvP7Y2aHnZ2ZEDQQ3Dyf69oLcs6ZM89zzplz7nOX7y2EIODbBEMPYVppsvk3EdhYdh6XEcVxTECp6TlmbJsB22Z1uYxNpfrT1HX+lM3y82qFtQastizOHBri1LCfA/xbU8i9XBuT24gzSAifWumTPM6NmQzbuN3MiEaZps+kL5RAEw6OoiBUEKm/MD0eZ6YRYWaTa7zgOGRsGxSlZhCtDdPKUjZHyeRfR9O8hHzzONAf4qKxMUKqyqeDQbyKwl8LBV4qlfhMKMQ5Q0McFAiwyO8nUhVKj2sag5PuB6tMk4/5/S1b/G3mcuFuYowmbZs7qgZyWVQyfHt0nQsTCea7XGiKguNYgIOqujCtDKsGbqwz6gAcp8iqgZuZ1X3cOhfoDFoWpw0M1Bl1AJdmTM4P7Y45dm/DZxRUPL55DcsLjsN1qVRdnuoqy+Lbg4N8Ixrl2HC4qfhwh67z+VCIA/1+HCqFZy+VSrzaIg84K0Qt1zZl2xiAbz14b/NVtYENnb/nVRR28nh4ptjY1xdg3/WUgrChyRdXsWb4rrplxXIfb6+5kjk9J1Z7c28YpGH3IWBaGVYOXIdtF4hFdiMeWYjjlFEVF5YW4VXbyy/HRutadd2Vy/GZoJ8vRA+gOHZ/3f7SQmuZ5yWAMUdh4k9HQeWpYus3qFdKJdyqxhVtRYQ5hKLHKOsJbs3keK6J5+bCsRSXdfk4e6i/9kb610KBPT0eFkciHNnbW5PXeKxQ4MpUinM7OtiyWOSVJt6rv+XzHNaiOnAylp1jcPSh2r8ndmxwRJlM/nVi4V3qPhPTNA4NBJhuGGzudlckJIJBlpVKvFEuv6+KUcvOTTLq3iWTfw3LXtSQf7aLx0NYVWs384mcFvZgjf110ndkWTVwE7O6FjdtHVc2kwyOLSGdXYrAxuPuprPtAFBUujq/iKF6sZwCuupFVaB/6K6GfUDlQVoqD+FxJSiWB2rLg6po2f1AoVFZfyu3G7XwQtPvAMjm3+CQto+zgydByrEIqzpRVaEwdl/L3FMn9zKdvk1wPAmEsHGcEtn8cqZ3fg4hLDK5ZZTLw7iMGDM6jyaVWYqmesgWVpArLEdV3AR8m6AoPsZsh261QKD0Co5TJOifj+W0sbnLzWnRKPPHrwlV5bVSiWtSKT7evgAmGHYuVwJFdXFRslFk+6VSib8XCuzh9XLi4LseIgO4qGMR3Xap8o9JjJXzGCKLUliO45TQvLNJaWE8epBR2+ZN0+TNcplNXS7mGgZxpchQYQ1F1wyGvDHcikLOsQg6g9ze002/bXFjOkNOwOFBPz+Ot7GsZLLA6yWuaSwtlejSddpVlf8Kh7k8leLIYJDNXC4sYEk+z+YuF1u6XJwYMpitlUE4ZBUPl2dsjglHCWJSKiexnSKa6kHXfDxXdFheznNNhw+PyIOi0eu4+d/BQX6fiKDbI4yknsIRZcKBrfC5p7esUi9bo9h2vqlhZzkOa6p6iGUhaNc0BJUc1sZzUua14Cy2DO5AKvOP2nJVcRHvOJL7CypHTsoAGbFtLmnRh/p3ySQHBgL0NDGaRm2bN8tlrk2lyAnBwYEA27rdxDWtpXdKB/6YSvFIPk9QUTgqFGK2y7VW+Z8x22ak2sFkvHtJRNPoM00eKxS4L5cjpCgcGw4zx+V631JS64uwpvHtWIzP9fY21PtvYhjMmwL5daaVZbBVDqeTJ19aJQ27qY5lZzGtindoaGxJdWnl0Rnq+AJPl7Sm/VdvzuQ4tHM+HmVJ3dutR1l7Vaxv0kt1sdzPNF/rH3lc03DK/RSHbnj3O+Kf5bZM66KC+7NZFng8/G1Cfs8BwSBnDw01aKaZwPnDw3wnFuOsJkUPs96Ht04Im5I53HJ9vriqwbALaBpfjUb5/tAQv56ggbe92815HR3vq4BjoiHZfH2jh7Vb17mqq4tvDw7yRvU8h1WVb7dFmV5+jmKTzhNlcxjbzjUYdqaZ4p2+ayhb7/ZyLZbWsHrgFqZ3/xd9w3dSLL5TWzc98bmqBmFziuUBDKOtzrDTC//k4755PFcyOSrgYpYO71hwQ7bMNm43T0/K6TKFwFFaix+rqkG5tApz6HZ8KJgIRjU/PZ1fwDRHKJbXNHzGdvKksi+TzL4IVF5O2sK7IhyLkfRTtZSGXPFtxjIvssm0k+gbvpvcBG/44NhDdMYOJObupn/sSfBvB4pOsfAOavlpZsaP4KJUil9NuCZ28Hj4SUcHaSfLxMePSw/xSAtPFsDd2WxDMYQJnDWS5/queINASNrM4xRe5Z2Rd9sFklyC3zOHjvZPcfSaVJ1RENc0rurq5M5ynCuG3i1uiGsaP+/o4Llcjl8m363WfqJQYJquc2lngpuHhuvmuLPHw0/icea6XPx2bIyLkslKQYXfz1xD49IY9A/dQKlabORWDM6O7k9U99E7+GeyhTdq+wr45rFt9OPM1d4gP/BXCtWs1w4twEWJY0klHyGTfb62fa6wHEOP0t1+KCv7r6fZ60Mzfcei4/BCqcR3BgdrHW8M4CvRKKdGo/ymibblt4az3Na9Ny7/zijmEIrqJq2GuaOkMcPVeM8Ztu2WoeaiEIzZdoOg9Khtc+HoaJ3syROFAjN0nZ+0t3NSf3+DcZPQNFaZJueNjNSWPZjPc2QwyMmRCIkm98M1psl3Bgd5fkIIfRePh/+Oxzl5YKDu+fFAPs/nQyFOiUb/5XaJ/y5zDYNru7v5fyMjPF8q4VEUjggGOT4cniLdJ97jOVRYSSSw9Yc4nnpkzfGHQHNjoHJDE6pnrVpId2TL+L2z6pZ5zNVs0eKtZ65h4LPqk4YLpdXs43Zo9RM/LuTHTi+pX6joa82TSDtOQ6VlUFUbwjvjjDbZHirm7cGBdS1dqDzgXXpjHtU4XndXw7KUbfM/Q0M8Oyk08HypxPeHhhhbS86HZRcomSMUy4OYVvpfkk5RFIVN3W4u6+rirmnTuLWnh1t7evi4u0yxhXAy0LTKMl/qrTPqxom3H0r/8N11Rh2AaY1i6JGW3+HSw9hWfZi4mHqc70UMbow7HFh6gLnJ6zigdD83xG3OCPu4dpLcy7PFIvi2bPkd4cA2E0LElevesnP0Dd5MLHZQ088EfZvVGWkCh5HU3zGtJNHgDvVzj+xGKvtS3fbj9I/ch6ro3K3vyVHDOocMCs4rb0ou8imuTqb5x6Rr4h/FIlckk4T0elOsbCZbVp5C5RrLN1k/bNuMOo3Xve6k6Z9o1FXJFZeTzb7M7p56r29EVXmyUOTiVKrO+Bi2bb7c3888T2Nx1mrL4rp0im0ndRx5s1zmbcvi5P7+WuViSQjuzGYpWml6+6+uqyB3hMnI6H0UiispmyN1+8rml5EbvR8vZp3MkuOYKNZInVE3jmmNkcktI9gkHDqegD6ZXsvi7MFBjg+6uTnh5eYONz+P+3kolyOmacxuYgwZisIqW+Pw/jxfSoY4ZsTFsQM5fpFMk2hiXLib+qgn7q9x/SrTbHr/XmlZPJ7Ps8+k9ooG8MN4nEuaSCbdksk0TZcZs+0Gow7gqWKRH4+MsKhJaPO6dLqpJ/PDwqOqbO3x8JvOTh6cPp17pk/nW21tDe0e/3NR0bXWUSb3Bs6xk4bdh4Ch1ct/vFv5qKNpwbV2BcgLQdC/Nb7QrnjCe+P1zMRrDfPTjhjTJt2cujSNn3e043cyMEFvSlXctJHl5+1tDRGhA/0+9tFHKBbrpU2U0jvs4mntMt/Z4+G1STca5z309VyT8nMM4KcdHe+rKbSuB+iI7tt0naJoBP2bNywftW3+3iLf49likdEWhl2pPMKqgRt5c9VveGv1RSzvvRRHmHjdzdsqed3dKGsx/GK6zlyXi/luN12GgaFqtP4JKk0fcK20EF2an0JxRcPyscwLtIV3bvENKn7vbPKlVXXLfd7ZUFrJyMDVFIpvY9lZCsV3GB24hkD5DXb31hsKRSEoqUF8od0bvsNttBPwzSWTf6NhXdkcQW3S+s5lxNC1YO03ok7wBo6kn8bQg/i9m+EL7oLfuxlB36aMZZ5rOkeAVPZlhFIR0BbA3wsljukbYg+/n1CTl42ni0VsRWfib0hRdfZr0gN5nIXe1lXvZpOfRaXApTlj6Wf4Sqh+XIcHg1zdotKwKARLSyW2atIy7s5sno/768f26WCQS5PJhnSOrd1ulNJbTV8oAIZTfycS3K5hebbwOj7PjLplfu9Msk3O+Tjp3KsEfZs1LI9H9mr6wHy6UODSdhd7Fv6MGLgYMXgp08au42fhDENmvqnQ8zGhEPdkszhUDOCJL6r3N8l5jag2nS08XNN1nbDSeJ9Y20v5ndks32hr4/hwmN29Xr4cDnPLtGlcn0q1FFlv1gVo1LYbjLpx/l4osF2LVoFr67ryYRHRNLoNg84ppt2nawHao3s1XacoGkHfJh/yiOqZCj7Rjzy65icc2IZsfjld8QNRFYOyNYauBXApJocEvHUVrhP5pE9n2JjDBdkoGUewyLc1h/k0RPpRLorOZlCJ8I7pMF1XSZDGm34Ef2ghPncCxy6DqoGwGRl7hJ2ii/jT9Om8Vi6TsW228niIiAKDvRc3fG8p+yyndGzL44VSQ3hipmEQ0rSGhvOCiuzI5OpHqCTUztB17pw2jaWlEj5FYYtqHsp7tUqajM87k47ofgyNPVrr2qBpfqZ3fKZpNWn2PbTSmq0vmyne7ruirmemZWd4p/9aZncdR+/QHXVyCm5Xgvbovlh2nnXtyKppAdpCOzOafqphXTS0I5rW6MlUJzz0dC2IqhiYVhK7Ra7aeBi2Lbwro6mnGPeYqYqbaMeRDKsRvIEdKeZeRAgLj2cmsbaPsXrNZU33Nzr6AGd2nshfC6Waf2YTw2CVrbNc2YJFic3Q8i+iOEUs7xa0u9vp7buS5hl7ldC6zzODfHEliqIT9m9JKLAl2cI7qNFPknFUCsKhRwM19wLFzDNYqp+bjH15reww36XyNdXAspv/fqDiHfQZk0SjqeQ4HRoIcE0Tg6kgYPPpp1IyR1EVA5fRTsZSmW0YDWkTBrA4HMbbpLDAV21+PmRZ2EKgKAphRcGyWhsEtp3HP2lfHbrOqrV00VhpmnQ0MUrKQjRU327udnNVE49Rl66jNwmL1/ZVHsYIN6/WbjQG1aYdVcYRwsLtakfXglh2pqJH2LYvQd9mtaKXiSx0mRQH/lhX7W/aacyhm/hkxxfJ6xGu1TQGbJsuTePktjZSts3lLcTEm71Mh50MP4v7OHEwW9feMaAo/F/MS0TkYJIwUmkt9xZTCDyqytfb2igLgUtRWG1ZPNniJbPVuN5L67GVY2Bt4smSfw9FUQj55lMKDTKafqa2XFM9TE8cjf4vqBqsT6Rh9yGgaR46ovvREd2XYrkfR1hoqoex9HOYdorTO47m8aLBO5Nu3Nu6DWbrDn8r5jglpKEIhxW2Sdq2yaefBp4irLjZQfdj2XmKTpEi0BbaAVMITDuJ4hi49Ahuox2/K0JEN5g2wR1eNnMMoSAmPXgdp4Q7eR/XdR/OT0eTPFUs4VYUDvV7OC4c5GdjjQ+muzIZvhOLcc5wY+7BlyMRhBBENI1t3W40RSGkqms16ioaQSky+dfJF1fjdfcQ8m+GoYeJhXclHNgKy86gKDq65kfXQk01sILvYTg289rkiyubNkJ3nCJ9o/eTaPsYjihj2bma3l/v4O3M6vriWr9rIprqoj2yB7rmZzj1OI5TQlXdxMILaQvuiNZEoFjxbYm/3EcstDOmlcYWJTxGB5ra2pzsH7mfmdNOJe3dDs0aQ1VdFJQAT9ou/ntglAP9O/Dp9p0xgKfKDvtaxdZFDaKMWxT4XWcnA5aFT1Xp1DRuzWS4I1vk0rTCLt6d8SjwcrLML2ICx2nubQAVTXXj88ykLbQLYJPOvU5/8mmGwp/kG4NjtYeaChwb3Jaj4zO5P1/mqnTlAf9UEXZzh+jxzKirNp+Iz7sJD6Uaz+VThQKfapEGEFI1XEYbLuNdva3bxob4TizGA7kc92azFIVgJ4+nUoiQTHJStDFF4JttbfgokcuvRim+hqN40EILCPrmtizC8Xlm0DfJJuqrCty+1cK4m2MYPNAkB3CRz8NKs/7456v9jUcnPfgHLAvLmwCaj8tltLVsZagq9bGAQmkVibaPkcq+3HT7kH8L3K4O5vScuE4dRFzld8i1atuWeoSejs9yQ08PZtWACqoq32uSzzvOJ5qcd13zEhi+nRs6Ps6zpsYyE7YwYHvDQiTvRu04ouEzaxMo/pjfT0RVURWlpm8ZUlX28fn4S775XA5sElZtdn8aR6ExEjLOJ9axIE3yr1GJHu1HW3gXyuYYquLC0MMYehClSSTiQx3bBv32jYSymcJxioxlXiCZ+QeOKKOpPtrCO6OpHvqHbuXajiP5RUpjSaGidfXZgIt9XUXaVFhYfJjC6GuAYAsjTjx+MCurhpgjSpQn3bjLVopVA9fX/q2g0t1+GJraqPGma37awrsykvp7wzqvESWQfZzvu92I0EwUHMg9SWmgl+8mvsgCt8J1WZOc47Cn1+CL4QiP5Iv8tKOD69NpVpTLzKyqrReFoNe2+cngIO+YJgqwu9fLd2OxlgLFxVIfb/ddVfMGpHNLGRx7iFldX8TrnobLiDZImzQjWL2ZLmlyM93d623a3zZbWN5yf/nC29jBHVg9eBuq6q4aLgK/dw7qewhRT0bXA8QjuxEJboPjWBUjVQ+gKs1DQoOOixmBbVk1cHOdR6Q7fih+72bkCo2hWq93E141Vf5rIEdQ9VAWgpLIclEigUtRuDtX5O4Jz6a9E2vPg8kKwVcH+gmqKmUh2M3rZWY1nJ4XgkcmHOdb8zrHBHcin3m6YT/B4E7kS2sYTtbnGbo7v8rJ/SMN3Q+uzhTYzN3FkknFGz8azXFbYn9WrrmcyZ5BQ49gGl0sLTd65YKq2iDeC7CP19u0BZtLUTitv5/9/X5+3N6OBvyzXOYHQ0MoioJfVdnB7eZt02SWy8VXIhHm6YLk4NWUy4O1/eQzTzN32sktuqEoxKP7cNZIvVfn1kymZccVv6KwncddVyABFYPgxEiEr/QP1i2/P5fj8GCQSyd5s14slTCjm6IojzatWo2Fd2U49UTj93vnUJgkdWPZORxh4/PMJD8p71NVPcSje6KprqYvL82wm6QZjFMq9+FVbEKTUjpOjUZ5LJ9vkELZzeNpKj2ja0HaQtvSN3ApOxod7KqHMIspiuYQPe2fblqhvqnLxU5uN89OCpWGVZWvRKMNL64RTePUaJQnC4WGce3q8TCjybjaNI3dPJ6m6ST7+Xy80GT5Hl4vM6ZEkcJHG03zoGke3EZsQw+lDnnmPwQsK81o5pm6t1fbyTM09iix8ELcRhyXKHCceJEvRGaCMHEV3yTqXcjI6EMUCstqnyubw9DSA1JBmfRwEzj0Dt2G131yQ1KnqrqIR3areI2Sj2E7BVTVQyy8GwOuzQmKNE7yfkqpJYCCzzePno7DWdN/JR8LbM2BHdsjUFHMAfLlLLdnPBSF4NBAgIP8fgZsmytSKU6NRvnqBIFiQUUKpZVAsWllWDV4c0OIRwiLVQM3MafnRAy9deuyieSF4IhgEIWKpMP4GPbyejkqFKKZbr82wVMzGUMLUlE+EzjVwpiAd1M64wfiMkI4jlmtjlXQNX/t7S1ZFXC1qDx026tdFSreinVz3c81HN5ZfTuTDZi+kXuY1XU8g4pCLv/u9eLzzaMjdhArCxbntbfjURQ0RWGNadKlmFze1cm3B4dqYXWfomCoPizN39RjqWl+gnqQxWGHm9PpityNEBzs17mySQrYDZkin+lcQLseZDT1eE0mIxjajbB/c0rFt/C5ZyHcPaiijC4sHigZLasTL06m+Vw4XGfcrbFtfpt287WuxfSP3E+x3IeCStC/Be3RfTikP0e3XsmR8ygKL5ZKPFMscnQoxJrqS4ag4v3Yz+fje/F400rpQ4NBrkqnuS+X475JXpqTIxHmGAY/74hTFAKPouBTVYbGltQZdeP0D9/HjM7PMzS2hHTuNcDB4+oi0bYIRY+yyG+xstq6LKyqHB4IsL3Hw7fb2vjt2FgtVDhD1/m/jg46NcEP2oJcnymSE4J9vS6ODYUIqwrzXS76qsdLoWIIfjYU4vlikecmGSSrbC+7dn6B3sGbsexKjpaiaLRH9sbvnUMy+1LlHlTF55lNd/yTZPJv1rVVc+lRvO5ugr5NyeRfZ7QqdxL0zactvGCtBVDNaCUoDOO/R5WymUIIE0UxMPQAMw2Dm6dN45qqrEhAUfhCOMxePl/TbhKqqhH2b4HbiDE09ijF8iBuVzvd7Z/C7epAafKy1a7rXJBIsCSf54+pFAUhWOTz8blwmOktDKvZhsH1PT1clUrxeKFAoCp3spfP11SoPaJp/Lijg/8ZGqr1XVaART4fZ8XjlIUgKwRLqnP8YiTCnl7vWjtmSKY2inivjvIbAel0mnA4TCqVIrSWPqf/CqaVoWQO807f1U3XK4rOtI7DKeLFpQdQnTyKolFWvFjmKMOD1zZ8piO6H5n8soa3ZKi0D4uGtqd/5P6GdfHwHiRi+zcdx3hrFEHFa5TFxydW9xJWVU4MudhMFziKynJLY2fzeXyBrRkTbh4tFEk5sLvHYIahU7JtjhpI172NfjUc5rnqw7QZP2lv59BJYYNCqZ/lvX9ouj3AnJ4v11XAFhyHlONUwr0q6KKAEAJNdfGqqbC4r4/PhULs7PFQEgK3ovCPYpFr02ku6epiE8MgJyr6bTFVZag0zFjfxXh988C/PShapWtF5mnc4b3oCmxFUlQS4w0FYmollFM2RxlK/o1s/nUUxUVbeGcige1Y5bj4/tBQrQoxrml8NxZjd6+XYIuE7XTVEFxjWbgVhZmGgZV+nOHkkqbbG3qUROcXcISFcEooqptXTZ3XyoIeQ+P80SRD1UKRrd1ufhR1E3WSDOjTCKgqKpV8HkUIgnYv2cHr6yodFVT8HUfznaSHNk3n8+EwZw4OsoPHw5m+Ee6zYvwiWe8V3cpl8H9RiKtgTwjXZXOvkMm+SKDrJB7Jl3ggX8krOyYcougIvj44SLMMIR34VSLBG6ZJp6bRb9vcnsnwtmlyY3cX06y3cFWN5Ez+LVTvfN4WQd62bP6creRO7er1spvXw2xNwVR0ykKQcxwCqkpM09Z6Pm5Kp7lwkmdsG7ebCzvayTgm16cyvG7abObSOCPsYc2aP2A7RTzubhT3LBRRppz/J5adoy2yiHhoGxyniMBBVVzoWghV1bCFYMi2KQqBm0qOXd5xWGWaqIpCxnFwVRvLt6kq3S4Xpl1i1K70QgkoCkGjUuyRqeqfZSfNsd80WWlZ/C2fJ6yq7O3zkdB1gqqKZWcq9wNho+sBDC2IWs1ltOwcjlNEVT3VFAgfjmNXWtY5eRQ0NM1f5+Gy7Gz19+htmkP3XpTKw7y5+nc0y9Xsin8KhM3A6F9wRBlVdRMP70Y0uAO6HqBcvTdo1XzHdcG2izjCRFWMln2RJzNi2zhCEFbVdSoUyNs2o05FraBrHapF01UNv8nnESq5fun3OUfJfxbvx06Rhh0frGFXNscolYdYOSE0OplpHUeS1eIc2JejXdMoC8EuXi9fV5+uE9ccR1O9TOs4gr6Re+vkBww9Snf8YHqH7sARJh5XJ0JYFEprAEHIvwXTOo5cp16MRcfh/42McNOkqq+5hsHlHX4ezFv871h91dX2bhcXtEcQGDxZKrO0WGRzt5sFHg+f7u1t2l4H4CC/n58mEnXLCsVelq+5tOX4Znd/CZ+n0ghspWnyu7ExHs/nuajdTzD/D/LZSsjb75lNrO1jfHPU5vFi87yxm3p6+MXICE8Ui3gUhdOjUTo1hXkujRvSGW7OFikIwS4eN1+PBirSEyXBRWNj9Ns2HZrG16JRDvKUeLv30ob8NF/nV/jiYLEhpwngsq4udm1SUTliWfQWU7S7fJRQEUC7IkiO3Ucq+yI+71wc//agGCilFZQy/8ARJjOmncJ1OZUuXae/KrlwVDjMtwcbvUbTdZ1rOttQnDI5YSFEJdzoUl2MOjoxJUc59xKlch/CSOD4tuGnKYu/Firz29Qw+Fw4zG9GR7kyZiFKy7F8O/FgwSblCPb1GnQ7gxjFVzC0EKrqrnWLSGVeQosfzolDZfomVSV/0u9njsvVEFoE+G4sxqaGgQr4VJW841B0HJaWyxzod5Pv/WltW5cRIxA/ggtScH++3i/brmlc0RFgusuHrjUPn+cch6zjVIx9TUNTFDK2TZ9lcW8uR8a22d/vZ65h8EYpz3mjKY4NupimK6y0BPv5PKT7r8SIH8HjZYMHCw4BFY72a/TYqzHKq+mOHUzZTqMAiurGrbdW5X+qUOD4vkaB5Jm6zmVdXWTMNIbII4QNmh+3GqDD5cFo8nsfsiwuHhvjnlyOTV0uSkLwTrnMzxIJdvJ40BSFEdtGUAlZ+9bFUHGcyovBhOO1NsZfXMb79Latxai2HZNs/i16h26tCxNHAjsQDmzJO/3XNHymLbQLibb9UNcx3PteFKtt00arbdNi79E2TSJZn7wfO0VelR8wCnpTF/5ENNVHQHNxe6cAcxBFMdAMPz5zelPDznHKCOGQaPs4iqLiOCaqqiOEQFFcxCN7oms+8sVVqKqL9uhepHOvEfJvSdkcIZN/HdspEPBugsuINc0d8agqx0ciPJTP1wRBofJmOCbc/O9YsuEzz5fK3JrJ8eVImMODQQ6veuGGLIu4ptHbQldpPGRReccQKIqKpvlRFAPRRHqhIhdTeQD2mibHrlnDiG3zu3Y/rtFbyJrvGjG54gryay7lnM7j+cxgY/eH+S4XBoIvhTS+FTJAUXnVLDLb3cZpAwNoisLxkQhuReHlUonj+kb4Q1cXPx8dqO1r0LZ5vZRjh/xjDUad24jzQrmi4zff5WJRtbfuy6USD+dy/GxkhIu7uhpU4oVVwm0EOH90jL8XCvhUla9Ho+zm2QS/f3vuKbq4aaxM3nHY3bs1X03sQCD7JHnh4oFcihWmySzD4IRwuKVO3wXxMEVhcVeuxE3Z8X25OSmsMU1XSBZHUX1bcZvYmtdNm7/35+vqHN8wTcLVPLWkEmaebxOyhec41BwFBGreQySwNXp4DwqlNYymn6RU7aMaj+7Jy7ZBn90YCP9TLseFfn9DhfX+Ph87uN2stCwuSSZZYZrMNgxOjETY2+fDXXqTif5Cj6ubXsfN/flkw3cM2TZXZkqc2eZpuAlaQvCOafKbsTEey+fxqSqfC4U4IhikJAT3ZbMsrxYx3JPN8oVwGFs4/DqSxU7/lbI5QpcRQzP2wdP5JY7vH6VvQtXukjwcFejiW9E5DCUfJZV9Hscp4/fOpT26D4YeQ9fqRzVq2/x0pF5DbpyzY23Y5TWI4VvJV4sbFEVHCe9FStmOuKsxif6RfJ7rqi9tE/UdT+7v59Zp07g/m+XGTIa847CXz8cp0SgzDKNpf1tLCN42TX474Xh9PhTisGAQn6LQb9vcl82Stm0WBQLMNQxKQvBMscjVqRRvV8/jf4XD7ODxNA1HZoTKg1YH8zpOwGePIkQZxejgryWVhaLSQm6yN280/Qxt4QW41ca0iqLjMGTbLC2VyDoO23k8tFc7OTQjWfXW/m5srJYm0Klp/CKRYItqMZhE8lFBeuz4YD12JXOEfGElQ8lHa90nJuJ199DdfigjqadITtDiUhSdnvbDSGWXksm/VveZWHhXHEcQ8M2mbA5XHpZ6Gx5XO4rqZWjskYYKwY7ofnjcXazsrw/tet3TmZ74TMuKtF7T5I5MhgdyObyqyo/icR7Mprgo1VwjKayq3NaToNOo94LclE7zoybVsgpw57QeupxhxjLPYduFWtuhdP6f9I/c1/CZjuj+RILbUCiPcV3Ry6+TWRKaxiXRAsXhG5uOy+edyzuBT1JUdFQqj4DnikU+GfDTbS5neOSeWtcIv2c2K8OHM+YIRmybP2WzZB2HXb1eDvD7eSCbpUPXMaHmGVvosgkMXYIQJoYexeOeBsJEUTQuVfZgB6+fEdvm7myW3IR9/XxkhIs6OzGBghB4FQWvojBk2xyzZg2FCT/PfX0+vh0N8Z2hEZaW6w1ej6JwXVeCfltw8kB9p4mTIhEyjsMcl4u2aq/Qt8tlDvK7+PrgaNN9Xd8VI1B4mYJvO94yKwHZ+3M5/pLL1YVIv9HWxhzNZCe3zsDgLZQmyWUois6sruN4p++aht6g/ujH+GVpJg/kG3NGPxsMoisK92SzuBQFSwhu7Ori3kKBC0cbBZq/3tbGoT4P6eJblLUIGhCkzNV5P1dnml+rPkXhrmlddBn1obY3y2WO6u1tKKy4paeHHwwN8c9JGmQeReHa7i6Uvt9iOe9+l8+/NX9Ud+eGTGOu4m/b/UxL3UmpXO+BUxSD2d1fwuuu92D3WxYfW7myITzdretcn/AxuOYPTQseIvEjifjn459gsPSZJsf19bG6xYvWSZEIfy8UamkDUJEruqmnhzlNCp1aHa9t3G6+1dbGFyd5GX+XSPBKqcRvm7Tv+no0ypHBIJFJnrClxSJHralcW22qiltRGLBtHODEkJdDzEcoFBp182Z3n4DP01O3LO84PJbP889yma3cbmwhGHUc1pgmXwyHm+am3ZvN8q0mXm+fonD7tGl1SgPrimllcJwiiqKhqb51Dvm+H1K2TcpxsIQgqKq0fwAexnLVSC5W71/tmoYxhTTrPipIj91HCNNMks69Qk/7YawauLlOh8nQw3THDyFXeLvOqINKkcDqwVuZ3f2lqijtu7f0oH8LHLvA6qHb6qQkVMVgeufnaknPExkce5jpiaNRFK0SqqlSKK1iLP0s7dG9m5Zo9xgGX41G+Vw4jEalD+D1qdbvAhnHwaHx7XU/n49n/X7umZB0rgPntbfjL77BiuFb391H/jVcRhszO7+AoUcYHHu41he0o21fPK4u3um7BsW3NY8U5wIVbS6t+GKLUSkogZ15vmxzXbqSeO5VFI4MBokpFgNDtxIJ707ZMw9VWPjMXhwUnsnnWOSDX7YBQpBBcEs2xQGBMFFN4yfDwyyvesa2c4fpCO+H4p7GayLEvbkCQVXhiKCPY1SN80fGeGqCZ+TWTIaHczmu7O7mqnSaG9LpSj6VonBUMMgePl+jPpUQvG6JBkMMKiK1v0qm+XyTH/zlqRR/7O7mjIGBmtf0Z+3tvFUut9zXb5I5PunfmrPXDNYMzsOCQc5tb+f7Q0M1z90cw2BT1cQ0hxuMusqYHYZTTxAN7YDjlDH0MKaVIpVbSj75CP/VcQLPFk22cLspCsGLxSImFW/Ivn4/u3u95KpGaVlRuKhJeBYqhuorhsFPkkF6rcpvYqHHwyltQR4qFFt6iy2h8mShwPJymbkuVyU8nUpREoI9vF62drsrYUrTpNc0G4y68eP1u7Ek344dTHro3RcLx7c1dw03VmInNI0ZjFEoN4ZVhTAZGnuERPxTdWFZDejUddZU59GhquSppDEU8sta9l4tpB4l5J0BE/QPLWCNZdGt63w2GGSmYSCAvxUK3JvNstqyGvK0CkLw67Exzm1vrwvLZm2bC0dGmlYXv1QqMWDbxDWNtONgADkh6NR1zmhiJAH8Pplkf7+fyKTlt09ICZmc0nBrtsSn2raHSYadqrpR1UaDa6gq0/N8scjFVeNymq5zcjTKK6USe08yfoYtq64V4UTyQtTSHdYV2ymRK7xN/8i9tZd9v3cOXbFPoOshbDtDvtSLY5fweaaj68GmYuXvxYpymf8ZHubp6n1nuq7zg3ic7T2edQqtrwvDlsXlqRQ3Vu9fvmqByudDIVm8sQGRR/4DxtBD+L1zSWZeZFrHEdhOkbI5UqvodITFaPrJFp8WpLOvMLv7OPLFVThOCY+7C1UxWDNyR4M+mCNMegdvpyO6L2uGGxu/Z/Nv4PfMJlt4s275aPoZoqEdW1aZTk7I3cfv4+Zsc+2mnTxu/E26L8R1nbPjcb4cjfJCsUhAVdnS7SbsZFjVe2vD9mVzlJHUUyTaFuFz9+AIC1UxUDUPQ2NLKJnDeEWpJuRacBycahsoXQsR8s9DUQwKpV6E0clVhRA3Zd/1mBaE4Jp0GoMgR0w7k1uyWZaMFfAqBp8PbcNWusbpwTKjQzeTHg9voXFiZC9W2Fvg0oKcGYtRqN7MlpZKdPu351uDg7w5oWrwtmyWL4RCbO3x1Bl2AAcEAlyeTHLnBIX4khBcnU4zbNtc0tlJu15p7aZRyUFqZdgAPJ7Pc2ZbG/dPn44pBIaiMGSanDY4iA/4fWcnKcdBp+LpuXC0eWgP4K/5AgcEgjWPYUEIrk+nyQQCfDYU4vp0mrCqUhKCC9MOX1deBSovK7pvS3QtgvDMYRQPQ46gR9dxYTJm5fF5FLpDu5BLPwd6gN91hsk5Doai4FYUXimVmG4YPF8sEtf1Smso0ySh600NiISmsafPxw3pNN9qq4TdNEVhyLK4YGSU78Ri3J7J1MLgLxWL3JnN8jGfj6tTqVpIEioG5U/a2zk4EGBJPs9D+Tw+ReHsWKypkPE4jxUKfCM6k2D3aRTQ8CngYGDT37Dtlm43WqExxWKcbOEtYk6ZFSWdIdumXdNo1zROjURo01S6DIOVpolPqQgml0cbDcRxyuYo6iShYA04Ohhkgc/HxWNjvFouYwCL/H5+mUjUigA+HQziUBHavSWd5q/5PGnbrjfshOCxQrO68gpPFfJc1dWFAthU0i1GHaelqG5BCJJNUgdyaxHbLQhRKW6ikqbhCe9L2bMJ/baK5QRIWFZdLtyY43D20FBdislqy+J7Q0P8KpFgxLKITdjeggaN0Ym80qKLRCuKpT5WDdxQtyxXWM7bfVcxo/NzLO+9hIlh5bB/SxKxA5umzEDlmA7ZdsV4VhSiqkrOcfjimjV1RvAqy+Ir/f1c193NNp5/3zuYsW1+OjrK3RPuX3kh+EMySdq2OT4SIaJp68WIdCbOEYhqGmFZJNISadh9gJTNFCsHbqBsVkJHyewL6FqASHB7TDtLOruUrtgnMNeiQm/aKUZST1Es9aGoBsOpvzOra3HTfqFQ6Y6gtUgGr0iZNIZSbKfI+4nIz3e5mWMYtTyjcTTgW21thFu8qUWqOSybTAjn9I882/J7LCtLyRxiNPUUxfIAblcHsfAumFbFqDRzSzk2ug1PFSs9PkV4CzqNIKriIpVbWs1bmo3fvy1PDjR6Tgxgoc/P4r7+uobrLw4NcW9XkKGBa+py/AQ2Y6m/Mat7e/7f2BgPVaVTFGAfn4/N3e6m4a1r0ml+kUjgVZS60OqeXi9fmxQ2Hee+XI7F4TDHrllTy+U7IhAgsJab5M4eD4VqDtjbpslMw2BPr5ebenr4Sy7HrybIZBwWCBBSW98YfVWNusn8OZvlN4kED+Ry/E88zoWjoyR0HUv34I19mhVKgr8U4FBfkO8PDtFnv2tM7+X18ulgkO/1D3FIwMOXQnvyfNnhwtHhWgHFDh4PZ7a1YQFXplJ1MiyntbXxpXCYyybor33M72dxKISuKOzh8/G9oaE6KZAzYzEcIdja7eb/RkbIV8PgP+3oIKyqfGFSmLDftjlvZISjQ6G67gwPVaUkWuFVFBxF43fJck3H7viwm4/5/Q1tospCIJTWD1ZVMei3HdY4FqYQrBGCJbkcB1e7ZFw/8G7F8K4eD+f6uqGF2LHLFaPXEngw6dZ1dEUhoescFAiwuK+vth8TuDeXq4RIOzs5Y2CgJoYcVlW+EomwldvdWHglLLyq2rI7QlCpFLhcl8lQcBwWer1s1kK3cpxmxR6fWIsQ8D4+H1rpFUDF13EMF6RdLEmOb5uhW9e5qLOTTVwuRLX92kgT41FQueb+X3u9JJQOzDIM3m5h3DVr5TbOeHXzeOeJGCX6Rx5ouq1lZ8gXV+HSo3X391TuFXzeWbSFdmr4TNZxeKJQ4Lzh4Vqf2QUeD9+KxSq9uSedFwFcODrKLxOJppI+74dRx2naAg3g5kyG3X0+/pzN8s1YjM5/w3uXsW0eKxQ4f2Skdp/ewe3mx+3tLTVQN3ZkIPwDwhE2o+mna0bdOJadZTj5N9xGlK74wSiaH0+TxvXj6J7ZJNoW0RbamaBvs2png7UbYa3CMj7PTIqlRg+CzzPzfVWOdRou/tCZ4OhgAHf1Jryd280fu7uY61rXhloVHKf5267X3UPAP5flvReTzL5AsdxHKvsiy3svxufpweeZgWWnmSXWcIjfjQl4NC/54mrWDN9NrrCCQqmX4eRj9PZfxa/ingaF9o8HAtydzdYZdQBbuFyYxbeaFm54Qntw/liGv0zQwxNUktF/MzbGF1uEZB7L59l50ltyWYimkh5QCbz3VnXMxvlTLseCFj1J5xoGx0UifH7NGi5OJnkgl+OSZJIT+/tZaZrcmsnUtUm6dy37Ajg4EOChJg9SB/CrKt9pa+Pno6O8aZo8VyxCcCG/K8Q4bTjHHn4/Zw4NNVS7/rVQ4LFCgX19Ph7Jl3ndgu9M2u4fxSInDwwwatt1LevyQnD+yAhzXK6a8OpZsUq/5B8PD/N6ucx5IyN1c1xpWXxncJCwpvFqqUTacbCoeNdOHRgg7Ti163cib1S9gxO5MZ3mU2tR8j8sGOTPmQz35HK8Ui5zTzbLf61Zw4mRCOFJxvizxSK6f+uW+woHd+SJosIZAwN8Y3CQMwYGWG6apIXgpnS67pp5slgk6ZqDojTP8YpH9uGKdJkjVq/mzapnKec4/HpsrOm1t9KyeLZYrPOMphyH/xsdZRuPp0G4OUyZIwKtf/N7+X0c09fH7ZkM9+VynDM8jCME7S2Mii5NayrXMd/lYqsmD3GfonBKNEpPZEemdX+Fq/I+lhTqIxlrLIsT+vror15PzQR9x1laKjUcl7iuc0ok0nR7n6KwSwvv14hlcXUqxRGrV3PQqlV8treXIatEsUkIfpxCaQ0uV6PY7XDycUyr0Yh6pVTijIGBmlEHlV7Hp/T38+1Yc9Hcl0ulut/Jv8potWq6GRYVT++fczm+OTDASItUiHXh5VKJbw0O1t2n/1Eqsbivj761eFI3ZqRh9wFh2zmSmedbrs/k3iJXXMVAcQ1GuHlTe0314rhn4TIixCK7kmjbr5JzoQVbNptXUFGVxhugS49i6OEmnj6FztjHWko+tKLbcPGdWJx7pk3jgenT+W1nJ9t4vO+772sosGXT5W2hBQyMPEgzI3Zg9C+0hSqN7Qsjd3OCaxU3JoL4RI507pWG7S07i5Z9gk/662/AC73epsZLQtfRzUYDGMDyzOOhfPMHw+OFAtu1uMkXqm/sE2nVCqjV+vFKwi81MR5Pjkb54dBQQ6iyJARnDQ2xeNKDaXxfxzfZ16aGwR4+H4+2aHvkVhTOHBqqeXQMRWG1o3FvvkRYVbGEaDCWx/lTNssiv5/Dg0H+0CR5Hip6YCtNk7lNEtKvSqX4bCjEHl4vY1Xx608Eg/yxRZg0JwQvl0oN1Y5lIbgmleKQFi3FJnsrp1UlVha3OF6fDga5ZFInh119Pu7NZLigo4OjgkFm6DrzXS5Oj0bRtDDe0G4N+zKMDgq+7VjjvNtXxAbuqRrqn2/y/f8zVqYj8QUM7d1UCkXR6WhbhGWlOCZokBeCHw0Pk6zqoD23FuPm+WKxqVftD2NjDZ45Wzh81gebGI33o69EwizJFxqO5fkjI1zQ0dFgVHsVhQsSiaZVsR26zq86OzkjGiWhaQRVlUMCAW7u6WGGYWDoYTJalNubFKpApQp6pWmiKArT11Lo0KFpDb+7guOgKApfrlbHj9NdFYdu1pM17zhckkzy09FRktX1I7bNK+UyepMe0OMYehC7SaV4RSy8/ntGbZsLWlRKD9k2A5bVtMNGu6atl1Cdbx3vXy9Ucy3/FUar4d5mDNs2L5TWLta/sSJDsR8gE4sUGteVKZRWYVspBsJHkGj/LOXR+zDtygPK456GEv0EttqY96ZrATqi+zAw+peGdbHIHhhGtNbKR1E0wv5taI/uBYpKNLQTycwLCGHhdU+jM3YgbqO9YT/rgltV6fo38yfcRhyvewaF0sq65apq1BWaTKRSSTZ+6QqKY/fTEdmH7FoawRdzSzkoviu3TXjpFYCqKDDpwdNnWVj+LqCxGCMr1n4za9UUfB+fr+Em3GdZbO5yNU3In+dyNc3ruSqV4n/jca7o6uKeaoXtAq+XHl2nv8XNc9C2m/abHN/XTV0d3J7Lk7IFB/rcbOb28P2hkaYenc1crobSmO3dbu7PVY59VNMYWMvb+biW4RyXi0tbGHYAr5bLTXujLi+X2cPnY2u3uxbG7tZ1lq8lz+m1cplCk/PyRKHAwYEAkyXANWgwOrp0natTKT7u97Ooq4u7qpXS+/v9bO5y8eX+fibPeh+fj58MD3NJKsU+Ph9HhEIUHYdey+LCZIm5+pYsSsxDy7+M6hQxvZuzRolx9kCl5/Jk/pLL8ZtEoi5EDPBiyeTqQpiTEkdhOXkQDgJBMvM82fybxLs3AyrFDCnbRlUUIprWNBwJlZSJ/ibn8I1yuUGLsqj4EeU3uDAS5U0R5MGCIKzCIX4Xq22Nbw81Gh4vl8tcl0xyS08PD+dyvFqtTt3f56NnLUZXQtc5PhLh0GAQQaV7i3fCdV0SomXHEqBWePKpQIBLk8mm1/eXIpGGytGU4/C9oSH28vm4oKMDWwh0RWHYtrlgdJQ9vV6+O+mFbsS2ua7Jy8Y1WZsfBRdiJR9s8u0KPs8MhpOPNazxuqc19OMtC8Fra7nu/1kqMcto7EF+YiSyXgobYprWNCUHKuHp1yeM7a1ymS3WErJuRclxWLaWOT5dKHBQi5ezjRlp2H1AaKqXoH9zUtnmlZp+31xG088QCy0g5PZzbbqDraOfo0uzAZXHStDlBNmjaesbnUhweww9zODow5StMQw9Qkd0HwK+TdA1P9MTR1WLKxR0zVerDutsO4B4eA9AoKquf6naan1i6EGmJ44klX2Z0fTTOE6JgG8zdK112AtAUX14/dtQLryBqrowPDMpNvHWvYuoNeIe59VikU/4/dw4SYT5tXKZcttsVMXVKDasrD2EMfk7ALZ0uZhrGJwZi9WMsV2rxtgP43HOHBysCztO03XOisWaigpDxSB8pVRiyLZxKwqXJpOc375249xuEXoZtfK0W8v4un8WoFIorSA58Dw/jB/NyUN2Xc5gj67zrbY20pOMJEVRcKr7H7SstXpEgqqKSUUXrH1CledkOjSNl5qsm24YDFkWlhC1cYx/54oWYZlZhtG0T3CgRa/Yw4NBluTzhFSVzarivQOWxe5eL2cMDhJTVU5ra8OvKNyeTtMRjTatutWAMhWP20PVQgyo9Ceebhj8KpXjkrTCAu+OuBVYmiyzxsoR17S6XMxxBLQU+e7SdVLZZxmZVIjlcXUxMuFlRFDxjB0WCNTlKk5kV6+X65qsm2YYTD6zqqoyqM8mllvCrFIvX3N3I2wTLePhWnZvun+AvxWLnAGcEI1W9TfXTQdOU5SWosBeRWnQPpzI7Op12aXr/Kyjg+8MDtYZgp8OBNjP1/x+KIAHczkebOLh372ZwLht08xsfq5Y4p3gJsz2ryE74X6lKBrTOo4klXm5yacUOtsWNeROq1S8b4MtDPSZhsGqSdf94YEAe7eY4/slruv8OpHghL6+unSKGbrOadEoZ064f/2rQs5aVT5lqMUcZ6/lXrMxM2UMu9/+9rdccMEF9Pf3s+222/LrX/+aBQsWbLDxqKpBe3RPMvlltX6i43jdM/B7ZhLwzq3pxx0XqVTAPV8o4NM09gu6ade0lqFNXfNV9N48s6g8OtQ6LTpd80KT8Kqq6rjUdS/N/zAw9CCx8ELCga0BgaZ6sO0CmuqtactNRFXcvGG7uVvZld3bFlIU8Ie04AfhrclkmhdjeH1bUlK9XNDhY41l0aXrWEIwTddZks83hAruzSsc1/lFhoduqTVqVxQdHya7ejw82SSUtYPbTbuuc6Dfz98LBfyKwsGBANt6PBQch3OHh9nL56ND13kwl+PadJqrurr4VlsbJSpaZZ26Treu0W/ZTcOZBpVq2nOGhni+GoZo1zSimtZQnDGOu9ofttnyfb0uhvqWMJR8d7muBZhOnnPjMQYdUTtephD8MZXipEiQuKbVxldyHA4Jhbij2rIr5zgt3+SPCoW4O5Mh6TgcHQzy8yZVvhqwwOtt8EwBfD4UwqIiMeJSFMpCcHsmw+dCIX7SJCzlVhS2cLubylV8NhRCCEFAUchW//v5UIhDgkH+USyywOvlhWIRv6qyfVXAdsiy2D8Q4B/FInnH4bBQiLCm1R2PcZ4tFtnT660ZdOM8Uyzy+VCIG9JpCkI0hLwPCQS4v0WhQLOcwLCqstDrYWSksbo+FN2PnyUr1+oWLhfh6nWyp8/HS5Pa/CnAD2MxHshmG7yPUOmHawvBn7NZXiuV2MLtZhu3G1X18aixO3sHBGWzD0X1UNA72NP28KcW89jT6615xtbVqHsv2qsevWbneq5h0F39Pq+qspfPx5+mT2dZuUzWcdjK7SbeotIyrKoc5PfXVa9P5FNNPEbNXvDGOW0oy8PTDiAR3YtCaQ2a6sHjSqBrQdyudiynQK6qXOAy4nTFP4HL1fjiFtc0vhSJcF6T614HPu7384lAgNfKZXLvMcd/lVkuF9f29LCyKgUU1zQKVQ/nWPXFq01Va3mx75d2TePESKTpb9sA9vG37tSyMTMlDLsbb7yRb3zjG/z+979nl1124Re/+AUHHHAAy5Yto6OjY4ONy6W3MbfnRIZTT5LJvYaqumgLLSDk37xBEHi8YnTT91nl06oE/j8NRVHqjomi6HS3H8KqgUbB4c74J3nEdnNrdpSbqvfakKritLXh9c2nMEnQWVO9dET34tuDKVaaJjFNY9S2iek6FyUS/Li9neeKxUqHB0XhwECAHd0uMopKIXYMAYoIYeOoXgqqn/9uNzh7aJh/THgobud285P2dpbkkgRVlW+2tVXy2AoF9vSodGs+vhuLcWs2S8402dvn46BAAD+Cv+QyPJIvEtI00rbN3j4Pp0VjHBcOc00qVXvzD6sq/9fRge5Y7Or1ckIkQlv1bTZlWZwWjfL/muSjfC0aJVOVCRg3tWKaxv91dNAmhhDxT5HKLsURJfzeOfg8MxCqi58PJ3mrXKaterwSus6vEx3o2ee4vC1OQQmgK+Aqr8ajBdjP6+XhQoFfjI5yfkcHlyWTNQ0tT7XxfELTuLRQYJZh8HG/n+WmyR0THphuReHc9nY8VMK64+FCA/h8OIwATMfh4XyegwMBbs9keNM0yTsOx4XDXJtK1c3xpx0drGpiYG7ucvHpYJBb02nOaW9Hrx6blaUSGnBnJsNzk/J3vhuLsa/fz0n97+ZfXptOs5PbzcWdnRzeW9+7+Z5slqu6u3myUKjzIpWFYLlp8s22Nn426Xxt73az0OvliiZG7Q5uN35VJay+20FlM5eLc9vjxJwcltFOyRwCqhGD6MfoVeI8WhjFrSicE4/XOpx0VV9APh8K8VKphL8qP5SxLD4ZCPBIPl/7Do1KiHILt5tDe3vrPLZhVeXyri56XEGOGxrGr7ZTFIKoVuLCjnDTVAOvonByNLretNTGMRSFz4RClByHq9LpmndzV4+H/2lvrwuxelSVaaq6TsLCXlXlpGiUv+XzDRp6B/n9TfcR0zSm6zqrmnhyZxkGiurFowfxuOqfT241xvSOI7CdfLW3rhu9xT1eVRQO9Pt5uVisM6A9isKFHR106TrudZzjv0NC10noOrMMg7MHB/n7hPtim6pySVfXv1wVqygKB/j9vFoq1d0nfIrCLxMJOqXkSVOmROeJXXbZhZ133pnf/OY3ADiOw/Tp0/na177GWWed9Z6f/yA7T1TGY1U9Twq65l9vb6hTHccpUzJHGU4+Rqk8iNuIE4/uictoo4TBiG3Ta5p4VJWEptGu65SsLPniSjLpJ3GcEm7ffGLB7fC52ugzS/TbDr1mRZy1U1Np1yshvPuzWRwqIZewpvExvx+fMCmhkhaVtkl+VSGIYNAGv6aRcRxGbJs2TSOkqvw1l+MAn0ZOVJquG4pCTNXIOg4hPYAClKj4V8d9qWHFxBQ2Y0Il59j4VY2o4qCjUVR0kkKh17LwKAodmsZAqcAaBzZ1u7k3m6UkBIcFg3gUBa8Cy0yL346NVSQ3DIOTo1Hm6+BSDTKiErZ0qypRVSWhKGjkGMu8gOOUUBQV4diEQ9viMTrotSvzGxezbVNVlmQyHBR0U7azFEr9aKobj6sdQw1QUjReKpX4YyoFQnBiNEq3rpNzHMJapbH9snKJHt2gXdOY5nIxbJYYdSrhb7+qsInhQgXOGBzki+Ew/qrsik9RuDeXYwe3m7mGgV/T8CgK/zcywl+rOmqfDAT4VCCAoSgYikJQUQipKvfncmzt8fBgNkvacdjP78dQFN4qlfh0KMRIVR8rVG2sfkM63bRPLcBvEwnOGBhoyOU6KRJhP5+Pi5NJllcLP46LRCjbNmFd59p0mkfzefyqyrGhEPv7/WhUEsAfzOXIOA77+HzMqooFf21goC5/aguXi18kEsRV6LcFKcfGpSiEFIUuw8WwaSJEAVUUEMLB0Lw8W9L5TTLJjl4vx4ZClVDqhHtPb/W6f9000YH9/H62dbsJVz2TA7ZN0XHoMQxcwBf6+pqGnGfoOld1d2MLQWqCllqbrtNvmtyWzXJTOk3Ocdjb5+Or0SizWrQnWx+Uqj1dM46Dp6rB+e9Ke0DleN2dzfJgLkdAVTkuHGZrt7tlvtrrpRL/1ddXK56AisF3RVcXc9ejTEfKrnj3XyuVCKgqm7hctGsarg3Q/WGket28VS7ToevM0HU6df3ffual7co99Y1ymYCqMsswaK9qXG4svB875T/esCuXy/h8Pm655RYOO+yw2vLFixeTTCa58847Gz5TKpUoTXgbT6fTTJ8+/QMz7CT/Ho5j4ohyRaB4HWVZ8lYeRzh4NC/6WvTaxklbFslqA/MuXUdXVRwh6LcsNCFQqRhlAAesXg1Ucs7mGQavmyZFIfh+PM43BgZY6HWzj1slK+DOvEXWcfhjdzfTDYNsNfcmoKp14dGCmQcsBDo+o3UOzLh4a0BRyDgWChVPhWqNsLz3DwS8m6O1fQJLMdCFiTN2L5n8q8zp+Qped2fTfTqOje3kqh4CV0sdxLLjkBUCF5U36fx4qGVSw/d+08QSgrim4fkXHqhFx+HpQoFvDA5SrB57G/hMMMjXolFUpdKgfsy26dB1So5Dn20TUVXaNa0mhtupafx6bIxLUylcisJOHg/eap/ewWpHhJt7euryfwYsi8/09rYsLDgmFOIt0+TJSaK8cU3jtGiUl0oluqq5gw9X2/BdlEgwzTBIV4WmY+vgvRixLIZsm0HbpqMqUPxenys7TsWIEKLmDStTuVZaPeTtaq6iDgTXcq5eK5U4YpJHciK39/SwWYvkeFtUWvMJKjmW69tT92EyfrwMIPAe17ao3j/+WS7zRrnMPJeLeS4XXTIvTPIvsFG1FBseHsa2bRKJ+t6KiUSC1157relnzjvvPH70ox99GMOTrAdU1UBtSNteOz79/SUIh3SdyT8VVVEapBdenhBm6LWsOg/GA9ksv0ok+H8jI5xbeLet1fcTiVpBQauHgXctxtxEJsp2RCcYuXmzYohkC/+E3n82fK6VtiGAqmqoTaqvJ+NSVSa2U/e3eEB3/psPLo+qstDn485p01hhmuQch81cLmITPC/RScdxsxb7Gk8sLwvB3ycZY6lqr9GJCCregVakHKepzEOqWshyy6RCnDHHIS8EHlV9X1JAMV0npuvMX+dPVM5Px/s0mjRFaTiWzWhVtLEu69dW8PCfxroeL6i8/HQZBl2GwX4yF0zyIfKf++r0b/Dd736XVCpV+1u1atWGHpLkP4SoprU0MR/M5djc5eKa7m7unjaNe6dP5+eJxIeijq5rPhSaP3AUVHTtP+vBYigKPVU9vQMCAWa7XP9SOG3RWh6oC7zeWku6cXyK0iAkPZEdPJ6mEhM7e7282mS5AU0Fd//TaFvLde96H8aORCL54PmPN+zi8TiapjEwqTXTwMAAnZ3NQ09ut5tQKFT3J5GsC/FqlVYzjguHCVdz/ea4XMwwjPWS27Mu6FqAeKS5vEQsstt/nGG3vtjK7W4q0qoD32hrawg/hjSNb8RiTUMZMw2DmKo2SLTowJcjEe6Y5K2DStFBfAoYPXFN47gWXVVOCIenxBwlkqnCf7xh53K52HHHHXnooYdqyxzH4aGHHmLhwoUbcGSSqYhHVfl8OMz/xOMkqg+zDk3jnHicL4bDdYKpHyaqatAWXkBX/FM1DUBdC9IV/ySx0K7vq2XcVCKh61zW2clngsGaEv72bjfXdne31MCaYxhc293N9tWcMZei8JlgkMu6utja7ebIJvuao+t8va2Njuo1kdA0fhSPc2w4/L67sXwU8aoqXwyHOScer7UDS2ga/xOP8/kpMkeJZKrwH188ARW5k8WLF/OHP/yBBQsW8Itf/IKbbrqJ1157rSH3rhkfdFWsZOohqs29TSEwqiKaH4VqZyEElp1FCAtF0art5zb8uDY0RcdhrJpT51fVhhZjzUjaNjnHQaUSgh83Xlrta/yaGG/4/lG5JtYnQggGbRvrI3bdSyRTnY2qeALgqKOOYmhoiB/+8If09/ez3Xbbcd99962TUSeR/CsoH9GE8Ml6gJIKnn+h/d24tuS67uujek2sTxRFITHF5yiR/KczJTx2/y7SYyeRSCQSieSjyvuxU2RihEQikUgkEskUQRp2EolEIpFIJFMEadhJJBKJRCKRTBGkYSeRSCQSiUQyRZCGnUQikUgkEskUQRp2EolEIpFIJFMEadhJJBKJRCKRTBGkYSeRSCQSiUQyRZCGnUQikUgkEskUQRp2EolEIpFIJFMEadhJJBKJRCKRTBFkN2dgvF1uOp3ewCORSCQSiUQiqWfcPhm3V9aGNOyATCYDwPTp0zfwSCQSiUQikUiak8lkCIfDa91GEeti/k1xHMdhzZo1BINBFEVZb/tNp9NMnz6dVatWEQqF1tt+/1PYmOcv5y7nvrHNHTbu+cu5b5xzhw9n/kIIMpkM3d3dqOras+ikxw5QVZVp06Z9YPsPhUIb5cU+zsY8fzl3OfeNkY15/nLuG+fc4YOf/3t56saRxRMSiUQikUgkUwRp2EkkEolEIpFMEaRh9wHidrs555xzcLvdG3ooG4SNef5y7nLuGyMb8/zl3DfOucNHb/6yeEIikUgkEolkiiA9dhKJRCKRSCRTBGnYSSQSiUQikUwRpGEnkUgkEolEMkWQht0HyG9/+1tmzZqFx+Nhl1124emnn97QQ1rv/PWvf+VTn/oU3d3dKIrCHXfcUbdeCMEPf/hDurq68Hq9LFq0iDfeeGPDDHY9c95557HzzjsTDAbp6OjgsMMOY9myZXXbFItFTjnlFGKxGIFAgCOOOIKBgYENNOL1x0UXXcQ222xT021auHAh9957b239VJ13M84//3wUReGMM86oLZvK8//v//5vFEWp+5s/f35t/VSeO0Bvby/HHnsssVgMr9fL1ltvzbPPPltbP5XvebNmzWo494qicMoppwBT+9zbts0PfvADZs+ejdfrZe7cufz4xz+ua/H1kTn3QvKBcMMNNwiXyyUuv/xy8corr4gTTzxRRCIRMTAwsKGHtl7585//LL73ve+J2267TQDi9ttvr1t//vnni3A4LO644w7x4osvikMOOUTMnj1bFAqFDTPg9cgBBxwgrrjiCrF06VLxwgsviE984hNixowZIpvN1rb56le/KqZPny4eeugh8eyzz4pdd91V7Lbbbhtw1OuHu+66S9xzzz3i9ddfF8uWLRNnn322MAxDLF26VAgxdec9maefflrMmjVLbLPNNuL000+vLZ/K8z/nnHPElltuKfr6+mp/Q0NDtfVTee6jo6Ni5syZ4rjjjhNPPfWUWL58ubj//vvFm2++WdtmKt/zBgcH6877gw8+KADxyCOPCCGm9rk/99xzRSwWE3/605/EihUrxM033ywCgYD45S9/Wdvmo3LupWH3AbFgwQJxyimn1P5t27bo7u4W55133gYc1QfLZMPOcRzR2dkpLrjggtqyZDIp3G63uP766zfACD9YBgcHBSAeffRRIURlroZhiJtvvrm2zT//+U8BiCeeeGJDDfMDIxqNiksvvXSjmXcmkxGbbrqpePDBB8Xee+9dM+ym+vzPOeccse222zZdN9XnfuaZZ4o99tij5fqN7Z53+umni7lz5wrHcab8uT/44IPF8ccfX7fs8MMPF8ccc4wQ4qN17mUo9gOgXC7z3HPPsWjRotoyVVVZtGgRTzzxxAYc2YfLihUr6O/vrzsO4XCYXXbZZUoeh1QqBUBbWxsAzz33HKZp1s1//vz5zJgxY0rN37ZtbrjhBnK5HAsXLtxo5n3KKadw8MEH180TNo7z/sYbb9Dd3c2cOXM45phjWLlyJTD1537XXXex00478ZnPfIaOjg623357Lrnkktr6jemeVy6X+eMf/8jxxx+PoihT/tzvtttuPPTQQ7z++usAvPjiizz22GMcdNBBwEfr3MtesR8Aw8PD2LZNIpGoW55IJHjttdc20Kg+fPr7+wGaHofxdVMFx3E444wz2H333dlqq62AyvxdLheRSKRu26ky/5dffpmFCxdSLBYJBALcfvvtbLHFFrzwwgtTet4AN9xwA//4xz945plnGtZN9fO+yy67cOWVVzJv3jz6+vr40Y9+xJ577snSpUun/NyXL1/ORRddxDe+8Q3OPvtsnnnmGU477TRcLheLFy/eqO55d9xxB8lkkuOOOw6Y+tf9WWedRTqdZv78+Wiahm3bnHvuuRxzzDHAR+t5Jw07iWQ9cMopp7B06VIee+yxDT2UD4158+bxwgsvkEqluOWWW1i8eDGPPvrohh7WB86qVas4/fTTefDBB/F4PBt6OB864x4KgG222YZddtmFmTNnctNNN+H1ejfgyD54HMdhp5124ic/+QkA22+/PUuXLuX3v/89ixcv3sCj+3C57LLLOOigg+ju7t7QQ/lQuOmmm7j22mu57rrr2HLLLXnhhRc444wz6O7u/sidexmK/QCIx+NomtZQDTQwMEBnZ+cGGtWHz/hcp/pxOPXUU/nTn/7EI488wrRp02rLOzs7KZfLJJPJuu2nyvxdLhebbLIJO+64I+eddx7bbrstv/zlL6f8vJ977jkGBwfZYYcd0HUdXdd59NFH+dWvfoWu6yQSiSk9/8lEIhE222wz3nzzzSl/7ru6uthiiy3qlm2++ea1UPTGcs975513+Mtf/sIJJ5xQWzbVz/23v/1tzjrrLI4++mi23nprvvCFL/D1r3+d8847D/honXtp2H0AuFwudtxxRx566KHaMsdxeOihh1i4cOEGHNmHy+zZs+ns7Kw7Dul0mqeeempKHAchBKeeeiq33347Dz/8MLNnz65bv+OOO2IYRt38ly1bxsqVK6fE/CfjOA6lUmnKz3v//ffn5Zdf5oUXXqj97bTTThxzzDG1/5/K859MNpvlrbfeoqura8qf+913371B0uj1119n5syZwNS/541zxRVX0NHRwcEHH1xbNtXPfT6fR1XrTSZN03AcB/iInfsPtVRjI+KGG24QbrdbXHnlleLVV18VX/7yl0UkEhH9/f0bemjrlUwmI55//nnx/PPPC0D8/Oc/F88//7x45513hBCV8u9IJCLuvPNO8dJLL4lDDz10ypT+n3TSSSIcDoslS5bUSQDk8/naNl/96lfFjBkzxMMPPyyeffZZsXDhQrFw4cINOOr1w1lnnSUeffRRsWLFCvHSSy+Js846SyiKIh544AEhxNSddysmVsUKMbXn/81vflMsWbJErFixQjz++ONi0aJFIh6Pi8HBQSHE1J77008/LXRdF+eee6544403xLXXXit8Pp/44x//WNtmKt/zhKgoPMyYMUOceeaZDeum8rlfvHix6Onpqcmd3HbbbSIej4vvfOc7tW0+KudeGnYfIL/+9a/FjBkzhMvlEgsWLBBPPvnkhh7SeueRRx4RQMPf4sWLhRCVEvAf/OAHIpFICLfbLfbff3+xbNmyDTvo9USzeQPiiiuuqG1TKBTEySefLKLRqPD5fOLTn/606Ovr23CDXk8cf/zxYubMmcLlcon29nax//7714w6IabuvFsx2bCbyvM/6qijRFdXl3C5XKKnp0ccddRRdTpuU3nuQghx9913i6222kq43W4xf/58cfHFF9etn8r3PCGEuP/++wXQdE5T+dyn02lx+umnixkzZgiPxyPmzJkjvve974lSqVTb5qNy7hUhJsgmSyQSiUQikUj+Y5E5dhKJRCKRSCRTBGnYSSQSiUQikUwRpGEnkUgkEolEMkWQhp1EIpFIJBLJFEEadhKJRCKRSCRTBGnYSSQSiUQikUwRpGEnkUgkEolEMkWQhp1EIpFIJBLJFEEadhKJRCKRSCRTBGnYSSQSyTryxBNPoGlaXfNziUQi+SghW4pJJBLJOnLCCScQCAS47LLLWLZsGd3d3Rt6SBKJRFKH9NhJJBLJOpDNZrnxxhs56aSTOPjgg7nyyivr1t91111suummeDwe9t13X6666ioURSGZTNa2eeyxx9hzzz3xer1Mnz6d0047jVwu9+FORCKRTGmkYSeRSCTrwE033cT8+fOZN28exx57LJdffjnjAY8VK1Zw5JFHcthhh/Hiiy/yla98he9973t1n3/rrbc48MADOeKII3jppZe48cYbeeyxxzj11FM3xHQkEskURYZiJRKJZB3Yfffd+exnP8vpp5+OZVl0dXVx8803s88++3DWWWdxzz338PLLL9e2//73v8+5557L2NgYkUiEE044AU3T+MMf/lDb5rHHHmPvvfcml8vh8Xg2xLQkEskUQ3rsJBKJ5D1YtmwZTz/9NJ/73OcA0HWdo446issuu6y2fuedd677zIIFC+r+/eKLL3LllVcSCARqfwcccACO47BixYoPZyISiWTKo2/oAUgkEslHncsuuwzLsuqKJYQQuN1ufvOb36zTPrLZLF/5ylc47bTTGtbNmDFjvY1VIpFs3EjDTiKRSNaCZVlcffXV/OxnP+PjH/943brDDjuM66+/nnnz5vHnP/+5bt0zzzxT9+8ddtiBV199lU022eQDH7NEItl4kTl2EolEshbuuOMOjjrqKAYHBwmHw3XrzjzzTB5++GFuuukm5s2bx9e//nW+9KUv8cILL/DNb36T1atXk0wmCYfDvPTSS+y6664cf/zxnHDCCfj9fl599VUefPDBdfb6SSQSyXshc+wkEolkLVx22WUsWrSowagDOOKII3j22WfJZDLccsst3HbbbWyzzTZcdNFFtapYt9sNwDbbbMOjjz7K66+/zp577sn222/PD3/4Q6mFJ5FI1ivSYyeRSCQfAOeeey6///3vWbVq1YYeikQi2YiQOXYSiUSyHvjd737HzjvvTCwW4/HHH+eCCy6QGnUSieRDRxp2EolEsh544403+N///V9GR0eZMWMG3/zmN/nud7+7oYclkUg2MmQoViKRSCQSiWSKIIsnJBKJRCKRSKYI0rCTSCQSiUQimSJIw04ikUgkEolkiiANO4lEIpFIJJIpgjTsJBKJRCKRSKYI0rCTSCQSiUQimSJIw04ikUgkEolkiiANO4lEIpFIJJIpgjTsJBKJRCKRSKYI/x8wLOGmxxzfSgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=\"Age\",y=\"Fare\",hue=\"Survived\",data=df_train,palette=\"rainbow\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbzAoipp9IBW"
   },
   "source": [
    "## **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1728325532001,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "_CsGUy939HHE",
    "outputId": "b0602280-a9a0-454d-a2df-ce877d28b082"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1728325532001,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "wrwnw-F49X3h",
    "outputId": "4ed42b9d-77ca-4f01-859d-d6a614ab118f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female  28.0      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"Age\"].fillna(df_train[\"Age\"].median(),inplace=True)\n",
    "df_train['Embarked'].fillna(df_train['Embarked'].mode()[0],inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1728325532001,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "ntIheACs-x8n",
    "outputId": "7510a72e-e255-4859-9681-5ff51a5be3c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name   Age  SibSp  Parch  \\\n",
       "0                              Braund, Mr. Owen Harris  22.0      1      0   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0      1      0   \n",
       "2                               Heikkinen, Miss. Laina  26.0      0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0      1      0   \n",
       "4                             Allen, Mr. William Henry  35.0      0      0   \n",
       "..                                                 ...   ...    ...    ...   \n",
       "886                              Montvila, Rev. Juozas  27.0      0      0   \n",
       "887                       Graham, Miss. Margaret Edith  19.0      0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  28.0      1      2   \n",
       "889                              Behr, Mr. Karl Howell  26.0      0      0   \n",
       "890                                Dooley, Mr. Patrick  32.0      0      0   \n",
       "\n",
       "               Ticket     Fare Cabin  Sex_female  Sex_male  Embarked_C  \\\n",
       "0           A/5 21171   7.2500   NaN       False      True       False   \n",
       "1            PC 17599  71.2833   C85        True     False        True   \n",
       "2    STON/O2. 3101282   7.9250   NaN        True     False       False   \n",
       "3              113803  53.1000  C123        True     False       False   \n",
       "4              373450   8.0500   NaN       False      True       False   \n",
       "..                ...      ...   ...         ...       ...         ...   \n",
       "886            211536  13.0000   NaN       False      True       False   \n",
       "887            112053  30.0000   B42        True     False       False   \n",
       "888        W./C. 6607  23.4500   NaN        True     False       False   \n",
       "889            111369  30.0000  C148       False      True        True   \n",
       "890            370376   7.7500   NaN       False      True       False   \n",
       "\n",
       "     Embarked_Q  Embarked_S  \n",
       "0         False        True  \n",
       "1         False       False  \n",
       "2         False        True  \n",
       "3         False        True  \n",
       "4         False        True  \n",
       "..          ...         ...  \n",
       "886       False        True  \n",
       "887       False        True  \n",
       "888       False        True  \n",
       "889       False       False  \n",
       "890        True       False  \n",
       "\n",
       "[891 rows x 15 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train=pd.get_dummies(df_train,columns=['Sex','Embarked'])\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1728325532001,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "dKRmv3DJAS38",
    "outputId": "7cdb79a1-122f-424f-8a64-eaa0d5e24bab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare  Sex_female  \\\n",
       "0            1         0       3  22.0      1      0   7.2500       False   \n",
       "1            2         1       1  38.0      1      0  71.2833        True   \n",
       "2            3         1       3  26.0      0      0   7.9250        True   \n",
       "3            4         1       1  35.0      1      0  53.1000        True   \n",
       "4            5         0       3  35.0      0      0   8.0500       False   \n",
       "\n",
       "   Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0      True       False       False        True  \n",
       "1     False        True       False       False  \n",
       "2     False       False       False        True  \n",
       "3     False       False       False        True  \n",
       "4      True       False       False        True  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unneccessary columns\n",
    "df_train.drop(['Cabin','Name','Ticket'],inplace=True,axis=1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1728325532001,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "Pity9hChBGWC"
   },
   "outputs": [],
   "source": [
    "x=df_train.drop([\"Survived\"],axis=1)\n",
    "y=df_train[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1728325532001,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "3sZvP3tWDJb8"
   },
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "x1=scaler.fit_transform(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1728325532002,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "rHzGZZH5Dfuk"
   },
   "outputs": [],
   "source": [
    "x=pd.DataFrame(x1,columns=x.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1728325532002,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "zvuqqWrXD3yE",
    "outputId": "eee83f41-1acf-41f1-9d2f-496a98adf3ea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.730108</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.565736</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.502445</td>\n",
       "      <td>-0.737695</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.726220</td>\n",
       "      <td>-1.566107</td>\n",
       "      <td>0.663861</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.786845</td>\n",
       "      <td>1.355574</td>\n",
       "      <td>-1.355574</td>\n",
       "      <td>2.074505</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>-1.623803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.722332</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.258337</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.488854</td>\n",
       "      <td>1.355574</td>\n",
       "      <td>-1.355574</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.718444</td>\n",
       "      <td>-1.566107</td>\n",
       "      <td>0.433312</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.420730</td>\n",
       "      <td>1.355574</td>\n",
       "      <td>-1.355574</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.714556</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>0.433312</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.486337</td>\n",
       "      <td>-0.737695</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>1.714556</td>\n",
       "      <td>-0.369365</td>\n",
       "      <td>-0.181487</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.386671</td>\n",
       "      <td>-0.737695</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1.718444</td>\n",
       "      <td>-1.566107</td>\n",
       "      <td>-0.796286</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.044381</td>\n",
       "      <td>1.355574</td>\n",
       "      <td>-1.355574</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1.722332</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.104637</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>2.008933</td>\n",
       "      <td>-0.176263</td>\n",
       "      <td>1.355574</td>\n",
       "      <td>-1.355574</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1.726220</td>\n",
       "      <td>-1.566107</td>\n",
       "      <td>-0.258337</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.044381</td>\n",
       "      <td>-0.737695</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>2.074505</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>-1.623803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1.730108</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>0.202762</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.492378</td>\n",
       "      <td>-0.737695</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>3.251373</td>\n",
       "      <td>-1.623803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId    Pclass       Age     SibSp     Parch      Fare  \\\n",
       "0      -1.730108  0.827377 -0.565736  0.432793 -0.473674 -0.502445   \n",
       "1      -1.726220 -1.566107  0.663861  0.432793 -0.473674  0.786845   \n",
       "2      -1.722332  0.827377 -0.258337 -0.474545 -0.473674 -0.488854   \n",
       "3      -1.718444 -1.566107  0.433312  0.432793 -0.473674  0.420730   \n",
       "4      -1.714556  0.827377  0.433312 -0.474545 -0.473674 -0.486337   \n",
       "..           ...       ...       ...       ...       ...       ...   \n",
       "886     1.714556 -0.369365 -0.181487 -0.474545 -0.473674 -0.386671   \n",
       "887     1.718444 -1.566107 -0.796286 -0.474545 -0.473674 -0.044381   \n",
       "888     1.722332  0.827377 -0.104637  0.432793  2.008933 -0.176263   \n",
       "889     1.726220 -1.566107 -0.258337 -0.474545 -0.473674 -0.044381   \n",
       "890     1.730108  0.827377  0.202762 -0.474545 -0.473674 -0.492378   \n",
       "\n",
       "     Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0     -0.737695  0.737695   -0.482043   -0.307562    0.615838  \n",
       "1      1.355574 -1.355574    2.074505   -0.307562   -1.623803  \n",
       "2      1.355574 -1.355574   -0.482043   -0.307562    0.615838  \n",
       "3      1.355574 -1.355574   -0.482043   -0.307562    0.615838  \n",
       "4     -0.737695  0.737695   -0.482043   -0.307562    0.615838  \n",
       "..          ...       ...         ...         ...         ...  \n",
       "886   -0.737695  0.737695   -0.482043   -0.307562    0.615838  \n",
       "887    1.355574 -1.355574   -0.482043   -0.307562    0.615838  \n",
       "888    1.355574 -1.355574   -0.482043   -0.307562    0.615838  \n",
       "889   -0.737695  0.737695    2.074505   -0.307562   -1.623803  \n",
       "890   -0.737695  0.737695   -0.482043    3.251373   -1.623803  \n",
       "\n",
       "[891 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1728325532002,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "RSo63C3bKSNT"
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 551,
     "status": "ok",
     "timestamp": 1728325532540,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "f4kJUNiKKhL9",
    "outputId": "dfc613a2-0dd6-4d1c-efec-10b883f96cdd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-1.613471</td>\n",
       "      <td>-1.566107</td>\n",
       "      <td>0.817561</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.090272</td>\n",
       "      <td>-0.737695</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>2.074505</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>-1.623803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.691229</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>-1.949034</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>0.767630</td>\n",
       "      <td>-0.312172</td>\n",
       "      <td>1.355574</td>\n",
       "      <td>-1.355574</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>1.664014</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>1.355510</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.467209</td>\n",
       "      <td>-0.737695</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>-1.022513</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>-1.564784</td>\n",
       "      <td>3.154809</td>\n",
       "      <td>2.008933</td>\n",
       "      <td>-0.016444</td>\n",
       "      <td>-0.737695</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>1.675678</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.719436</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.450180</td>\n",
       "      <td>-0.737695</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>0.346022</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>0.049062</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.474005</td>\n",
       "      <td>1.355574</td>\n",
       "      <td>-1.355574</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>0.540416</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.104637</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.472998</td>\n",
       "      <td>-0.737695</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>2.074505</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>-1.623803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.186618</td>\n",
       "      <td>-1.566107</td>\n",
       "      <td>3.199906</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.348330</td>\n",
       "      <td>-0.737695</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>2.074505</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>-1.623803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>0.318806</td>\n",
       "      <td>-1.566107</td>\n",
       "      <td>-0.104637</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>3.817033</td>\n",
       "      <td>-0.737695</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>-1.076944</td>\n",
       "      <td>-1.566107</td>\n",
       "      <td>-0.104637</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.126430</td>\n",
       "      <td>-0.737695</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId    Pclass       Age     SibSp     Parch      Fare  \\\n",
       "30     -1.613471 -1.566107  0.817561 -0.474545 -0.473674 -0.090272   \n",
       "10     -1.691229  0.827377 -1.949034  0.432793  0.767630 -0.312172   \n",
       "873     1.664014  0.827377  1.355510 -0.474545 -0.473674 -0.467209   \n",
       "182    -1.022513  0.827377 -1.564784  3.154809  2.008933 -0.016444   \n",
       "876     1.675678  0.827377 -0.719436 -0.474545 -0.473674 -0.450180   \n",
       "..           ...       ...       ...       ...       ...       ...   \n",
       "534     0.346022  0.827377  0.049062 -0.474545 -0.473674 -0.474005   \n",
       "584     0.540416  0.827377 -0.104637 -0.474545 -0.473674 -0.472998   \n",
       "493     0.186618 -1.566107  3.199906 -0.474545 -0.473674  0.348330   \n",
       "527     0.318806 -1.566107 -0.104637 -0.474545 -0.473674  3.817033   \n",
       "168    -1.076944 -1.566107 -0.104637 -0.474545 -0.473674 -0.126430   \n",
       "\n",
       "     Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "30    -0.737695  0.737695    2.074505   -0.307562   -1.623803  \n",
       "10     1.355574 -1.355574   -0.482043   -0.307562    0.615838  \n",
       "873   -0.737695  0.737695   -0.482043   -0.307562    0.615838  \n",
       "182   -0.737695  0.737695   -0.482043   -0.307562    0.615838  \n",
       "876   -0.737695  0.737695   -0.482043   -0.307562    0.615838  \n",
       "..          ...       ...         ...         ...         ...  \n",
       "534    1.355574 -1.355574   -0.482043   -0.307562    0.615838  \n",
       "584   -0.737695  0.737695    2.074505   -0.307562   -1.623803  \n",
       "493   -0.737695  0.737695    2.074505   -0.307562   -1.623803  \n",
       "527   -0.737695  0.737695   -0.482043   -0.307562    0.615838  \n",
       "168   -0.737695  0.737695   -0.482043   -0.307562    0.615838  \n",
       "\n",
       "[712 rows x 11 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1728325532540,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "jiOpbkcMKjds",
    "outputId": "f265e0e1-bce8-4e10-e52f-fea03ff48cc5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>1.018625</td>\n",
       "      <td>-1.566107</td>\n",
       "      <td>0.971260</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.119131</td>\n",
       "      <td>-0.737695</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-1.586256</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.642586</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.486337</td>\n",
       "      <td>-0.737695</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>0.660940</td>\n",
       "      <td>-0.369365</td>\n",
       "      <td>-0.412037</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>2.008933</td>\n",
       "      <td>0.660333</td>\n",
       "      <td>1.355574</td>\n",
       "      <td>-1.355574</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>-1.073056</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.104637</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.489104</td>\n",
       "      <td>-0.737695</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-1.465732</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.949986</td>\n",
       "      <td>3.154809</td>\n",
       "      <td>2.008933</td>\n",
       "      <td>-0.488854</td>\n",
       "      <td>1.355574</td>\n",
       "      <td>-1.355574</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>-1.384086</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.412037</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.486337</td>\n",
       "      <td>-0.737695</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-1.419077</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.565736</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.467209</td>\n",
       "      <td>-0.737695</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>1.559041</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.104637</td>\n",
       "      <td>6.784163</td>\n",
       "      <td>2.008933</td>\n",
       "      <td>0.751946</td>\n",
       "      <td>-0.737695</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>1.652350</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.258337</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.489442</td>\n",
       "      <td>-0.737695</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>-0.754249</td>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.027788</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>0.767630</td>\n",
       "      <td>-0.437762</td>\n",
       "      <td>1.355574</td>\n",
       "      <td>-1.355574</td>\n",
       "      <td>-0.482043</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId    Pclass       Age     SibSp     Parch      Fare  \\\n",
       "707     1.018625 -1.566107  0.971260 -0.474545 -0.473674 -0.119131   \n",
       "37     -1.586256  0.827377 -0.642586 -0.474545 -0.473674 -0.486337   \n",
       "615     0.660940 -0.369365 -0.412037  0.432793  2.008933  0.660333   \n",
       "169    -1.073056  0.827377 -0.104637 -0.474545 -0.473674  0.489104   \n",
       "68     -1.465732  0.827377 -0.949986  3.154809  2.008933 -0.488854   \n",
       "..           ...       ...       ...       ...       ...       ...   \n",
       "89     -1.384086  0.827377 -0.412037 -0.474545 -0.473674 -0.486337   \n",
       "80     -1.419077  0.827377 -0.565736 -0.474545 -0.473674 -0.467209   \n",
       "846     1.559041  0.827377 -0.104637  6.784163  2.008933  0.751946   \n",
       "870     1.652350  0.827377 -0.258337 -0.474545 -0.473674 -0.489442   \n",
       "251    -0.754249  0.827377 -0.027788  0.432793  0.767630 -0.437762   \n",
       "\n",
       "     Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "707   -0.737695  0.737695   -0.482043   -0.307562    0.615838  \n",
       "37    -0.737695  0.737695   -0.482043   -0.307562    0.615838  \n",
       "615    1.355574 -1.355574   -0.482043   -0.307562    0.615838  \n",
       "169   -0.737695  0.737695   -0.482043   -0.307562    0.615838  \n",
       "68     1.355574 -1.355574   -0.482043   -0.307562    0.615838  \n",
       "..          ...       ...         ...         ...         ...  \n",
       "89    -0.737695  0.737695   -0.482043   -0.307562    0.615838  \n",
       "80    -0.737695  0.737695   -0.482043   -0.307562    0.615838  \n",
       "846   -0.737695  0.737695   -0.482043   -0.307562    0.615838  \n",
       "870   -0.737695  0.737695   -0.482043   -0.307562    0.615838  \n",
       "251    1.355574 -1.355574   -0.482043   -0.307562    0.615838  \n",
       "\n",
       "[179 rows x 11 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1728325532540,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "T7FEw_rJKl8h",
    "outputId": "2a4eebbb-77f5-4029-d9cb-a2204dcd4d3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30     0\n",
       "10     1\n",
       "873    0\n",
       "182    0\n",
       "876    0\n",
       "      ..\n",
       "534    0\n",
       "584    0\n",
       "493    0\n",
       "527    0\n",
       "168    0\n",
       "Name: Survived, Length: 712, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1728325532540,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "MvVRwsuEKoNf",
    "outputId": "8d5c3497-e074-46e3-c71c-3598e4e5451c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "707    1\n",
       "37     0\n",
       "615    1\n",
       "169    0\n",
       "68     1\n",
       "      ..\n",
       "89     0\n",
       "80     0\n",
       "846    0\n",
       "870    0\n",
       "251    0\n",
       "Name: Survived, Length: 179, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDJkS34yED9S"
   },
   "source": [
    "## **Building Predictive Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install xgboost\n",
    "# %pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 721,
     "status": "ok",
     "timestamp": 1728325533257,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "A48K7woQD_de"
   },
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import lightgbm\n",
    "import lightgbm as LGBMClassifier\n",
    "import xgboost as XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1728325533257,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "SLMiXgOMFg1b"
   },
   "outputs": [],
   "source": [
    "# params={\n",
    "#     'n_estimators':[90,110,150],\n",
    "#     'learning_rate':[0.5,0.7,1],\n",
    "#     'lambda':[1,2,3],\n",
    "#     'max_depth':[3,7,11]\n",
    "# }\n",
    "\n",
    "params= {\n",
    "    \"num_leaves\": [15, 31],\n",
    "    \"max_depth\": [-1, 10],\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"min_child_samples\": [5, 10]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 152
    },
    "executionInfo": {
     "elapsed": 38922,
     "status": "ok",
     "timestamp": 1728325572177,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "J8aU0vWfFm1c",
    "outputId": "b80ecad7-06d7-4aac-83b4-9eeec088dd33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, feature_weights=None,\n",
       "                                     gamma=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     lea...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.05, 0.1], &#x27;max_depth&#x27;: [-1, 10],\n",
       "                         &#x27;min_child_samples&#x27;: [5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200], &#x27;num_leaves&#x27;: [15, 31]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=estimator,-estimator%20object\">\n",
       "            estimator\n",
       "            <span class=\"param-doc-description\">estimator: estimator object<br><br>This is assumed to implement the scikit-learn estimator interface.<br>Either estimator needs to provide a ``score`` function,<br>or ``scoring`` must be passed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">XGBClassifier...ree=None, ...)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=param_grid,-dict%20or%20list%20of%20dictionaries\">\n",
       "            param_grid\n",
       "            <span class=\"param-doc-description\">param_grid: dict or list of dictionaries<br><br>Dictionary with parameters names (`str`) as keys and lists of<br>parameter settings to try as values, or a list of such<br>dictionaries, in which case the grids spanned by each dictionary<br>in the list are explored. This enables searching over any sequence<br>of parameter settings.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">{&#x27;learning_rate&#x27;: [0.05, 0.1], &#x27;max_depth&#x27;: [-1, 10], &#x27;min_child_samples&#x27;: [5, 10], &#x27;n_estimators&#x27;: [100, 200], ...}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=scoring,-str%2C%20callable%2C%20list%2C%20tuple%20or%20dict%2C%20default%3DNone\">\n",
       "            scoring\n",
       "            <span class=\"param-doc-description\">scoring: str, callable, list, tuple or dict, default=None<br><br>Strategy to evaluate the performance of the cross-validated model on<br>the test set.<br><br>If `scoring` represents a single score, one can use:<br><br>- a single string (see :ref:`scoring_string_names`);<br>- a callable (see :ref:`scoring_callable`) that returns a single value;<br>- `None`, the `estimator`'s<br>  :ref:`default evaluation criterion <scoring_api_overview>` is used.<br><br>If `scoring` represents multiple scores, one can use:<br><br>- a list or tuple of unique strings;<br>- a callable returning a dictionary where the keys are the metric<br>  names and the values are the metric scores;<br>- a dictionary with metric names as keys and callables as values.<br><br>See :ref:`multimetric_grid_search` for an example.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Number of jobs to run in parallel.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.<br><br>.. versionchanged:: v0.20<br>   `n_jobs` default changed from 1 to None</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=refit,-bool%2C%20str%2C%20or%20callable%2C%20default%3DTrue\">\n",
       "            refit\n",
       "            <span class=\"param-doc-description\">refit: bool, str, or callable, default=True<br><br>Refit an estimator using the best found parameters on the whole<br>dataset.<br><br>For multiple metric evaluation, this needs to be a `str` denoting the<br>scorer that would be used to find the best parameters for refitting<br>the estimator at the end.<br><br>Where there are considerations other than maximum score in<br>choosing a best estimator, ``refit`` can be set to a function which<br>returns the selected ``best_index_`` given ``cv_results_``. In that<br>case, the ``best_estimator_`` and ``best_params_`` will be set<br>according to the returned ``best_index_`` while the ``best_score_``<br>attribute will not be available.<br><br>The refitted estimator is made available at the ``best_estimator_``<br>attribute and permits using ``predict`` directly on this<br>``GridSearchCV`` instance.<br><br>Also for multiple metric evaluation, the attributes ``best_index_``,<br>``best_score_`` and ``best_params_`` will only be available if<br>``refit`` is set and all of them will be determined w.r.t this specific<br>scorer.<br><br>See ``scoring`` parameter to know more about multiple metric<br>evaluation.<br><br>See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`<br>to see how to design a custom selection strategy using a callable<br>via `refit`.<br><br>See :ref:`this example<br><sphx_glr_auto_examples_model_selection_plot_grid_search_refit_callable.py>`<br>for an example of how to use ``refit=callable`` to balance model<br>complexity and cross-validated score.<br><br>.. versionchanged:: 0.20<br>    Support for callable added.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=cv,-int%2C%20cross-validation%20generator%20or%20an%20iterable%2C%20default%3DNone\">\n",
       "            cv\n",
       "            <span class=\"param-doc-description\">cv: int, cross-validation generator or an iterable, default=None<br><br>Determines the cross-validation splitting strategy.<br>Possible inputs for cv are:<br><br>- None, to use the default 5-fold cross validation,<br>- integer, to specify the number of folds in a `(Stratified)KFold`,<br>- :term:`CV splitter`,<br>- An iterable yielding (train, test) splits as arrays of indices.<br><br>For integer/None inputs, if the estimator is a classifier and ``y`` is<br>either binary or multiclass, :class:`StratifiedKFold` is used. In all<br>other cases, :class:`KFold` is used. These splitters are instantiated<br>with `shuffle=False` so the splits will be the same across calls.<br><br>Refer :ref:`User Guide <cross_validation>` for the various<br>cross-validation strategies that can be used here.<br><br>.. versionchanged:: 0.22<br>    ``cv`` default value if None changed from 3-fold to 5-fold.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=verbose,-int\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int<br><br>Controls the verbosity: the higher, the more messages.<br><br>- >1 : the computation time for each fold and parameter candidate is<br>  displayed;<br>- >2 : the score is also displayed;<br>- >3 : the fold and candidate parameter indexes are also displayed<br>  together with the starting time of the computation.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=pre_dispatch,-int%2C%20or%20str%2C%20default%3D%272%2An_jobs%27\">\n",
       "            pre_dispatch\n",
       "            <span class=\"param-doc-description\">pre_dispatch: int, or str, default='2*n_jobs'<br><br>Controls the number of jobs that get dispatched during parallel<br>execution. Reducing this number can be useful to avoid an<br>explosion of memory consumption when more jobs get dispatched<br>than CPUs can process. This parameter can be:<br><br>- None, in which case all the jobs are immediately created and spawned. Use<br>  this for lightweight and fast-running jobs, to avoid delays due to on-demand<br>  spawning of the jobs<br>- An int, giving the exact number of total jobs that are spawned<br>- A str, giving an expression as a function of n_jobs, as in '2*n_jobs'</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=error_score,-%27raise%27%20or%20numeric%2C%20default%3Dnp.nan\">\n",
       "            error_score\n",
       "            <span class=\"param-doc-description\">error_score: 'raise' or numeric, default=np.nan<br><br>Value to assign to the score if an error occurs in estimator fitting.<br>If set to 'raise', the error is raised. If a numeric value is given,<br>FitFailedWarning is raised. This parameter does not affect the refit<br>step, which will always raise the error.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=return_train_score,-bool%2C%20default%3DFalse\">\n",
       "            return_train_score\n",
       "            <span class=\"param-doc-description\">return_train_score: bool, default=False<br><br>If ``False``, the ``cv_results_`` attribute will not include training<br>scores.<br>Computing training scores is used to get insights on how different<br>parameter settings impact the overfitting/underfitting trade-off.<br>However computing the scores on the training set can be computationally<br>expensive and is not strictly required to select the parameters that<br>yield the best generalization performance.<br><br>.. versionadded:: 0.19<br><br>.. versionchanged:: 0.21<br>    Default value was changed from ``True`` to ``False``</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: XGBClassifier</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
       "              max_leaves=None, min_child_samples=5, min_child_weight=None,\n",
       "              missing=nan, monotone_constraints=None, multi_strategy=None,\n",
       "              n_estimators=100, n_jobs=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=objective,-typing.Union%5Bstr%2C%20xgboost.sklearn._SklObjWProto%2C%20typing.Callable%5B%5Btyping.Any%2C%20typing.Any%5D%2C%20typing.Tuple%5Bnumpy.ndarray%2C%20numpy.ndarray%5D%5D%2C%20NoneType%5D\">\n",
       "            objective\n",
       "            <span class=\"param-doc-description\">objective: typing.Union[str, xgboost.sklearn._SklObjWProto, typing.Callable[[typing.Any, typing.Any], typing.Tuple[numpy.ndarray, numpy.ndarray]], NoneType]<br><br>Specify the learning task and the corresponding learning objective or a custom<br>objective function to be used.<br><br>For custom objective, see :doc:`/tutorials/custom_metric_obj` and<br>:ref:`custom-obj-metric` for more information, along with the end note for<br>function signatures.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;binary:logistic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=base_score,-typing.Union%5Bfloat%2C%20typing.List%5Bfloat%5D%2C%20NoneType%5D\">\n",
       "            base_score\n",
       "            <span class=\"param-doc-description\">base_score: typing.Union[float, typing.List[float], NoneType]<br><br>The initial prediction score of all instances, global bias.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=callbacks,-typing.Optional%5Btyping.List%5Bxgboost.callback.TrainingCallback%5D%5D\">\n",
       "            callbacks\n",
       "            <span class=\"param-doc-description\">callbacks: typing.Optional[typing.List[xgboost.callback.TrainingCallback]]<br><br>List of callback functions that are applied at end of each iteration.<br>It is possible to use predefined callbacks by using<br>:ref:`Callback API <callback_api>`.<br><br>.. note::<br><br>   States in callback are not preserved during training, which means callback<br>   objects can not be reused for multiple training sessions without<br>   reinitialization or deepcopy.<br><br>.. code-block:: python<br><br>    for params in parameters_grid:<br>        # be sure to (re)initialize the callbacks before each run<br>        callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]<br>        reg = xgboost.XGBRegressor(**params, callbacks=callbacks)<br>        reg.fit(X, y)</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=colsample_bylevel,-typing.Optional%5Bfloat%5D\">\n",
       "            colsample_bylevel\n",
       "            <span class=\"param-doc-description\">colsample_bylevel: typing.Optional[float]<br><br>Subsample ratio of columns for each level.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=colsample_bynode,-typing.Optional%5Bfloat%5D\">\n",
       "            colsample_bynode\n",
       "            <span class=\"param-doc-description\">colsample_bynode: typing.Optional[float]<br><br>Subsample ratio of columns for each split.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=colsample_bytree,-typing.Optional%5Bfloat%5D\">\n",
       "            colsample_bytree\n",
       "            <span class=\"param-doc-description\">colsample_bytree: typing.Optional[float]<br><br>Subsample ratio of columns when constructing each tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=device,-typing.Optional%5Bstr%5D\">\n",
       "            device\n",
       "            <span class=\"param-doc-description\">device: typing.Optional[str]<br><br>.. versionadded:: 2.0.0<br><br>Device ordinal, available options are `cpu`, `cuda`, and `gpu`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=early_stopping_rounds,-typing.Optional%5Bint%5D\">\n",
       "            early_stopping_rounds\n",
       "            <span class=\"param-doc-description\">early_stopping_rounds: typing.Optional[int]<br><br>.. versionadded:: 1.6.0<br><br>- Activates early stopping. Validation metric needs to improve at least once in<br>  every **early_stopping_rounds** round(s) to continue training.  Requires at<br>  least one item in **eval_set** in :py:meth:`fit`.<br><br>- If early stopping occurs, the model will have two additional attributes:<br>  :py:attr:`best_score` and :py:attr:`best_iteration`. These are used by the<br>  :py:meth:`predict` and :py:meth:`apply` methods to determine the optimal<br>  number of trees during inference. If users want to access the full model<br>  (including trees built after early stopping), they can specify the<br>  `iteration_range` in these inference methods. In addition, other utilities<br>  like model plotting can also use the entire model.<br><br>- If you prefer to discard the trees after `best_iteration`, consider using the<br>  callback function :py:class:`xgboost.callback.EarlyStopping`.<br><br>- If there's more than one item in **eval_set**, the last entry will be used for<br>  early stopping.  If there's more than one metric in **eval_metric**, the last<br>  metric will be used for early stopping.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=enable_categorical,-bool\">\n",
       "            enable_categorical\n",
       "            <span class=\"param-doc-description\">enable_categorical: bool<br><br>See the same parameter of :py:class:`DMatrix` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=eval_metric,-typing.Union%5Bstr%2C%20typing.List%5Btyping.Union%5Bstr%2C%20typing.Callable%5D%5D%2C%20typing.Callable%2C%20NoneType%5D\">\n",
       "            eval_metric\n",
       "            <span class=\"param-doc-description\">eval_metric: typing.Union[str, typing.List[typing.Union[str, typing.Callable]], typing.Callable, NoneType]<br><br>.. versionadded:: 1.6.0<br><br>Metric used for monitoring the training result and early stopping.  It can be a<br>string or list of strings as names of predefined metric in XGBoost (See<br>:doc:`/parameter`), one of the metrics in :py:mod:`sklearn.metrics`, or any<br>other user defined metric that looks like `sklearn.metrics`.<br><br>If custom objective is also provided, then custom metric should implement the<br>corresponding reverse link function.<br><br>Unlike the `scoring` parameter commonly used in scikit-learn, when a callable<br>object is provided, it's assumed to be a cost function and by default XGBoost<br>will minimize the result during early stopping.<br><br>For advanced usage on Early stopping like directly choosing to maximize instead<br>of minimize, see :py:obj:`xgboost.callback.EarlyStopping`.<br><br>See :doc:`/tutorials/custom_metric_obj` and :ref:`custom-obj-metric` for more<br>information.<br><br>.. code-block:: python<br><br>    from sklearn.datasets import load_diabetes<br>    from sklearn.metrics import mean_absolute_error<br>    X, y = load_diabetes(return_X_y=True)<br>    reg = xgb.XGBRegressor(<br>        tree_method=\"hist\",<br>        eval_metric=mean_absolute_error,<br>    )<br>    reg.fit(X, y, eval_set=[(X, y)])</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=feature_types,-typing.Optional%5Btyping.Sequence%5Bstr%5D%5D\">\n",
       "            feature_types\n",
       "            <span class=\"param-doc-description\">feature_types: typing.Optional[typing.Sequence[str]]<br><br>.. versionadded:: 1.7.0<br><br>Used for specifying feature types without constructing a dataframe. See<br>the :py:class:`DMatrix` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=feature_weights,-Optional%5BArrayLike%5D\">\n",
       "            feature_weights\n",
       "            <span class=\"param-doc-description\">feature_weights: Optional[ArrayLike]<br><br>Weight for each feature, defines the probability of each feature being selected<br>when colsample is being used.  All values must be greater than 0, otherwise a<br>`ValueError` is thrown.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=gamma,-typing.Optional%5Bfloat%5D\">\n",
       "            gamma\n",
       "            <span class=\"param-doc-description\">gamma: typing.Optional[float]<br><br>(min_split_loss) Minimum loss reduction required to make a further partition on<br>a leaf node of the tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=grow_policy,-typing.Optional%5Bstr%5D\">\n",
       "            grow_policy\n",
       "            <span class=\"param-doc-description\">grow_policy: typing.Optional[str]<br><br>Tree growing policy.<br><br>- depthwise: Favors splitting at nodes closest to the node,<br>- lossguide: Favors splitting at nodes with highest loss change.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=interaction_constraints,-typing.Union%5Bstr%2C%20typing.List%5Btyping.Tuple%5Bstr%5D%5D%2C%20NoneType%5D\">\n",
       "            interaction_constraints\n",
       "            <span class=\"param-doc-description\">interaction_constraints: typing.Union[str, typing.List[typing.Tuple[str]], NoneType]<br><br>Constraints for interaction representing permitted interactions.  The<br>constraints must be specified in the form of a nested list, e.g. ``[[0, 1], [2,<br>3, 4]]``, where each inner list is a group of indices of features that are<br>allowed to interact with each other.  See :doc:`tutorial<br></tutorials/feature_interaction_constraint>` for more information</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=learning_rate,-typing.Optional%5Bfloat%5D\">\n",
       "            learning_rate\n",
       "            <span class=\"param-doc-description\">learning_rate: typing.Optional[float]<br><br>Boosting learning rate (xgb's \"eta\")</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.05</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=max_bin,-typing.Optional%5Bint%5D\">\n",
       "            max_bin\n",
       "            <span class=\"param-doc-description\">max_bin: typing.Optional[int]<br><br>If using histogram-based algorithm, maximum number of bins per feature</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=max_cat_threshold,-typing.Optional%5Bint%5D\">\n",
       "            max_cat_threshold\n",
       "            <span class=\"param-doc-description\">max_cat_threshold: typing.Optional[int]<br><br>.. versionadded:: 1.7.0<br><br>.. note:: This parameter is experimental<br><br>Maximum number of categories considered for each split. Used only by<br>partition-based splits for preventing over-fitting. Also, `enable_categorical`<br>needs to be set to have categorical feature support. See :doc:`Categorical Data<br></tutorials/categorical>` and :ref:`cat-param` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=max_cat_to_onehot,-Optional%5Bint%5D\">\n",
       "            max_cat_to_onehot\n",
       "            <span class=\"param-doc-description\">max_cat_to_onehot: Optional[int]<br><br>.. versionadded:: 1.6.0<br><br>.. note:: This parameter is experimental<br><br>A threshold for deciding whether XGBoost should use one-hot encoding based split<br>for categorical data.  When number of categories is lesser than the threshold<br>then one-hot encoding is chosen, otherwise the categories will be partitioned<br>into children nodes. Also, `enable_categorical` needs to be set to have<br>categorical feature support. See :doc:`Categorical Data<br></tutorials/categorical>` and :ref:`cat-param` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=max_delta_step,-typing.Optional%5Bfloat%5D\">\n",
       "            max_delta_step\n",
       "            <span class=\"param-doc-description\">max_delta_step: typing.Optional[float]<br><br>Maximum delta step we allow each tree's weight estimation to be.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=max_depth,-%20typing.Optional%5Bint%5D\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth:  typing.Optional[int]<br><br>Maximum tree depth for base learners.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=max_leaves,-typing.Optional%5Bint%5D\">\n",
       "            max_leaves\n",
       "            <span class=\"param-doc-description\">max_leaves: typing.Optional[int]<br><br>Maximum number of leaves; 0 indicates no limit.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=min_child_weight,-typing.Optional%5Bfloat%5D\">\n",
       "            min_child_weight\n",
       "            <span class=\"param-doc-description\">min_child_weight: typing.Optional[float]<br><br>Minimum sum of instance weight(hessian) needed in a child.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=missing,-float\">\n",
       "            missing\n",
       "            <span class=\"param-doc-description\">missing: float<br><br>Value in the data which needs to be present as a missing value. Default to<br>:py:data:`numpy.nan`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=monotone_constraints,-typing.Union%5Btyping.Dict%5Bstr%2C%20int%5D%2C%20str%2C%20NoneType%5D\">\n",
       "            monotone_constraints\n",
       "            <span class=\"param-doc-description\">monotone_constraints: typing.Union[typing.Dict[str, int], str, NoneType]<br><br>Constraint of variable monotonicity.  See :doc:`tutorial </tutorials/monotonic>`<br>for more information.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=multi_strategy,-typing.Optional%5Bstr%5D\">\n",
       "            multi_strategy\n",
       "            <span class=\"param-doc-description\">multi_strategy: typing.Optional[str]<br><br>.. versionadded:: 2.0.0<br><br>.. note:: This parameter is working-in-progress.<br><br>The strategy used for training multi-target models, including multi-target<br>regression and multi-class classification. See :doc:`/tutorials/multioutput` for<br>more information.<br><br>- ``one_output_per_tree``: One model for each target.<br>- ``multi_output_tree``:  Use multi-target trees.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=n_estimators,-Optional%5Bint%5D\">\n",
       "            n_estimators\n",
       "            <span class=\"param-doc-description\">n_estimators: Optional[int]<br><br>Number of boosting rounds.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=n_jobs,-typing.Optional%5Bint%5D\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: typing.Optional[int]<br><br>Number of parallel threads used to run xgboost.  When used with other<br>Scikit-Learn algorithms like grid search, you may choose which algorithm to<br>parallelize and balance the threads.  Creating thread contention will<br>significantly slow down both algorithms.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=random_state,-typing.Union%5Bnumpy.random.mtrand.RandomState%2C%20numpy.random._generator.Generator%2C%20int%2C%20NoneType%5D\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: typing.Union[numpy.random.mtrand.RandomState, numpy.random._generator.Generator, int, NoneType]<br><br>Random number seed.<br><br>.. note::<br><br>   Using gblinear booster with shotgun updater is nondeterministic as<br>   it uses Hogwild algorithm.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=reg_alpha,-typing.Optional%5Bfloat%5D\">\n",
       "            reg_alpha\n",
       "            <span class=\"param-doc-description\">reg_alpha: typing.Optional[float]<br><br>L1 regularization term on weights (xgb's alpha).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=reg_lambda,-typing.Optional%5Bfloat%5D\">\n",
       "            reg_lambda\n",
       "            <span class=\"param-doc-description\">reg_lambda: typing.Optional[float]<br><br>L2 regularization term on weights (xgb's lambda).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=sampling_method,-typing.Optional%5Bstr%5D\">\n",
       "            sampling_method\n",
       "            <span class=\"param-doc-description\">sampling_method: typing.Optional[str]<br><br>Sampling method. Used only by the GPU version of ``hist`` tree method.<br><br>- ``uniform``: Select random training instances uniformly.<br>- ``gradient_based``: Select random training instances with higher probability<br>    when the gradient and hessian are larger. (cf. CatBoost)</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=scale_pos_weight,-typing.Optional%5Bfloat%5D\">\n",
       "            scale_pos_weight\n",
       "            <span class=\"param-doc-description\">scale_pos_weight: typing.Optional[float]<br><br>Balancing of positive and negative weights.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=subsample,-typing.Optional%5Bfloat%5D\">\n",
       "            subsample\n",
       "            <span class=\"param-doc-description\">subsample: typing.Optional[float]<br><br>Subsample ratio of the training instance.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=tree_method,-typing.Optional%5Bstr%5D\">\n",
       "            tree_method\n",
       "            <span class=\"param-doc-description\">tree_method: typing.Optional[str]<br><br>Specify which tree method to use.  Default to auto.  If this parameter is set to<br>default, XGBoost will choose the most conservative option available.  It's<br>recommended to study this option from the parameters document :doc:`tree method<br></treemethod>`</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=validate_parameters,-typing.Optional%5Bbool%5D\">\n",
       "            validate_parameters\n",
       "            <span class=\"param-doc-description\">validate_parameters: typing.Optional[bool]<br><br>Give warnings for unknown parameter.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=verbosity,-typing.Optional%5Bint%5D\">\n",
       "            verbosity\n",
       "            <span class=\"param-doc-description\">verbosity: typing.Optional[int]<br><br>The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_samples</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_leaves</td>\n",
       "            <td class=\"value\">15</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-1');</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, feature_weights=None,\n",
       "                                     gamma=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     lea...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None, ...),\n",
       "             param_grid={'learning_rate': [0.05, 0.1], 'max_depth': [-1, 10],\n",
       "                         'min_child_samples': [5, 10],\n",
       "                         'n_estimators': [100, 200], 'num_leaves': [15, 31]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid1=GridSearchCV(xgboost.XGBClassifier(),param_grid=params,verbose=1)\n",
    "grid1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1728325572177,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "r65tBdNVGh-c",
    "outputId": "bd7f888c-3f6a-4407-b95d-c011cfabbcd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.05,\n",
       " 'max_depth': 10,\n",
       " 'min_child_samples': 5,\n",
       " 'n_estimators': 100,\n",
       " 'num_leaves': 15}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 48244,
     "status": "ok",
     "timestamp": 1728325620418,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "7blPsHX4GHEn",
    "outputId": "f5a0d493-87a8-476e-a521-b94a2969d22b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000064 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000081 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000099 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000087 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000118 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000110 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000078 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000099 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000108 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000110 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000064 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000077 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000081 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000081 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000084 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000078 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000108 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 390\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 387\n",
      "[LightGBM] [Info] Number of data points in the train set: 569, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369069 -> initscore=-0.536215\n",
      "[LightGBM] [Info] Start training from score -0.536215\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 381\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 211, number of negative: 359\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 389\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.370175 -> initscore=-0.531464\n",
      "[LightGBM] [Info] Start training from score -0.531464\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 210, number of negative: 360\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 384\n",
      "[LightGBM] [Info] Number of data points in the train set: 570, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.368421 -> initscore=-0.538997\n",
      "[LightGBM] [Info] Start training from score -0.538997\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 263, number of negative: 449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000116 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 458\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369382 -> initscore=-0.534869\n",
      "[LightGBM] [Info] Start training from score -0.534869\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=LGBMClassifier(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.05, 0.1], &#x27;max_depth&#x27;: [-1, 10],\n",
       "                         &#x27;min_child_samples&#x27;: [5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200], &#x27;num_leaves&#x27;: [15, 31]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GridSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('estimator',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=estimator,-estimator%20object\">\n",
       "            estimator\n",
       "            <span class=\"param-doc-description\">estimator: estimator object<br><br>This is assumed to implement the scikit-learn estimator interface.<br>Either estimator needs to provide a ``score`` function,<br>or ``scoring`` must be passed.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">LGBMClassifier()</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('param_grid',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=param_grid,-dict%20or%20list%20of%20dictionaries\">\n",
       "            param_grid\n",
       "            <span class=\"param-doc-description\">param_grid: dict or list of dictionaries<br><br>Dictionary with parameters names (`str`) as keys and lists of<br>parameter settings to try as values, or a list of such<br>dictionaries, in which case the grids spanned by each dictionary<br>in the list are explored. This enables searching over any sequence<br>of parameter settings.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">{&#x27;learning_rate&#x27;: [0.05, 0.1], &#x27;max_depth&#x27;: [-1, 10], &#x27;min_child_samples&#x27;: [5, 10], &#x27;n_estimators&#x27;: [100, 200], ...}</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scoring',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=scoring,-str%2C%20callable%2C%20list%2C%20tuple%20or%20dict%2C%20default%3DNone\">\n",
       "            scoring\n",
       "            <span class=\"param-doc-description\">scoring: str, callable, list, tuple or dict, default=None<br><br>Strategy to evaluate the performance of the cross-validated model on<br>the test set.<br><br>If `scoring` represents a single score, one can use:<br><br>- a single string (see :ref:`scoring_string_names`);<br>- a callable (see :ref:`scoring_callable`) that returns a single value;<br>- `None`, the `estimator`'s<br>  :ref:`default evaluation criterion <scoring_api_overview>` is used.<br><br>If `scoring` represents multiple scores, one can use:<br><br>- a list or tuple of unique strings;<br>- a callable returning a dictionary where the keys are the metric<br>  names and the values are the metric scores;<br>- a dictionary with metric names as keys and callables as values.<br><br>See :ref:`multimetric_grid_search` for an example.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Number of jobs to run in parallel.<br>``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>for more details.<br><br>.. versionchanged:: v0.20<br>   `n_jobs` default changed from 1 to None</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('refit',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=refit,-bool%2C%20str%2C%20or%20callable%2C%20default%3DTrue\">\n",
       "            refit\n",
       "            <span class=\"param-doc-description\">refit: bool, str, or callable, default=True<br><br>Refit an estimator using the best found parameters on the whole<br>dataset.<br><br>For multiple metric evaluation, this needs to be a `str` denoting the<br>scorer that would be used to find the best parameters for refitting<br>the estimator at the end.<br><br>Where there are considerations other than maximum score in<br>choosing a best estimator, ``refit`` can be set to a function which<br>returns the selected ``best_index_`` given ``cv_results_``. In that<br>case, the ``best_estimator_`` and ``best_params_`` will be set<br>according to the returned ``best_index_`` while the ``best_score_``<br>attribute will not be available.<br><br>The refitted estimator is made available at the ``best_estimator_``<br>attribute and permits using ``predict`` directly on this<br>``GridSearchCV`` instance.<br><br>Also for multiple metric evaluation, the attributes ``best_index_``,<br>``best_score_`` and ``best_params_`` will only be available if<br>``refit`` is set and all of them will be determined w.r.t this specific<br>scorer.<br><br>See ``scoring`` parameter to know more about multiple metric<br>evaluation.<br><br>See :ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`<br>to see how to design a custom selection strategy using a callable<br>via `refit`.<br><br>See :ref:`this example<br><sphx_glr_auto_examples_model_selection_plot_grid_search_refit_callable.py>`<br>for an example of how to use ``refit=callable`` to balance model<br>complexity and cross-validated score.<br><br>.. versionchanged:: 0.20<br>    Support for callable added.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('cv',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=cv,-int%2C%20cross-validation%20generator%20or%20an%20iterable%2C%20default%3DNone\">\n",
       "            cv\n",
       "            <span class=\"param-doc-description\">cv: int, cross-validation generator or an iterable, default=None<br><br>Determines the cross-validation splitting strategy.<br>Possible inputs for cv are:<br><br>- None, to use the default 5-fold cross validation,<br>- integer, to specify the number of folds in a `(Stratified)KFold`,<br>- :term:`CV splitter`,<br>- An iterable yielding (train, test) splits as arrays of indices.<br><br>For integer/None inputs, if the estimator is a classifier and ``y`` is<br>either binary or multiclass, :class:`StratifiedKFold` is used. In all<br>other cases, :class:`KFold` is used. These splitters are instantiated<br>with `shuffle=False` so the splits will be the same across calls.<br><br>Refer :ref:`User Guide <cross_validation>` for the various<br>cross-validation strategies that can be used here.<br><br>.. versionchanged:: 0.22<br>    ``cv`` default value if None changed from 3-fold to 5-fold.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=verbose,-int\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int<br><br>Controls the verbosity: the higher, the more messages.<br><br>- >1 : the computation time for each fold and parameter candidate is<br>  displayed;<br>- >2 : the score is also displayed;<br>- >3 : the fold and candidate parameter indexes are also displayed<br>  together with the starting time of the computation.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('pre_dispatch',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=pre_dispatch,-int%2C%20or%20str%2C%20default%3D%272%2An_jobs%27\">\n",
       "            pre_dispatch\n",
       "            <span class=\"param-doc-description\">pre_dispatch: int, or str, default='2*n_jobs'<br><br>Controls the number of jobs that get dispatched during parallel<br>execution. Reducing this number can be useful to avoid an<br>explosion of memory consumption when more jobs get dispatched<br>than CPUs can process. This parameter can be:<br><br>- None, in which case all the jobs are immediately created and spawned. Use<br>  this for lightweight and fast-running jobs, to avoid delays due to on-demand<br>  spawning of the jobs<br>- An int, giving the exact number of total jobs that are spawned<br>- A str, giving an expression as a function of n_jobs, as in '2*n_jobs'</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;2*n_jobs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('error_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=error_score,-%27raise%27%20or%20numeric%2C%20default%3Dnp.nan\">\n",
       "            error_score\n",
       "            <span class=\"param-doc-description\">error_score: 'raise' or numeric, default=np.nan<br><br>Value to assign to the score if an error occurs in estimator fitting.<br>If set to 'raise', the error is raised. If a numeric value is given,<br>FitFailedWarning is raised. This parameter does not affect the refit<br>step, which will always raise the error.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('return_train_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.model_selection.GridSearchCV.html#:~:text=return_train_score,-bool%2C%20default%3DFalse\">\n",
       "            return_train_score\n",
       "            <span class=\"param-doc-description\">return_train_score: bool, default=False<br><br>If ``False``, the ``cv_results_`` attribute will not include training<br>scores.<br>Computing training scores is used to get insights on how different<br>parameter settings impact the overfitting/underfitting trade-off.<br>However computing the scores on the training set can be computationally<br>expensive and is not strictly required to select the parameters that<br>yield the best generalization performance.<br><br>.. versionadded:: 0.19<br><br>.. versionchanged:: 0.21<br>    Default value was changed from ``True`` to ``False``</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: LGBMClassifier</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\"><pre>LGBMClassifier(learning_rate=0.05, max_depth=10, min_child_samples=5,\n",
       "               num_leaves=15)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMClassifier</div></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"best_estimator___\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('boosting_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">boosting_type</td>\n",
       "            <td class=\"value\">&#x27;gbdt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_leaves</td>\n",
       "            <td class=\"value\">15</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth</td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate</td>\n",
       "            <td class=\"value\">0.05</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_for_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_for_bin</td>\n",
       "            <td class=\"value\">200000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_split_gain',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_split_gain</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight</td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_samples</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_freq',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_freq</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type</td>\n",
       "            <td class=\"value\">&#x27;split&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-2');</script></body>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=LGBMClassifier(),\n",
       "             param_grid={'learning_rate': [0.05, 0.1], 'max_depth': [-1, 10],\n",
       "                         'min_child_samples': [5, 10],\n",
       "                         'n_estimators': [100, 200], 'num_leaves': [15, 31]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid2=GridSearchCV(lightgbm.LGBMClassifier(),param_grid=params,verbose=1)\n",
    "grid2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1728325620418,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "XaZ-AMGEGeDc",
    "outputId": "b6248978-a147-4662-8bb5-37407aedd430"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.05,\n",
       " 'max_depth': 10,\n",
       " 'min_child_samples': 5,\n",
       " 'n_estimators': 100,\n",
       " 'num_leaves': 15}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1728325620418,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "hdItrY7YHYdl",
    "outputId": "dd1ec23d-49eb-452b-a594-8e24b8e24ba6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-3.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-3.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.7, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=90,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=objective,-typing.Union%5Bstr%2C%20xgboost.sklearn._SklObjWProto%2C%20typing.Callable%5B%5Btyping.Any%2C%20typing.Any%5D%2C%20typing.Tuple%5Bnumpy.ndarray%2C%20numpy.ndarray%5D%5D%2C%20NoneType%5D\">\n",
       "            objective\n",
       "            <span class=\"param-doc-description\">objective: typing.Union[str, xgboost.sklearn._SklObjWProto, typing.Callable[[typing.Any, typing.Any], typing.Tuple[numpy.ndarray, numpy.ndarray]], NoneType]<br><br>Specify the learning task and the corresponding learning objective or a custom<br>objective function to be used.<br><br>For custom objective, see :doc:`/tutorials/custom_metric_obj` and<br>:ref:`custom-obj-metric` for more information, along with the end note for<br>function signatures.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;binary:logistic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=base_score,-typing.Union%5Bfloat%2C%20typing.List%5Bfloat%5D%2C%20NoneType%5D\">\n",
       "            base_score\n",
       "            <span class=\"param-doc-description\">base_score: typing.Union[float, typing.List[float], NoneType]<br><br>The initial prediction score of all instances, global bias.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=callbacks,-typing.Optional%5Btyping.List%5Bxgboost.callback.TrainingCallback%5D%5D\">\n",
       "            callbacks\n",
       "            <span class=\"param-doc-description\">callbacks: typing.Optional[typing.List[xgboost.callback.TrainingCallback]]<br><br>List of callback functions that are applied at end of each iteration.<br>It is possible to use predefined callbacks by using<br>:ref:`Callback API <callback_api>`.<br><br>.. note::<br><br>   States in callback are not preserved during training, which means callback<br>   objects can not be reused for multiple training sessions without<br>   reinitialization or deepcopy.<br><br>.. code-block:: python<br><br>    for params in parameters_grid:<br>        # be sure to (re)initialize the callbacks before each run<br>        callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]<br>        reg = xgboost.XGBRegressor(**params, callbacks=callbacks)<br>        reg.fit(X, y)</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=colsample_bylevel,-typing.Optional%5Bfloat%5D\">\n",
       "            colsample_bylevel\n",
       "            <span class=\"param-doc-description\">colsample_bylevel: typing.Optional[float]<br><br>Subsample ratio of columns for each level.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=colsample_bynode,-typing.Optional%5Bfloat%5D\">\n",
       "            colsample_bynode\n",
       "            <span class=\"param-doc-description\">colsample_bynode: typing.Optional[float]<br><br>Subsample ratio of columns for each split.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=colsample_bytree,-typing.Optional%5Bfloat%5D\">\n",
       "            colsample_bytree\n",
       "            <span class=\"param-doc-description\">colsample_bytree: typing.Optional[float]<br><br>Subsample ratio of columns when constructing each tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=device,-typing.Optional%5Bstr%5D\">\n",
       "            device\n",
       "            <span class=\"param-doc-description\">device: typing.Optional[str]<br><br>.. versionadded:: 2.0.0<br><br>Device ordinal, available options are `cpu`, `cuda`, and `gpu`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=early_stopping_rounds,-typing.Optional%5Bint%5D\">\n",
       "            early_stopping_rounds\n",
       "            <span class=\"param-doc-description\">early_stopping_rounds: typing.Optional[int]<br><br>.. versionadded:: 1.6.0<br><br>- Activates early stopping. Validation metric needs to improve at least once in<br>  every **early_stopping_rounds** round(s) to continue training.  Requires at<br>  least one item in **eval_set** in :py:meth:`fit`.<br><br>- If early stopping occurs, the model will have two additional attributes:<br>  :py:attr:`best_score` and :py:attr:`best_iteration`. These are used by the<br>  :py:meth:`predict` and :py:meth:`apply` methods to determine the optimal<br>  number of trees during inference. If users want to access the full model<br>  (including trees built after early stopping), they can specify the<br>  `iteration_range` in these inference methods. In addition, other utilities<br>  like model plotting can also use the entire model.<br><br>- If you prefer to discard the trees after `best_iteration`, consider using the<br>  callback function :py:class:`xgboost.callback.EarlyStopping`.<br><br>- If there's more than one item in **eval_set**, the last entry will be used for<br>  early stopping.  If there's more than one metric in **eval_metric**, the last<br>  metric will be used for early stopping.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=enable_categorical,-bool\">\n",
       "            enable_categorical\n",
       "            <span class=\"param-doc-description\">enable_categorical: bool<br><br>See the same parameter of :py:class:`DMatrix` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=eval_metric,-typing.Union%5Bstr%2C%20typing.List%5Btyping.Union%5Bstr%2C%20typing.Callable%5D%5D%2C%20typing.Callable%2C%20NoneType%5D\">\n",
       "            eval_metric\n",
       "            <span class=\"param-doc-description\">eval_metric: typing.Union[str, typing.List[typing.Union[str, typing.Callable]], typing.Callable, NoneType]<br><br>.. versionadded:: 1.6.0<br><br>Metric used for monitoring the training result and early stopping.  It can be a<br>string or list of strings as names of predefined metric in XGBoost (See<br>:doc:`/parameter`), one of the metrics in :py:mod:`sklearn.metrics`, or any<br>other user defined metric that looks like `sklearn.metrics`.<br><br>If custom objective is also provided, then custom metric should implement the<br>corresponding reverse link function.<br><br>Unlike the `scoring` parameter commonly used in scikit-learn, when a callable<br>object is provided, it's assumed to be a cost function and by default XGBoost<br>will minimize the result during early stopping.<br><br>For advanced usage on Early stopping like directly choosing to maximize instead<br>of minimize, see :py:obj:`xgboost.callback.EarlyStopping`.<br><br>See :doc:`/tutorials/custom_metric_obj` and :ref:`custom-obj-metric` for more<br>information.<br><br>.. code-block:: python<br><br>    from sklearn.datasets import load_diabetes<br>    from sklearn.metrics import mean_absolute_error<br>    X, y = load_diabetes(return_X_y=True)<br>    reg = xgb.XGBRegressor(<br>        tree_method=\"hist\",<br>        eval_metric=mean_absolute_error,<br>    )<br>    reg.fit(X, y, eval_set=[(X, y)])</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=feature_types,-typing.Optional%5Btyping.Sequence%5Bstr%5D%5D\">\n",
       "            feature_types\n",
       "            <span class=\"param-doc-description\">feature_types: typing.Optional[typing.Sequence[str]]<br><br>.. versionadded:: 1.7.0<br><br>Used for specifying feature types without constructing a dataframe. See<br>the :py:class:`DMatrix` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=feature_weights,-Optional%5BArrayLike%5D\">\n",
       "            feature_weights\n",
       "            <span class=\"param-doc-description\">feature_weights: Optional[ArrayLike]<br><br>Weight for each feature, defines the probability of each feature being selected<br>when colsample is being used.  All values must be greater than 0, otherwise a<br>`ValueError` is thrown.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=gamma,-typing.Optional%5Bfloat%5D\">\n",
       "            gamma\n",
       "            <span class=\"param-doc-description\">gamma: typing.Optional[float]<br><br>(min_split_loss) Minimum loss reduction required to make a further partition on<br>a leaf node of the tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=grow_policy,-typing.Optional%5Bstr%5D\">\n",
       "            grow_policy\n",
       "            <span class=\"param-doc-description\">grow_policy: typing.Optional[str]<br><br>Tree growing policy.<br><br>- depthwise: Favors splitting at nodes closest to the node,<br>- lossguide: Favors splitting at nodes with highest loss change.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=interaction_constraints,-typing.Union%5Bstr%2C%20typing.List%5Btyping.Tuple%5Bstr%5D%5D%2C%20NoneType%5D\">\n",
       "            interaction_constraints\n",
       "            <span class=\"param-doc-description\">interaction_constraints: typing.Union[str, typing.List[typing.Tuple[str]], NoneType]<br><br>Constraints for interaction representing permitted interactions.  The<br>constraints must be specified in the form of a nested list, e.g. ``[[0, 1], [2,<br>3, 4]]``, where each inner list is a group of indices of features that are<br>allowed to interact with each other.  See :doc:`tutorial<br></tutorials/feature_interaction_constraint>` for more information</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=learning_rate,-typing.Optional%5Bfloat%5D\">\n",
       "            learning_rate\n",
       "            <span class=\"param-doc-description\">learning_rate: typing.Optional[float]<br><br>Boosting learning rate (xgb's \"eta\")</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.7</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=max_bin,-typing.Optional%5Bint%5D\">\n",
       "            max_bin\n",
       "            <span class=\"param-doc-description\">max_bin: typing.Optional[int]<br><br>If using histogram-based algorithm, maximum number of bins per feature</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=max_cat_threshold,-typing.Optional%5Bint%5D\">\n",
       "            max_cat_threshold\n",
       "            <span class=\"param-doc-description\">max_cat_threshold: typing.Optional[int]<br><br>.. versionadded:: 1.7.0<br><br>.. note:: This parameter is experimental<br><br>Maximum number of categories considered for each split. Used only by<br>partition-based splits for preventing over-fitting. Also, `enable_categorical`<br>needs to be set to have categorical feature support. See :doc:`Categorical Data<br></tutorials/categorical>` and :ref:`cat-param` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=max_cat_to_onehot,-Optional%5Bint%5D\">\n",
       "            max_cat_to_onehot\n",
       "            <span class=\"param-doc-description\">max_cat_to_onehot: Optional[int]<br><br>.. versionadded:: 1.6.0<br><br>.. note:: This parameter is experimental<br><br>A threshold for deciding whether XGBoost should use one-hot encoding based split<br>for categorical data.  When number of categories is lesser than the threshold<br>then one-hot encoding is chosen, otherwise the categories will be partitioned<br>into children nodes. Also, `enable_categorical` needs to be set to have<br>categorical feature support. See :doc:`Categorical Data<br></tutorials/categorical>` and :ref:`cat-param` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=max_delta_step,-typing.Optional%5Bfloat%5D\">\n",
       "            max_delta_step\n",
       "            <span class=\"param-doc-description\">max_delta_step: typing.Optional[float]<br><br>Maximum delta step we allow each tree's weight estimation to be.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=max_depth,-%20typing.Optional%5Bint%5D\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth:  typing.Optional[int]<br><br>Maximum tree depth for base learners.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">3</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=max_leaves,-typing.Optional%5Bint%5D\">\n",
       "            max_leaves\n",
       "            <span class=\"param-doc-description\">max_leaves: typing.Optional[int]<br><br>Maximum number of leaves; 0 indicates no limit.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=min_child_weight,-typing.Optional%5Bfloat%5D\">\n",
       "            min_child_weight\n",
       "            <span class=\"param-doc-description\">min_child_weight: typing.Optional[float]<br><br>Minimum sum of instance weight(hessian) needed in a child.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=missing,-float\">\n",
       "            missing\n",
       "            <span class=\"param-doc-description\">missing: float<br><br>Value in the data which needs to be present as a missing value. Default to<br>:py:data:`numpy.nan`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=monotone_constraints,-typing.Union%5Btyping.Dict%5Bstr%2C%20int%5D%2C%20str%2C%20NoneType%5D\">\n",
       "            monotone_constraints\n",
       "            <span class=\"param-doc-description\">monotone_constraints: typing.Union[typing.Dict[str, int], str, NoneType]<br><br>Constraint of variable monotonicity.  See :doc:`tutorial </tutorials/monotonic>`<br>for more information.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=multi_strategy,-typing.Optional%5Bstr%5D\">\n",
       "            multi_strategy\n",
       "            <span class=\"param-doc-description\">multi_strategy: typing.Optional[str]<br><br>.. versionadded:: 2.0.0<br><br>.. note:: This parameter is working-in-progress.<br><br>The strategy used for training multi-target models, including multi-target<br>regression and multi-class classification. See :doc:`/tutorials/multioutput` for<br>more information.<br><br>- ``one_output_per_tree``: One model for each target.<br>- ``multi_output_tree``:  Use multi-target trees.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=n_estimators,-Optional%5Bint%5D\">\n",
       "            n_estimators\n",
       "            <span class=\"param-doc-description\">n_estimators: Optional[int]<br><br>Number of boosting rounds.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">90</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=n_jobs,-typing.Optional%5Bint%5D\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: typing.Optional[int]<br><br>Number of parallel threads used to run xgboost.  When used with other<br>Scikit-Learn algorithms like grid search, you may choose which algorithm to<br>parallelize and balance the threads.  Creating thread contention will<br>significantly slow down both algorithms.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=random_state,-typing.Union%5Bnumpy.random.mtrand.RandomState%2C%20numpy.random._generator.Generator%2C%20int%2C%20NoneType%5D\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: typing.Union[numpy.random.mtrand.RandomState, numpy.random._generator.Generator, int, NoneType]<br><br>Random number seed.<br><br>.. note::<br><br>   Using gblinear booster with shotgun updater is nondeterministic as<br>   it uses Hogwild algorithm.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=reg_alpha,-typing.Optional%5Bfloat%5D\">\n",
       "            reg_alpha\n",
       "            <span class=\"param-doc-description\">reg_alpha: typing.Optional[float]<br><br>L1 regularization term on weights (xgb's alpha).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=reg_lambda,-typing.Optional%5Bfloat%5D\">\n",
       "            reg_lambda\n",
       "            <span class=\"param-doc-description\">reg_lambda: typing.Optional[float]<br><br>L2 regularization term on weights (xgb's lambda).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">3</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=sampling_method,-typing.Optional%5Bstr%5D\">\n",
       "            sampling_method\n",
       "            <span class=\"param-doc-description\">sampling_method: typing.Optional[str]<br><br>Sampling method. Used only by the GPU version of ``hist`` tree method.<br><br>- ``uniform``: Select random training instances uniformly.<br>- ``gradient_based``: Select random training instances with higher probability<br>    when the gradient and hessian are larger. (cf. CatBoost)</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=scale_pos_weight,-typing.Optional%5Bfloat%5D\">\n",
       "            scale_pos_weight\n",
       "            <span class=\"param-doc-description\">scale_pos_weight: typing.Optional[float]<br><br>Balancing of positive and negative weights.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=subsample,-typing.Optional%5Bfloat%5D\">\n",
       "            subsample\n",
       "            <span class=\"param-doc-description\">subsample: typing.Optional[float]<br><br>Subsample ratio of the training instance.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=tree_method,-typing.Optional%5Bstr%5D\">\n",
       "            tree_method\n",
       "            <span class=\"param-doc-description\">tree_method: typing.Optional[str]<br><br>Specify which tree method to use.  Default to auto.  If this parameter is set to<br>default, XGBoost will choose the most conservative option available.  It's<br>recommended to study this option from the parameters document :doc:`tree method<br></treemethod>`</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=validate_parameters,-typing.Optional%5Bbool%5D\">\n",
       "            validate_parameters\n",
       "            <span class=\"param-doc-description\">validate_parameters: typing.Optional[bool]<br><br>Give warnings for unknown parameter.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier#:~:text=verbosity,-typing.Optional%5Bint%5D\">\n",
       "            verbosity\n",
       "            <span class=\"param-doc-description\">verbosity: typing.Optional[int]<br><br>The degree of verbosity. Valid values are 0 (silent) - 3 (debug).</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-3');</script></body>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.7, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=90,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model=xgboost.XGBClassifier(reg_lambda= 3, learning_rate= 0.7, max_depth= 3, n_estimators=90)\n",
    "xgb_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1728325620418,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "urEXRHi-IIvE",
    "outputId": "14721ab7-f0e5-4c0a-fe8b-ed06d8de8a58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1=xgb_model.predict(x_test)\n",
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1728325620418,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "ND7N25rzIleO",
    "outputId": "25e7e3df-54e0-4f91-d6a5-ffdd1a000aa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 263, number of negative: 449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 458\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.369382 -> initscore=-0.534869\n",
      "[LightGBM] [Info] Start training from score -0.534869\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-4.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-4.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.5, max_depth=3, n_estimators=110, reg_lambda=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LGBMClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('boosting_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">boosting_type</td>\n",
       "            <td class=\"value\">&#x27;gbdt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_leaves</td>\n",
       "            <td class=\"value\">31</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth</td>\n",
       "            <td class=\"value\">3</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate</td>\n",
       "            <td class=\"value\">0.5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators</td>\n",
       "            <td class=\"value\">110</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_for_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_for_bin</td>\n",
       "            <td class=\"value\">200000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_split_gain',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_split_gain</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight</td>\n",
       "            <td class=\"value\">0.001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_samples</td>\n",
       "            <td class=\"value\">20</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample_freq',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample_freq</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type</td>\n",
       "            <td class=\"value\">&#x27;split&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-4');</script></body>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.5, max_depth=3, n_estimators=110, reg_lambda=2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model=lightgbm.LGBMClassifier(reg_lambda= 2, learning_rate= 0.5, max_depth= 3, n_estimators=110)\n",
    "lgb_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1728325620418,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "Kr_cB5JOI4R5",
    "outputId": "091e9ba1-b21a-4e74-d223-7cbef2515e1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2=lgb_model.predict(x_test)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1728325620418,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "_ZFIvEFNLF0b",
    "outputId": "bf784a9d-9fd3-43ea-e6b0-5b6cc2b67e83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM - Accuracy: 0.75\n",
      "LightGBM - Precision: 0.80\n",
      "LightGBM - Recall: 0.59\n",
      "LightGBM - F1 Score: 0.68\n",
      "XGBoost - Accuracy: 0.75\n",
      "XGBoost - Precision: 0.79\n",
      "XGBoost - Recall: 0.58\n",
      "XGBoost - F1 Score: 0.67\n"
     ]
    }
   ],
   "source": [
    "# evaluate models\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    print(f\"{model_name} - Accuracy: {accuracy_score(y_true, y_pred):.2f}\")\n",
    "    print(f\"{model_name} - Precision: {precision_score(y_true, y_pred):.2f}\")\n",
    "    print(f\"{model_name} - Recall: {recall_score(y_true, y_pred):.2f}\")\n",
    "    print(f\"{model_name} - F1 Score: {f1_score(y_true, y_pred):.2f}\")\n",
    "\n",
    "evaluate_model(y_test, pred2, 'LightGBM')\n",
    "evaluate_model(y_test, pred1, 'XGBoost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rY58w3VnLoKf"
   },
   "source": [
    "## **Comparative Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 518,
     "status": "ok",
     "timestamp": 1728325620932,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "tQ_krw32LftG"
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['LightGBM', 'XGBoost'],\n",
    "    'Accuracy': [accuracy_score(y_test, pred2), accuracy_score(y_test, pred1)],\n",
    "    'Precision': [precision_score(y_test, pred2), precision_score(y_test, pred1)],\n",
    "    'Recall': [recall_score(y_test, pred2), recall_score(y_test, pred1)],\n",
    "    'F1 Score': [f1_score(y_test, pred2), f1_score(y_test, pred1)]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1728325620932,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "n-QNZ6Q7MJ0w",
    "outputId": "f37526e9-fdbc-49a6-a5fc-465004a2284e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.754190</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.594937</td>\n",
       "      <td>0.681159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.748603</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.582278</td>\n",
       "      <td>0.671533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy  Precision    Recall  F1 Score\n",
       "0  LightGBM  0.754190   0.796610  0.594937  0.681159\n",
       "1   XGBoost  0.748603   0.793103  0.582278  0.671533"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1728325620932,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "DZjGe4OJMMN7",
    "outputId": "473a5195-e101-4aca-a26e-a620eb9adb54"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results.set_index('Model').plot(kind='bar', figsize=(10, 6), colormap='viridis')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylabel('Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 474,
     "status": "ok",
     "timestamp": 1728325974276,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "Z1zDPsFQPWvO"
   },
   "outputs": [],
   "source": [
    "df_test=pd.read_csv('Titanic_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1728325975896,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "JirAgBkyPxIb",
    "outputId": "26f3d2bb-24b1-489b-d943-416ecbd9fa56"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                          Name  \\\n",
       "0            892       3                              Kelly, Mr. James   \n",
       "1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
       "2            894       2                     Myles, Mr. Thomas Francis   \n",
       "3            895       3                              Wirz, Mr. Albert   \n",
       "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
       "..           ...     ...                                           ...   \n",
       "413         1305       3                            Spector, Mr. Woolf   \n",
       "414         1306       1                  Oliva y Ocana, Dona. Fermina   \n",
       "415         1307       3                  Saether, Mr. Simon Sivertsen   \n",
       "416         1308       3                           Ware, Mr. Frederick   \n",
       "417         1309       3                      Peter, Master. Michael J   \n",
       "\n",
       "        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \n",
       "0      male  34.5      0      0              330911    7.8292   NaN        Q  \n",
       "1    female  47.0      1      0              363272    7.0000   NaN        S  \n",
       "2      male  62.0      0      0              240276    9.6875   NaN        Q  \n",
       "3      male  27.0      0      0              315154    8.6625   NaN        S  \n",
       "4    female  22.0      1      1             3101298   12.2875   NaN        S  \n",
       "..      ...   ...    ...    ...                 ...       ...   ...      ...  \n",
       "413    male   NaN      0      0           A.5. 3236    8.0500   NaN        S  \n",
       "414  female  39.0      0      0            PC 17758  108.9000  C105        C  \n",
       "415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
       "416    male   NaN      0      0              359309    8.0500   NaN        S  \n",
       "417    male   NaN      1      1                2668   22.3583   NaN        C  \n",
       "\n",
       "[418 rows x 11 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 487,
     "status": "ok",
     "timestamp": 1728325978687,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "nMxFLQewP6NN",
    "outputId": "5055567b-3ad9-4b53-de81-2ed7a7d94b20"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                          Name   Age  \\\n",
       "0            892       3                              Kelly, Mr. James  34.5   \n",
       "1            893       3              Wilkes, Mrs. James (Ellen Needs)  47.0   \n",
       "2            894       2                     Myles, Mr. Thomas Francis  62.0   \n",
       "3            895       3                              Wirz, Mr. Albert  27.0   \n",
       "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  22.0   \n",
       "..           ...     ...                                           ...   ...   \n",
       "413         1305       3                            Spector, Mr. Woolf   NaN   \n",
       "414         1306       1                  Oliva y Ocana, Dona. Fermina  39.0   \n",
       "415         1307       3                  Saether, Mr. Simon Sivertsen  38.5   \n",
       "416         1308       3                           Ware, Mr. Frederick   NaN   \n",
       "417         1309       3                      Peter, Master. Michael J   NaN   \n",
       "\n",
       "     SibSp  Parch              Ticket      Fare Cabin  Sex_female  Sex_male  \\\n",
       "0        0      0              330911    7.8292   NaN       False      True   \n",
       "1        1      0              363272    7.0000   NaN        True     False   \n",
       "2        0      0              240276    9.6875   NaN       False      True   \n",
       "3        0      0              315154    8.6625   NaN       False      True   \n",
       "4        1      1             3101298   12.2875   NaN        True     False   \n",
       "..     ...    ...                 ...       ...   ...         ...       ...   \n",
       "413      0      0           A.5. 3236    8.0500   NaN       False      True   \n",
       "414      0      0            PC 17758  108.9000  C105        True     False   \n",
       "415      0      0  SOTON/O.Q. 3101262    7.2500   NaN       False      True   \n",
       "416      0      0              359309    8.0500   NaN       False      True   \n",
       "417      1      1                2668   22.3583   NaN       False      True   \n",
       "\n",
       "     Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         False        True       False  \n",
       "1         False       False        True  \n",
       "2         False        True       False  \n",
       "3         False       False        True  \n",
       "4         False       False        True  \n",
       "..          ...         ...         ...  \n",
       "413       False       False        True  \n",
       "414        True       False       False  \n",
       "415       False       False        True  \n",
       "416       False       False        True  \n",
       "417        True       False       False  \n",
       "\n",
       "[418 rows x 14 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test=pd.get_dummies(df_test,columns=['Sex','Embarked'])\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 1548,
     "status": "ok",
     "timestamp": 1728325985169,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "ivzrcPvgQCp6",
    "outputId": "f7a46fb0-70d8-43d0-8259-8e6166acf80b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass   Age  SibSp  Parch      Fare  Sex_female  Sex_male  \\\n",
       "0            892       3  34.5      0      0    7.8292       False      True   \n",
       "1            893       3  47.0      1      0    7.0000        True     False   \n",
       "2            894       2  62.0      0      0    9.6875       False      True   \n",
       "3            895       3  27.0      0      0    8.6625       False      True   \n",
       "4            896       3  22.0      1      1   12.2875        True     False   \n",
       "..           ...     ...   ...    ...    ...       ...         ...       ...   \n",
       "413         1305       3   NaN      0      0    8.0500       False      True   \n",
       "414         1306       1  39.0      0      0  108.9000        True     False   \n",
       "415         1307       3  38.5      0      0    7.2500       False      True   \n",
       "416         1308       3   NaN      0      0    8.0500       False      True   \n",
       "417         1309       3   NaN      1      1   22.3583       False      True   \n",
       "\n",
       "     Embarked_C  Embarked_Q  Embarked_S  \n",
       "0         False        True       False  \n",
       "1         False       False        True  \n",
       "2         False        True       False  \n",
       "3         False       False        True  \n",
       "4         False       False        True  \n",
       "..          ...         ...         ...  \n",
       "413       False       False        True  \n",
       "414        True       False       False  \n",
       "415       False       False        True  \n",
       "416       False       False        True  \n",
       "417        True       False       False  \n",
       "\n",
       "[418 rows x 11 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unneccessary columns\n",
    "df_test.drop(['Cabin','Name','Ticket'],inplace=True,axis=1)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1728326122616,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "f1Y4jSM5Qpby"
   },
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "x3=scaler.fit_transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 768,
     "status": "ok",
     "timestamp": 1728326126780,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "KJz4noEMQb-L"
   },
   "outputs": [],
   "source": [
    "df_test=pd.DataFrame(x3,columns=df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 704,
     "status": "ok",
     "timestamp": 1728326138174,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "N8ggqI-dQ9wu",
    "outputId": "4f022bf4-8f31-401f-ca2e-0bd51be7b564"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.727912</td>\n",
       "      <td>0.873482</td>\n",
       "      <td>0.298549</td>\n",
       "      <td>-0.499470</td>\n",
       "      <td>-0.400248</td>\n",
       "      <td>-0.497811</td>\n",
       "      <td>-0.755929</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>-0.568142</td>\n",
       "      <td>2.843757</td>\n",
       "      <td>-1.350676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.719625</td>\n",
       "      <td>0.873482</td>\n",
       "      <td>1.181328</td>\n",
       "      <td>0.616992</td>\n",
       "      <td>-0.400248</td>\n",
       "      <td>-0.512660</td>\n",
       "      <td>1.322876</td>\n",
       "      <td>-1.322876</td>\n",
       "      <td>-0.568142</td>\n",
       "      <td>-0.351647</td>\n",
       "      <td>0.740370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.711337</td>\n",
       "      <td>-0.315819</td>\n",
       "      <td>2.240662</td>\n",
       "      <td>-0.499470</td>\n",
       "      <td>-0.400248</td>\n",
       "      <td>-0.464532</td>\n",
       "      <td>-0.755929</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>-0.568142</td>\n",
       "      <td>2.843757</td>\n",
       "      <td>-1.350676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.703050</td>\n",
       "      <td>0.873482</td>\n",
       "      <td>-0.231118</td>\n",
       "      <td>-0.499470</td>\n",
       "      <td>-0.400248</td>\n",
       "      <td>-0.482888</td>\n",
       "      <td>-0.755929</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>-0.568142</td>\n",
       "      <td>-0.351647</td>\n",
       "      <td>0.740370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.694763</td>\n",
       "      <td>0.873482</td>\n",
       "      <td>-0.584229</td>\n",
       "      <td>0.616992</td>\n",
       "      <td>0.619896</td>\n",
       "      <td>-0.417971</td>\n",
       "      <td>1.322876</td>\n",
       "      <td>-1.322876</td>\n",
       "      <td>-0.568142</td>\n",
       "      <td>-0.351647</td>\n",
       "      <td>0.740370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1.694763</td>\n",
       "      <td>0.873482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.499470</td>\n",
       "      <td>-0.400248</td>\n",
       "      <td>-0.493856</td>\n",
       "      <td>-0.755929</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>-0.568142</td>\n",
       "      <td>-0.351647</td>\n",
       "      <td>0.740370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1.703050</td>\n",
       "      <td>-1.505120</td>\n",
       "      <td>0.616350</td>\n",
       "      <td>-0.499470</td>\n",
       "      <td>-0.400248</td>\n",
       "      <td>1.312180</td>\n",
       "      <td>1.322876</td>\n",
       "      <td>-1.322876</td>\n",
       "      <td>1.760125</td>\n",
       "      <td>-0.351647</td>\n",
       "      <td>-1.350676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1.711337</td>\n",
       "      <td>0.873482</td>\n",
       "      <td>0.581038</td>\n",
       "      <td>-0.499470</td>\n",
       "      <td>-0.400248</td>\n",
       "      <td>-0.508183</td>\n",
       "      <td>-0.755929</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>-0.568142</td>\n",
       "      <td>-0.351647</td>\n",
       "      <td>0.740370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1.719625</td>\n",
       "      <td>0.873482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.499470</td>\n",
       "      <td>-0.400248</td>\n",
       "      <td>-0.493856</td>\n",
       "      <td>-0.755929</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>-0.568142</td>\n",
       "      <td>-0.351647</td>\n",
       "      <td>0.740370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1.727912</td>\n",
       "      <td>0.873482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.616992</td>\n",
       "      <td>0.619896</td>\n",
       "      <td>-0.237621</td>\n",
       "      <td>-0.755929</td>\n",
       "      <td>0.755929</td>\n",
       "      <td>1.760125</td>\n",
       "      <td>-0.351647</td>\n",
       "      <td>-1.350676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId    Pclass       Age     SibSp     Parch      Fare  \\\n",
       "0      -1.727912  0.873482  0.298549 -0.499470 -0.400248 -0.497811   \n",
       "1      -1.719625  0.873482  1.181328  0.616992 -0.400248 -0.512660   \n",
       "2      -1.711337 -0.315819  2.240662 -0.499470 -0.400248 -0.464532   \n",
       "3      -1.703050  0.873482 -0.231118 -0.499470 -0.400248 -0.482888   \n",
       "4      -1.694763  0.873482 -0.584229  0.616992  0.619896 -0.417971   \n",
       "..           ...       ...       ...       ...       ...       ...   \n",
       "413     1.694763  0.873482       NaN -0.499470 -0.400248 -0.493856   \n",
       "414     1.703050 -1.505120  0.616350 -0.499470 -0.400248  1.312180   \n",
       "415     1.711337  0.873482  0.581038 -0.499470 -0.400248 -0.508183   \n",
       "416     1.719625  0.873482       NaN -0.499470 -0.400248 -0.493856   \n",
       "417     1.727912  0.873482       NaN  0.616992  0.619896 -0.237621   \n",
       "\n",
       "     Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0     -0.755929  0.755929   -0.568142    2.843757   -1.350676  \n",
       "1      1.322876 -1.322876   -0.568142   -0.351647    0.740370  \n",
       "2     -0.755929  0.755929   -0.568142    2.843757   -1.350676  \n",
       "3     -0.755929  0.755929   -0.568142   -0.351647    0.740370  \n",
       "4      1.322876 -1.322876   -0.568142   -0.351647    0.740370  \n",
       "..          ...       ...         ...         ...         ...  \n",
       "413   -0.755929  0.755929   -0.568142   -0.351647    0.740370  \n",
       "414    1.322876 -1.322876    1.760125   -0.351647   -1.350676  \n",
       "415   -0.755929  0.755929   -0.568142   -0.351647    0.740370  \n",
       "416   -0.755929  0.755929   -0.568142   -0.351647    0.740370  \n",
       "417   -0.755929  0.755929    1.760125   -0.351647   -1.350676  \n",
       "\n",
       "[418 rows x 11 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 462,
     "status": "ok",
     "timestamp": 1728326140860,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "xPKUGDsKPgbZ",
    "outputId": "101853ef-e67e-4296-925c-80c07b3fa507"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict1=xgb_model.predict(df_test)\n",
    "predict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 723,
     "status": "ok",
     "timestamp": 1728326189005,
     "user": {
      "displayName": "Ubed M A",
      "userId": "10983971800976649461"
     },
     "user_tz": -330
    },
    "id": "oVw5J61sRBzG",
    "outputId": "d7cd814c-5f76-4e96-ff9b-1334c92d4847"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict2=lgb_model.predict(df_test)\n",
    "predict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0NFf9SUIRNT4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOvZ5gmikZFEcAFlfzWenba",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
